{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "globalbrewdatsynapsegbdev"
		},
		"LS_ADLS_SourceForecast_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'LS_ADLS_SourceForecast'"
		},
		"LS_ASQL_GrowthFactorAnalysis_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LS_ASQL_GrowthFactorAnalysis'"
		},
		"LS_ASQL_RosettaSource_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LS_ASQL_RosettaSource'"
		},
		"LS_ASYN_GrowthFactorAnalysis_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LS_ASYN_GrowthFactorAnalysis'"
		},
		"LS_ASYN_RosettaTarget_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LS_ASYN_RosettaTarget'"
		},
		"LS_MySQL_BrandHarmonization_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LS_MySQL_BrandHarmonization'"
		},
		"globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer'"
		},
		"LS_ADLS_SourceForecast_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://brewdatadlstestgbpoc.dfs.core.windows.net"
		},
		"globalbrewdatsynapsegbdev-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://abigrowthfactoradls.dfs.core.windows.net"
		},
		"TRIGGER_BH_ActionLog_properties_PL_ActionLog_Feedback_parameters_DBName": {
			"type": "string",
			"defaultValue": "GrowthFactorDev"
		},
		"TRIGGER_BH_ActionLog_properties_PL_ActionLog_Feedback_parameters_BATCH_NAME": {
			"type": "string",
			"defaultValue": "batch_BrandMasterFeedback"
		},
		"TRIGGER_BH_ActionLog_properties_PL_ActionLog_Feedback_parameters_CURRENT_USER": {
			"type": "string",
			"defaultValue": "synapseuser"
		},
		"TRIGGER_BrandHarmonization_properties_PL_Master_BrandHarmonization_parameters_DBName": {
			"type": "string",
			"defaultValue": "GrowthFactorDev"
		},
		"TRIGGER_BrandHarmonization_properties_PL_Master_BrandHarmonization_parameters_BATCH_NAME": {
			"type": "string",
			"defaultValue": "batch_BrandHarmonization"
		},
		"TRIGGER_BrandHarmonization_properties_PL_Master_BrandHarmonization_parameters_CURRENT_USER": {
			"type": "string",
			"defaultValue": "synapseuser"
		},
		"TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_EmailId": {
			"type": "string",
			"defaultValue": "\"Sashank.Datla-ext@ab-inbev.com\""
		},
		"TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_URL": {
			"type": "string",
			"defaultValue": ""
		},
		"TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_StorageAccountName": {
			"type": "string",
			"defaultValue": "abigrowthfactoradls"
		},
		"TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_IsTraining": {
			"type": "string",
			"defaultValue": "False"
		},
		"TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_databaseName": {
			"type": "string",
			"defaultValue": "growthfactordev"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/growthfactordev')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_ActionLog_Feedback')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_SP_ActionLogFeedback",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "PL_JOB_START",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_LoadActionLogFeedbackToBH"
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_BATCH_INITIATE",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_BATCH_INITIATE",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_BATCH_COMPLETE",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_JOB_END",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_BATCH_COMPLETE",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"BatchStatus": "COMPLETED"
							}
						}
					},
					{
						"name": "PL_JOB_START",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "LOOKUP_BATCH_RUN_ID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_actionlog_feedback",
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ACT_SP_ActionLogFeedback",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Act_Lookup_Job_Run_Id_ActionFeedback",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_ActionFeedback').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "LOOKUP_BATCH_RUN_ID",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_BATCH_INITIATE",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(BATCH_RUN_ID) AS BATCH_RUN_ID FROM dbo.ABI_BATCH_RUN_STATS WHERE BATCH_NAME = '@{pipeline().parameters.BATCH_NAME}' AND BATCH_STATUS = 'STARTED'",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_ActionFeedback",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = 'job_actionlog_feedback' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID = @{activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandMasterFeedback"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseuser"
					}
				},
				"folder": {
					"name": "Brand Harmonization"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_BATCH_INITIATE')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_BATCH_COMPLETE')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_BATCH_COMPLETE')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_SP_BATCH_COMPLETE",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_UpdateBatchStatus]",
							"storedProcedureParameters": {
								"BATCH_RUN_ID": {
									"value": {
										"value": "@pipeline().parameters.BATCH_RUN_ID",
										"type": "Expression"
									},
									"type": "String"
								},
								"BatchUpdatedGMT": {
									"value": {
										"value": "@formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss')",
										"type": "Expression"
									},
									"type": "String"
								},
								"CURRENT_USER": {
									"value": {
										"value": "@pipeline().parameters.CURRENT_USER",
										"type": "Expression"
									},
									"type": "String"
								},
								"BatchStatus": {
									"value": {
										"value": "@pipeline().parameters.BatchStatus",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseUser"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					},
					"BatchStatus": {
						"type": "string",
						"defaultValue": "COMPLETE"
					}
				},
				"folder": {
					"name": "ABC Framework"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_BATCH_INITIATE')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Act_Lookup_Last_Batch_Run_Id",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(BATCH_RUN_ID) AS BATCH_RUN_ID FROM ABI_BATCH_RUN_STATS WHERE BATCH_NAME = '@{pipeline().parameters.BATCH_NAME}' AND BATCH_STATUS = 'STARTED'",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_batch_run_stats",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "IF BATCH_RUN_ID EXISTS",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Act_Lookup_Last_Batch_Run_Id",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@not(equals(activity('Act_Lookup_Last_Batch_Run_Id').output.firstRow.BATCH_RUN_ID,null))",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Act_Lookup_Batch_Id",
									"type": "Lookup",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlDWSource",
											"sqlReaderQuery": {
												"value": "SELECT BATCH_ID AS BATCH_ID FROM ABI_BATCH_MD WHERE BATCH_NAME = '@{pipeline().parameters.BATCH_NAME}'",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"dataset": {
											"referenceName": "DS_ASYN_Destination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": "ABI_BATCH_MD",
												"SinkSchemaName": "dbo",
												"SQLPoolName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												}
											}
										}
									}
								},
								{
									"name": "Act_Insert_Batch_Run_Stats",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "Act_Lookup_Batch_Id",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlDWSource",
											"sqlReaderQuery": {
												"value": "SELECT @{concat(formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss'),activity('Act_Lookup_Batch_Id').output.firstRow.BATCH_ID)} AS BATCH_RUN_ID,@{formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss')} AS BATCH_UPD_GMT_TS,@{formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss')} AS BATCH_UPD_INS_TS,'STARTED' AS BATCH_STATUS,'@{pipeline().parameters.CURRENT_USER}' AS BATCH_CREATED_BY,'@{pipeline().parameters.CURRENT_USER}' AS BATCH_UPDATED_BY,'@{pipeline().parameters.BATCH_NAME}' AS BATCH_NAME,@{activity('Act_Lookup_Batch_Id').output.firstRow.BATCH_ID} AS BATCH_ID",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "SqlDWSink"
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "DS_ASYN_Destination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": "abi_batch_run_stats",
												"SinkSchemaName": "dbo",
												"SQLPoolName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "DS_ASYN_Destination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": "abi_batch_run_stats",
												"SinkSchemaName": "dbo",
												"SQLPoolName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												}
											}
										}
									]
								}
							],
							"ifTrueActivities": [
								{
									"name": "Act_fail",
									"type": "Lookup",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlDWSource",
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"dataset": {
											"referenceName": "DS_ASYN_Destination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": "test",
												"SinkSchemaName": "dboo",
												"SQLPoolName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												}
											}
										}
									}
								}
							]
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "'batch_BrandHarmonization'"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "'synapseUser'"
					}
				},
				"folder": {
					"name": "ABC Framework"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_BH_Model')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "PL_JOB_START_Model",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_dsmodel_execution",
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END_Model",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Act_Lookup_Job_Run_Id_Model",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "ACT_ForEach_SourceSystems_Model",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_Model').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_Model",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_Model",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = 'job_dsmodel_execution' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID = @{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "ACT_Lookup_SourceSystems",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_Model",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": "SELECT DISTINCT SourceSystem FROM [DataScienceModelConfiguration]",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_run_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ACT_ForEach_SourceSystems_Model",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_SourceSystems",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('ACT_Lookup_SourceSystems').output.value",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "ACT_Switch_DSNotebook",
									"type": "Switch",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"on": {
											"value": "@item().SourceSystem",
											"type": "Expression"
										},
										"cases": [
											{
												"value": "CIP",
												"activities": [
													{
														"name": "ACT_ModelExecution_CIP",
														"type": "SynapseNotebook",
														"dependsOn": [],
														"policy": {
															"timeout": "7.00:00:00",
															"retry": 0,
															"retryIntervalInSeconds": 30,
															"secureOutput": false,
															"secureInput": false
														},
														"userProperties": [],
														"typeProperties": {
															"notebook": {
																"referenceName": "ml_brand_matching_framework",
																"type": "NotebookReference"
															},
															"parameters": {
																"db_path": {
																	"value": {
																		"value": "@pipeline().parameters.DBName",
																		"type": "Expression"
																	},
																	"type": "string"
																}
															}
														}
													}
												]
											}
										],
										"defaultActivities": [
											{
												"name": "ACT_lookup_fail",
												"type": "Lookup",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "SqlDWSource",
														"queryTimeout": "02:00:00",
														"partitionOption": "None"
													},
													"dataset": {
														"referenceName": "DS_ASYN_Destination",
														"type": "DatasetReference",
														"parameters": {
															"SinkTableName": "abi_job",
															"SinkSchemaName": "abi_job",
															"SQLPoolName": {
																"value": "@pipeline().parameters.DBName",
																"type": "Expression"
															}
														}
													}
												}
											}
										]
									}
								}
							]
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "growthfactordev"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseuser"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					}
				},
				"folder": {
					"name": "Brand Harmonization"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-03T11:06:05Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/notebooks/ml_brand_matching_framework')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_DataLoadGrowthFactorAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "This pipeline loads data from 24 tables for growth factor analysis use case",
				"activities": [
					{
						"name": "ACT_ForEach_SourceTables",
						"description": "Iterate all the source tables",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_Config",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('ACT_Lookup_Config').output.value",
								"type": "Expression"
							},
							"batchCount": 6,
							"activities": [
								{
									"name": "ACT_CopyActivity",
									"description": "This activity copies data from azure sql db to synapse. It loads full data first time and incremental every next time.",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "AzureSqlSource",
											"sqlReaderQuery": {
												"value": "@{item().Query} @{item().TableName}",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "SqlDWSink",
											"preCopyScript": {
												"value": "@{concat('TRUNCATE TABLE ',item().TableName)}",
												"type": "Expression"
											},
											"disableMetricsCollection": false
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "DS_ASQL_GrowthFactorSource",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DS_ASYN_GrowthFactorDestination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": {
													"value": "@split(string(item().TableName),'.')[1]",
													"type": "Expression"
												},
												"SinkSchemaName": {
													"value": "@split(string(item().TableName),'.')[0]",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "ACT_Web_SendEmail_CopyFailure",
									"type": "WebActivity",
									"dependsOn": [
										{
											"activity": "ACT_CopyActivity",
											"dependencyConditions": [
												"Failed"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": true
									},
									"userProperties": [],
									"typeProperties": {
										"url": {
											"value": "@pipeline().parameters.URL",
											"type": "Expression"
										},
										"connectVia": {
											"referenceName": "AutoResolveIntegrationRuntime",
											"type": "IntegrationRuntimeReference"
										},
										"method": "POST",
										"headers": {
											"Content-Type": "application/json"
										},
										"body": {
											"value": "{\n   \"DataFactoryName\": \"@{pipeline().DataFactory}\",\n   \"PipelineName\": \"@{pipeline().Pipeline}\",\n   \"Subject\": \"Pipeline failed\",\n   \"ErrorMessage\": \"@{activity('ACT_CopyActivity').Error.message}\",\n   \"EmailTo\":  @{pipeline().parameters.EmailId}\n}\t\t",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "ACT_Lookup_Config",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": "SELECT TableName,Query FROM [dbo].[Watermark] WHERE IsActive = 1",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Watermark",
								"type": "DatasetReference",
								"parameters": {
									"DBName": "GrowthFactordev"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ACT_StoredProc_TransformFacturasBEES_Historico",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_CreateNewFacturasBEES_HistoricoTable]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedBillingData",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_StoredProc_TransformFacturasBEES_Historico",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadBillingData]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedCardViewed",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadCardViewedDataset]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedPointsActivity",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadPointsActivity]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedPointsRedeemed",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadPointsRedeemed]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedProductAdded",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadProductAddedDataset]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedOrderCompleted",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadOrderCompletedDataset]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedDeliveryRating",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadDeliveryRating]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedAppOpenedData",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadAppOpened]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_SendEmail_LookUp_Config",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_Config",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": true
						},
						"userProperties": [],
						"typeProperties": {
							"url": {
								"value": "@pipeline().parameters.URL",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"method": "POST",
							"headers": {
								"Content-Type": "application/json"
							},
							"body": {
								"value": "{\n   \"DataFactoryName\": \"@{pipeline().DataFactory}\",\n   \"PipelineName\": \"@{pipeline().Pipeline}\",\n   \"Subject\": \"Pipeline failed\",\n   \"ErrorMessage\": \"@{activity('ACT_Lookup_Config').Error.message}\",\n   \"EmailTo\": @{pipeline().parameters.EmailId}\n}\t\t",
								"type": "Expression"
							}
						}
					}
				],
				"parameters": {
					"EmailId": {
						"type": "string",
						"defaultValue": "\"Sashank.Datla-ext@ab-inbev.com\""
					},
					"URL": {
						"type": "string",
						"defaultValue": "https://prod-45.westeurope.logic.azure.com:443/workflows/4905946b127e4764bcc54d100c08385d/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=BVar7ak17GZOQXkJ3TGWqs_4EAPlnAX-fuzQETxBAaw"
					}
				},
				"variables": {
					"Mailer": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Growth Factor"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-18T07:34:01Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Watermark')]",
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASYN_GrowthFactorAnalysis')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASQL_GrowthFactorSource')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_GrowthFactorDestination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_DataLoadGrowthFactorAnalysisIncremental')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_ForEach_SourceTables_Incremental",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_Incremental_Config",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('ACT_Lookup_Incremental_Config').output.value",
								"type": "Expression"
							},
							"batchCount": 6,
							"activities": [
								{
									"name": "ACT_Copy_SourceDataIncremental",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "AzureSqlSource",
											"sqlReaderQuery": {
												"value": "@{item().Query} @{item().TableName} where CONVERT(DATE,@{item().ColumnName}) > ='@{item().LowerWaterMarkValue}' and CONVERT(DATE,@{item().ColumnName}) <'@{item().UpperWaterMarkValue}'",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "SqlDWSink",
											"preCopyScript": {
												"value": "@{concat('TRUNCATE TABLE ',item().TableName,'_incremental')}",
												"type": "Expression"
											},
											"disableMetricsCollection": false
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "DS_ASQL_GrowthFactorSource",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DS_ASYN_GrowthFactorDestination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": {
													"value": "@concat(split(string(item().TableName),'.')[1],'_incremental')",
													"type": "Expression"
												},
												"SinkSchemaName": {
													"value": "@split(string(item().TableName),'.')[0]",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "ACT_StoredProc_UpdateWaterMark",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [
										{
											"activity": "ACT_Copy_SourceDataIncremental",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[[dbo].[usp_UpdateWatermarkTable_incremental]",
										"storedProcedureParameters": {
											"LastModifiedtime": {
												"value": {
													"value": "@item().UpperWaterMarkValue",
													"type": "Expression"
												},
												"type": "DateTime"
											},
											"TableName": {
												"value": {
													"value": "@item().TableName",
													"type": "Expression"
												},
												"type": "String"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "LS_ASYN_GrowthFactorAnalysis",
										"type": "LinkedServiceReference"
									}
								},
								{
									"name": "ACT_Web_SendEmail_CopyFailure",
									"type": "WebActivity",
									"dependsOn": [
										{
											"activity": "ACT_Copy_SourceDataIncremental",
											"dependencyConditions": [
												"Failed"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": true
									},
									"userProperties": [],
									"typeProperties": {
										"url": {
											"value": "@pipeline().parameters.URL",
											"type": "Expression"
										},
										"connectVia": {
											"referenceName": "AutoResolveIntegrationRuntime",
											"type": "IntegrationRuntimeReference"
										},
										"method": "POST",
										"headers": {
											"Content-Type": "application/json"
										},
										"body": {
											"value": "{\n   \"DataFactoryName\": \"@{pipeline().DataFactory}\",\n   \"PipelineName\": \"@{pipeline().Pipeline}\",\n   \"Subject\": \"Pipeline failed\",\n   \"ErrorMessage\": \"@{activity('ACT_Copy_SourceDataIncremental').Error.message}\",\n   \"EmailTo\": @{pipeline().parameters.EmailId}\n}\t\t",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "ACT_Lookup_Incremental_Config",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": "SELECT TableName,ColumnName,LowerWatermarkValue,UpperWatermarkValue,IsActive,Query FROM [dbo].[Watermark_incremental] WHERE IsActive = 1",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Watermark",
								"type": "DatasetReference",
								"parameters": {
									"DBName": "GrowthFactordev"
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ACT_Execute_Model",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ACT_ConsolidatedBillingDataInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedAppOpenedDataInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedCardViewedInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedOrderCompletedInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedDeliveryRatingInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedProductAddedInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedPointsRedeemedInc",
								"dependencyConditions": [
									"Completed"
								]
							},
							{
								"activity": "ACT_StoredProc_ConsolidatedPointsActivityInc",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_OperationalizeModel",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"IsTraining": {
									"value": "@pipeline().parameters.IsTraining",
									"type": "Expression"
								},
								"StorageAccountName": {
									"value": "@pipeline().parameters.StorageAccountName",
									"type": "Expression"
								},
								"databaseName": {
									"value": "@pipeline().parameters.databaseName",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "ACT_StoredProc_TransformFacturasBEES_Historico_Inc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_CreateNewFacturasBEES_HistoricoTable_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_ConsolidatedBillingDataInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_StoredProc_TransformFacturasBEES_Historico_Inc",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadBillingData_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedAppOpenedDataInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadAppOpened_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedPointsActivityInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadPointsActivity_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedPointsRedeemedInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadPointsRedeemed_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedProductAddedInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadProductAddedDataset_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedOrderCompletedInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadOrderCompletedDataset_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedDeliveryRatingInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadDeliveryRating_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_StoredProc_ConsolidatedCardViewedInc",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_LoadCardViewedDataset_incremental]"
						},
						"linkedServiceName": {
							"referenceName": "LS_ASYN_GrowthFactorAnalysis",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "ACT_Web_SendEmail_LookUpIncrementalFailure",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_Incremental_Config",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": true
						},
						"userProperties": [],
						"typeProperties": {
							"url": {
								"value": "@pipeline().parameters.URL",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"method": "POST",
							"headers": {
								"Content-Type": "application/json"
							},
							"body": {
								"value": "{\n   \"DataFactoryName\": \"@{pipeline().DataFactory}\",\n   \"PipelineName\": \"@{pipeline().Pipeline}\",\n   \"Subject\": \"Pipeline failed\",\n   \"ErrorMessage\": \"@{activity('ACT_Lookup_Incremental_Config').Error.message}\",\n   \"EmailTo\": @{pipeline().parameters.EmailId}\n}\t\t",
								"type": "Expression"
							}
						}
					},
					{
						"name": "ACT_Web_SendEmail_Model",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "ACT_Execute_Model",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": true
						},
						"userProperties": [],
						"typeProperties": {
							"url": {
								"value": "@pipeline().parameters.URL",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"method": "POST",
							"headers": {
								"Content-Type": "application/json"
							},
							"body": {
								"value": "{\n   \"DataFactoryName\": \"@{pipeline().DataFactory}\",\n   \"PipelineName\": \"@{pipeline().Pipeline}\",\n   \"Subject\": \"Model failed\",\n   \"ErrorMessage\": \"@{activity('ACT_Execute_Model').Error.message}\",\n   \"EmailTo\": @{pipeline().parameters.EmailId}\n}\t\t",
								"type": "Expression"
							}
						}
					}
				],
				"parameters": {
					"EmailId": {
						"type": "string",
						"defaultValue": "\"Sashank.Datla-ext@ab-inbev.com\""
					},
					"URL": {
						"type": "string",
						"defaultValue": "https://prod-45.westeurope.logic.azure.com:443/workflows/4905946b127e4764bcc54d100c08385d/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=BVar7ak17GZOQXkJ3TGWqs_4EAPlnAX-fuzQETxBAaw"
					},
					"StorageAccountName": {
						"type": "string",
						"defaultValue": "abigrowthfactoradls"
					},
					"IsTraining": {
						"type": "string",
						"defaultValue": "False"
					},
					"databaseName": {
						"type": "string",
						"defaultValue": "growthfactordev"
					}
				},
				"folder": {
					"name": "Growth Factor"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-18T07:34:08Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Watermark')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_OperationalizeModel')]",
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASYN_GrowthFactorAnalysis')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASQL_GrowthFactorSource')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_GrowthFactorDestination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_JOB_END')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_SP_UpdateJobRun",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_UpdateJobStatus",
							"storedProcedureParameters": {
								"BATCH_RUN_ID": {
									"value": {
										"value": "@pipeline().parameters.BATCH_RUN_ID",
										"type": "Expression"
									},
									"type": "String"
								},
								"CURRENT_USER": {
									"value": {
										"value": "@pipeline().parameters.CURRENT_USER",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_ID": {
									"value": {
										"value": "@pipeline().parameters.JOB_RUN_ID",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_SOURCE_COUNT": {
									"value": {
										"value": "@pipeline().parameters.JOB_RUN_SOURCE_COUNT",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_TARGET_COUNT": {
									"value": {
										"value": "@pipeline().parameters.JOB_RUN_TARGET_COUNT",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_UPD_GMT_TS": {
									"value": {
										"value": "@{formatDateTime(pipeline().TriggerTime,'yyyyMMddhhmmss')}",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"JOB_RUN_ID": {
						"type": "string",
						"defaultValue": "202101280727411"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202101280726331"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseUser"
					},
					"JOB_RUN_SOURCE_COUNT": {
						"type": "string"
					},
					"JOB_RUN_TARGET_COUNT": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ABC Framework"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_JOB_ERROR')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_SP_UpdateJobRun",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Act_Lookup_Job_RunId",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_UpdateJobErrorStatus",
							"storedProcedureParameters": {
								"BATCH_RUN_ID": {
									"value": {
										"value": "@pipeline().parameters.BATCH_RUN_ID",
										"type": "Expression"
									},
									"type": "String"
								},
								"CURRENT_USER": {
									"value": {
										"value": "@pipeline().parameters.CURRENT_USER",
										"type": "Expression"
									},
									"type": "String"
								},
								"ERROR_MSG": {
									"value": {
										"value": "@pipeline().parameters.ERROR_MSG",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_ID": {
									"value": {
										"value": "@{activity('Act_Lookup_Job_RunId').output.firstRow.JOB_RUN_ID}",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_UPD_GMT_TS": {
									"value": {
										"value": "@{formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss')}",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_RunId",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME =  '@{pipeline().parameters.JOB_NAME}' AND BATCH_RUN_ID = @{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_run_stats",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "PL_BATCH_ERROR",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ACT_SP_UpdateJobRun",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_BATCH_COMPLETE",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"BatchStatus": "ERROR"
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"JOB_NAME": {
						"type": "string",
						"defaultValue": "job_rosetta_load"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202101280726331"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseUser"
					},
					"ERROR_MSG": {
						"type": "string",
						"defaultValue": "Default error"
					}
				},
				"folder": {
					"name": "ABC Framework"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_BATCH_COMPLETE')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_JOB_START')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Act_Lookup_Job_Id",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT JOB_ID AS JOB_ID FROM dbo.ABI_JOB_MD WHERE JOB_NAME =  '@{pipeline().parameters.JOB_NAME}'",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_run_stats",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "ACT_SP_InsertJobRun",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Act_Lookup_Job_Id",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_InsertJobStatus",
							"storedProcedureParameters": {
								"BATCH_RUN_ID": {
									"value": {
										"value": "@pipeline().parameters.BATCH_RUN_ID",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_ID": {
									"value": {
										"value": "@{activity('Act_Lookup_Job_Id').output.firstRow.JOB_ID}",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_CREATED_BY": {
									"value": {
										"value": "@{pipeline().parameters.CURRENT_USER}",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_ID": {
									"value": {
										"value": "@{concat(formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss'),activity('Act_Lookup_Job_Id').output.firstRow.JOB_ID)}",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_RUN_INS_GMT_TS": {
									"value": {
										"value": "@{formatDateTime(pipeline().TriggerTime,'yyyyMMddHHmmss')}",
										"type": "Expression"
									},
									"type": "String"
								},
								"JOB_NAME": {
									"value": {
										"value": "@pipeline().parameters.JOB_NAME",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"JOB_NAME": {
						"type": "string",
						"defaultValue": "job_cip_load"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "'batch_BrandHarmonization'"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "'synapseUser'"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					}
				},
				"folder": {
					"name": "ABC Framework"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_Load_BHConfig')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "PL_JOB_START_BHConfig",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": {
									"value": "@pipeline().parameters.JOB_NAME",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END_BHConfig",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Act_Lookup_Job_Run_Id_BHConfig",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "ACT_ForEach_CopyConfig",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_BHConfig').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_BHConfig",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_BHConfig",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = '@{pipeline().parameters.JOB_NAME}' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID = @{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "ACT_ForEach_CopyConfig",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_BHConfig",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@variables('FileNameConfiguration')",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "ACT_Copy_Config",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "JsonSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": true,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "JsonReadSettings"
											}
										},
										"sink": {
											"type": "SqlDWSink",
											"preCopyScript": {
												"value": "TRUNCATE TABLE dbo.@{item().TableName}",
												"type": "Expression"
											},
											"disableMetricsCollection": false
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "DS_Lookup_BHConfig",
											"type": "DatasetReference",
											"parameters": {
												"FileName": {
													"value": "@item().FileName",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "DS_ASYN_GrowthFactorDestination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": {
													"value": "@item().TableName",
													"type": "Expression"
												},
												"SinkSchemaName": "dbo"
											}
										}
									]
								}
							]
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseuser"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					},
					"JOB_NAME": {
						"type": "string",
						"defaultValue": "job_config_load"
					}
				},
				"variables": {
					"FileNameConfiguration": {
						"type": "Array",
						"defaultValue": [
							{
								"FileName": "BrandHarmonizationDataLoadConfiguration.json",
								"TableName": "BrandManagerDataLoadConfiguration"
							},
							{
								"FileName": "DataScienceModelConfiguration.json",
								"TableName": "DataScienceModelConfiguration"
							},
							{
								"FileName": "DataScienceScoreConfiguration.json",
								"TableName": "DataScienceScoreConfiguration"
							}
						]
					}
				},
				"folder": {
					"name": "Brand Harmonization"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/datasets/DS_Lookup_BHConfig')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_GrowthFactorDestination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_Load_CIP')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pipeline for data copy activity from MYSQL tables used for Brand Harmonization",
				"activities": [
					{
						"name": "ACT_Lookup_Incremental_Config",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_Cip",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": "SELECT TableName,IncrementalColumnName,IsActive,ColumnsList FROM [dbo].[DataSourceLoadConfiguration] WHERE IsActive = 1 AND [Source] = 'CIP'",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Watermark",
								"type": "DatasetReference",
								"parameters": {
									"DBName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ACT_ForEach_SourceTables_Incremental",
						"description": "Iterate all the source tables",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_Incremental_Config",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('ACT_Lookup_Incremental_Config').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "ACT_Copy_SourceDataIncremental",
									"description": "This activity copies data from MYSQL db to synapse SQL. It is incremental load pipeline",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "MySqlSource",
											"query": {
												"value": "@if(empty(item().IncrementalColumnName),concat('SELECT ',item().ColumnsList,' FROM ', item().TableName),concat('SELECT ',item().ColumnsList,' FROM ', item().TableName,' ',' where ',item().IncrementalColumnName,' >= ''',formatDateTime(getPastTime(1,'Month'),'yyyy-MM-dd'),''' and ',item().IncrementalColumnName,' < ''',formatDateTime(pipeline().TriggerTime,'yyyy-MM-dd'),''''))",
												"type": "Expression"
											}
										},
										"sink": {
											"type": "SqlDWSink",
											"preCopyScript": {
												"value": "@{concat('TRUNCATE TABLE ',if(empty(item().IncrementalColumnName),item().TableName,concat(item().TableName,'_incremental')))}",
												"type": "Expression"
											},
											"disableMetricsCollection": false
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "DS_MYSQL_BrandHarmonization",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DS_ASYN_Destination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": {
													"value": "@if(empty(item().IncrementalColumnName),split(string(item().TableName),'.')[1],concat(split(string(item().TableName),'.')[1],'_incremental'))",
													"type": "Expression"
												},
												"SinkSchemaName": {
													"value": "@split(string(item().TableName),'.')[0]",
													"type": "Expression"
												},
												"SQLPoolName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "ACT_If_isIncrementalTable",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "ACT_Copy_SourceDataIncremental",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@not(empty(item().IncrementalColumnName))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "ACT_StoredProc_UpdateWaterMark",
												"type": "SqlServerStoredProcedure",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"storedProcedureName": "[[dbo].[usp_BHUpdateWatermarkTable_incremental]",
													"storedProcedureParameters": {
														"UpperWaterMark": {
															"value": {
																"value": "@formatDateTime(pipeline().TriggerTime,'yyyy-MM-dd')",
																"type": "Expression"
															},
															"type": "DateTime"
														},
														"TableName": {
															"value": {
																"value": "@item().TableName",
																"type": "Expression"
															},
															"type": "String"
														},
														"LowerWaterMark": {
															"value": {
																"value": "@formatDateTime(getPastTime(1,'Month'),'yyyy-MM-dd')",
																"type": "Expression"
															},
															"type": "Datetime"
														}
													}
												},
												"linkedServiceName": {
													"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
													"type": "LinkedServiceReference",
													"parameters": {
														"DBName": {
															"value": "@pipeline().parameters.DBName",
															"type": "Expression"
														}
													}
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "PL_JOB_START_Cip",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_cip_load",
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END_Cip",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Act_Lookup_Job_Run_Id_Extraction_Cip",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_Extraction_Cip').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_Extraction_Cip",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_Cip",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = 'job_cip_load' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID = @{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "growthfactordev"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseuser"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					}
				},
				"variables": {
					"test": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Brand Harmonization/CIP"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-03T11:15:49Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Watermark')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/datasets/DS_MYSQL_BrandHarmonization')]",
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_Load_Rosetta')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pipeline for data copy activity from SQL -Data source: Rosetta",
				"activities": [
					{
						"name": "ACT_Lookup_Incremental_Config",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_Rosetta",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": "SELECT TableName,IncrementalColumnName,IsActive,ColumnsList FROM [dbo].[DataSourceLoadConfiguration] WHERE IsActive = 1 AND [Source] = 'rosetta'",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Watermark",
								"type": "DatasetReference",
								"parameters": {
									"DBName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ACT_ForEach_SourceTables_Incremental",
						"description": "Iterate all the source tables",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ACT_Lookup_Incremental_Config",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('ACT_Lookup_Incremental_Config').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "ACT_Copy_SourceDataIncremental",
									"description": "This activity copies data from MYSQL db to synapse SQL. It is incremental load pipeline",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "AzureSqlSource",
											"sqlReaderQuery": {
												"value": "@if(empty(item().IncrementalColumnName),concat('SELECT ',item().ColumnsList,' FROM ', item().TableName),concat('SELECT ',item().ColumnsList,' FROM ', item().TableName,' ',' where ',item().IncrementalColumnName,' >= ''',formatDateTime(getPastTime(1,'Month'),'yyyy-MM-dd'),''' and ',item().IncrementalColumnName,' < ''',formatDateTime(pipeline().TriggerTime,'yyyy-MM-dd'),''''))",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "SqlDWSink",
											"preCopyScript": {
												"value": "@{concat('TRUNCATE TABLE ',if(empty(item().IncrementalColumnName),item().TableName,concat(item().TableName,'_incremental')))}",
												"type": "Expression"
											},
											"tableOption": "autoCreate",
											"disableMetricsCollection": false
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "DS_ASQL_RosettaSource",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DS_ASYN_Destination",
											"type": "DatasetReference",
											"parameters": {
												"SinkTableName": {
													"value": "@if(empty(item().IncrementalColumnName),split(string(item().TableName),'.')[1],concat(split(string(item().TableName),'.')[1],'_incremental'))",
													"type": "Expression"
												},
												"SinkSchemaName": {
													"value": "@split(string(item().TableName),'.')[0]",
													"type": "Expression"
												},
												"SQLPoolName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "ACT_If_isIncrementalTable",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "ACT_Copy_SourceDataIncremental",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@not(empty(item().IncrementalColumnName))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "ACT_StoredProc_UpdateWaterMark",
												"type": "SqlServerStoredProcedure",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"storedProcedureName": "[[dbo].[usp_BHUpdateWatermarkTable_incremental]",
													"storedProcedureParameters": {
														"LowerWaterMark": {
															"value": {
																"value": "@formatDateTime(getPastTime(1,'Month'),'yyyy-MM-dd')",
																"type": "Expression"
															},
															"type": "DateTime"
														},
														"TableName": {
															"value": {
																"value": "@item().TableName",
																"type": "Expression"
															},
															"type": "String"
														},
														"UpperWaterMark": {
															"value": {
																"value": "@formatDateTime(pipeline().TriggerTime,'yyyy-MM-dd')",
																"type": "Expression"
															},
															"type": "DateTime"
														}
													}
												},
												"linkedServiceName": {
													"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
													"type": "LinkedServiceReference",
													"parameters": {
														"DBName": {
															"value": "@pipeline().parameters.DBName",
															"type": "Expression"
														}
													}
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "PL_JOB_START_Rosetta",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_rosetta_load",
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END_Rosetta",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ACT_ForEach_SourceTables_Incremental",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Act_Lookup_Job_Run_Id_Extraction_Rosetta",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_Extraction_Rosetta').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_Extraction_Rosetta",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_Rosetta",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = 'job_rosetta_load' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID =@{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapse user"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					}
				},
				"variables": {
					"test": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Brand Harmonization/Rosetta"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-03T11:15:49Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Watermark')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASQL_RosettaSource')]",
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_Master_BrandHarmonization')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "PL_BATCH_INITIATE",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_BATCH_INITIATE",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_BATCH_COMPLETE",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Process_ModelOutput",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_BATCH_COMPLETE",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"BatchStatus": "COMPLETED"
							}
						}
					},
					{
						"name": "LOOKUP_BATCH_RUN_ID",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_BATCH_INITIATE",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(BATCH_RUN_ID) AS BATCH_RUN_ID FROM dbo.ABI_BATCH_RUN_STATS WHERE BATCH_NAME = '@{pipeline().parameters.BATCH_NAME}' AND BATCH_STATUS = 'STARTED'",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					},
					{
						"name": "PL_Load_CIP",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "LOOKUP_BATCH_RUN_ID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_Load_CIP",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_Load_Rosetta",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "LOOKUP_BATCH_RUN_ID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_Load_Rosetta",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_Load_DSConfig",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "LOOKUP_BATCH_RUN_ID",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_Load_BHConfig",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"JOB_NAME": "job_config_load"
							}
						}
					},
					{
						"name": "PL_DataScienceModel",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Model_Prep",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_BH_Model",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_Model_Prep",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Load_CIP",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "PL_Load_Rosetta",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "PL_Load_DSConfig",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_Model_Preparation",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_model_preparation",
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_Process_ModelOutput",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_DataScienceModel",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_Process_ModelOutput",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"JOB_NAME": "job_model_output",
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_CIP_ERROR",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Load_CIP",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_ERROR",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_cip_load",
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"ERROR_MSG": {
									"value": "@activity('PL_Load_CIP').error.message",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_DSConfig_ERROR",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Load_DSConfig",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_ERROR",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_config_load",
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"ERROR_MSG": {
									"value": "@activity('PL_Load_DSConfig').error.message",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_Rosetta_ERROR",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Load_Rosetta",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_ERROR",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_rosetta_load",
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"ERROR_MSG": {
									"value": "@activity('PL_Load_Rosetta').error.message",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_DS_Model_ERROR",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_DataScienceModel",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_ERROR",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_dsmodel_execution",
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"ERROR_MSG": {
									"value": "@activity('PL_DataScienceModel').error.message",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_ProcessModelOutput_ERROR",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "PL_Process_ModelOutput",
								"dependencyConditions": [
									"Failed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_ERROR",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": "job_model_prep",
								"BATCH_RUN_ID": {
									"value": "@activity('LOOKUP_BATCH_RUN_ID').output.firstRow.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"ERROR_MSG": {
									"value": "activity('PL_Process_ModelOutput').error.message",
									"type": "Expression"
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseuser"
					}
				},
				"folder": {
					"name": "Brand Harmonization"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL_BATCH_INITIATE')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_BATCH_COMPLETE')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_Load_CIP')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_Load_Rosetta')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_Load_BHConfig')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_BH_Model')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_Model_Preparation')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_Process_ModelOutput')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_ERROR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_Model_Preparation')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_SP_LoadIntermediateTable",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_ModelPrep",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_CreateIntermediateTableForDS",
							"storedProcedureParameters": {
								"SourceSystem": {
									"value": "CIP",
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "ACT_SP_BrandMasterConsolidated",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_ModelPrep",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_LoadBHConsolidatedTable "
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_START_ModelPrep",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": {
									"value": "@pipeline().parameters.JOB_NAME",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END_ModelPrep",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "ACT_SP_BrandMasterConsolidated",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "ACT_SP_LoadIntermediateTable",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Act_Lookup_Job_Run_Id_BHConfig",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_BHConfig').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_BHConfig",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_ModelPrep",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = '@{pipeline().parameters.JOB_NAME}' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID = @{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "growthfactordev"
					},
					"JOB_NAME": {
						"type": "string",
						"defaultValue": "job_model_preparation"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseuser"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202102020627201"
					}
				},
				"folder": {
					"name": "Brand Harmonization"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_OperationalizeModel')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ModelExecution_ExportPredictions",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "ModelExecution_FeatureEngineering",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "ml_export_predictions",
								"type": "NotebookReference"
							},
							"parameters": {
								"isTraining": {
									"value": {
										"value": "@pipeline().parameters.IsTraining",
										"type": "Expression"
									},
									"type": "bool"
								},
								"storage_root_path": {
									"value": {
										"value": "@concat('abfss://',pipeline().DataFactory,'@',pipeline().parameters.StorageAccountName,'.dfs.core.windows.net/synapse/workspaces/',pipeline().DataFactory,'/warehouse/')",
										"type": "Expression"
									},
									"type": "string"
								}
							}
						}
					},
					{
						"name": "ModelExecution_FeatureEngineering",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "ModelExecution_ModelLoad",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "ml_feature_engineering",
								"type": "NotebookReference"
							},
							"parameters": {
								"isTraining": {
									"value": {
										"value": "@pipeline().parameters.IsTraining",
										"type": "Expression"
									},
									"type": "bool"
								},
								"delta_path": {
									"value": {
										"value": "@concat('abfss://',pipeline().DataFactory,'@',pipeline().parameters.StorageAccountName,'.dfs.core.windows.net/synapse/workspaces/',pipeline().DataFactory,'/warehouse/')",
										"type": "Expression"
									},
									"type": "string"
								}
							}
						}
					},
					{
						"name": "ModelExecution_ModelLoad",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "ml_data_load",
								"type": "NotebookReference"
							},
							"parameters": {
								"databaseName": {
									"value": {
										"value": "@pipeline().parameters.databaseName",
										"type": "Expression"
									},
									"type": "string"
								},
								"delta_table_path": {
									"value": {
										"value": "@concat('abfss://',pipeline().DataFactory,'@',pipeline().parameters.StorageAccountName,'.dfs.core.windows.net/synapse/workspaces/',pipeline().DataFactory,'/warehouse/')",
										"type": "Expression"
									},
									"type": "string"
								},
								"isTraining": {
									"value": {
										"value": "@pipeline().parameters.IsTraining",
										"type": "Expression"
									},
									"type": "string"
								}
							}
						}
					}
				],
				"parameters": {
					"IsTraining": {
						"type": "string",
						"defaultValue": "False"
					},
					"StorageAccountName": {
						"type": "string",
						"defaultValue": "abigrowthfactoradls"
					},
					"databaseName": {
						"type": "string",
						"defaultValue": "growthfactordev"
					}
				},
				"folder": {
					"name": "Growth Factor"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-18T07:33:54Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/ml_export_predictions')]",
				"[concat(variables('workspaceId'), '/notebooks/ml_feature_engineering')]",
				"[concat(variables('workspaceId'), '/notebooks/ml_data_load')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_Process_ModelOutput')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ACT_SP_LoadActionLog",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_ModelOutput",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "dbo.usp_LoadActionLog"
						},
						"linkedServiceName": {
							"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
							"type": "LinkedServiceReference",
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_START_ModelOutput",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_START",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_NAME": {
									"value": "@pipeline().parameters.JOB_NAME",
									"type": "Expression"
								},
								"BATCH_NAME": {
									"value": "@pipeline().parameters.BATCH_NAME",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "PL_JOB_END_BHConfig",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Act_Lookup_Job_Run_Id_ModelOutput",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "ACT_SP_LoadActionLog",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL_JOB_END",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"DBName": {
									"value": "@pipeline().parameters.DBName",
									"type": "Expression"
								},
								"JOB_RUN_ID": {
									"value": "@activity('Act_Lookup_Job_Run_Id_ModelOutput').output.firstRow.JOB_RUN_ID",
									"type": "Expression"
								},
								"BATCH_RUN_ID": {
									"value": "@pipeline().parameters.BATCH_RUN_ID",
									"type": "Expression"
								},
								"CURRENT_USER": {
									"value": "@pipeline().parameters.CURRENT_USER",
									"type": "Expression"
								}
							}
						}
					},
					{
						"name": "Act_Lookup_Job_Run_Id_ModelOutput",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "PL_JOB_START_ModelOutput",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "SELECT MAX(JOB_RUN_ID) AS JOB_RUN_ID FROM dbo.ABI_JOB_RUN_STATS WHERE JOB_NAME = '@{pipeline().parameters.JOB_NAME}' AND JOB_RUN_STATUS = 'STARTED' AND BATCH_RUN_ID = @{pipeline().parameters.BATCH_RUN_ID}",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "DS_ASYN_Destination",
								"type": "DatasetReference",
								"parameters": {
									"SinkTableName": "abi_job_md",
									"SinkSchemaName": "dbo",
									"SQLPoolName": {
										"value": "@pipeline().parameters.DBName",
										"type": "Expression"
									}
								}
							}
						}
					}
				],
				"parameters": {
					"DBName": {
						"type": "string",
						"defaultValue": "GrowthFactorDev"
					},
					"BATCH_RUN_ID": {
						"type": "string",
						"defaultValue": "202101280726331"
					},
					"CURRENT_USER": {
						"type": "string",
						"defaultValue": "synapseUser"
					},
					"JOB_NAME": {
						"type": "string",
						"defaultValue": "job_model_prep"
					},
					"BATCH_NAME": {
						"type": "string",
						"defaultValue": "batch_BrandHarmonization"
					}
				},
				"folder": {
					"name": "Brand Harmonization"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_START')]",
				"[concat(variables('workspaceId'), '/pipelines/PL_JOB_END')]",
				"[concat(variables('workspaceId'), '/datasets/DS_ASYN_Destination')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL_ScaleUp')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Web1",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"url": "https://management.azure.com/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Sql/servers/globalbrewdatsynapsegbdev/databases/growthfactordev?api-version=2019-06-01-preview",
							"connectVia": {
								"referenceName": "AutoResolveIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"method": "PUT",
							"headers": {
								"Content-Type": "application/json"
							},
							"body": {
								"value": "json({\"sku\":{\"name\":\"DW200c\"}, \"location\": \"West Europe\"})",
								"type": "Expression"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://management.azure.com/"
							}
						}
					}
				],
				"folder": {
					"name": "Growth Factor"
				},
				"annotations": [],
				"lastPublishTime": "2020-12-18T07:34:03Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ADLS_ForecastSource')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ADLS_SourceForecast",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Forecasting",
						"fileSystem": "dataarchitecture"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ADLS_SourceForecast')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ADLS_SourceStagingTables')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"CountryName": {
						"type": "string"
					},
					"FileName": {
						"type": "string"
					},
					"SheetName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": {
						"value": "@dataset().SheetName",
						"type": "Expression"
					},
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().CountryName",
							"type": "Expression"
						},
						"fileSystem": "forecasting"
					},
					"firstRowAsHeader": true
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASQL_GrowthFactorSource')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ASQL_GrowthFactorAnalysis",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASQL_GrowthFactorAnalysis')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASQL_RosettaSource')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ASQL_RosettaSource",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASQL_RosettaSource')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_Destination')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": {
							"value": "@dataset().SQLPoolName",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"SinkTableName": {
						"type": "string"
					},
					"SinkSchemaName": {
						"type": "string"
					},
					"SQLPoolName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().SinkSchemaName",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().SinkTableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_ForecastSource')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ADLS_SourceForecast",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Country": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().Country",
							"type": "Expression"
						},
						"fileSystem": "dataarchitecture/Forecasting"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ADLS_SourceForecast')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_ForecastTable')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": {
							"value": "@dataset().DatabaseName",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"TableName": {
						"type": "string"
					},
					"TableSchema": {
						"type": "string"
					},
					"DatabaseName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().TableSchema",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().TableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_GrowthFactorDestination')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ASYN_GrowthFactorAnalysis",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"SinkTableName": {
						"type": "string"
					},
					"SinkSchemaName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().SinkSchemaName",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().SinkTableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASYN_GrowthFactorAnalysis')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_RosettaTarget')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ASYN_RosettaTarget",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"SchemaName": {
						"type": "string"
					},
					"TableName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().SchemaName",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().TableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASYN_RosettaTarget')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_Watermark')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": {
							"value": "@dataset().DBName",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"DBName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "TableName",
						"type": "varchar"
					},
					{
						"name": "IsActive",
						"type": "bit"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Watermark"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_ASYN_WatermarkIncremental')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_ASYN_GrowthFactorAnalysis",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "TableName",
						"type": "varchar"
					},
					{
						"name": "ColumnName",
						"type": "varchar"
					},
					{
						"name": "LowerWaterMarkValue",
						"type": "date"
					},
					{
						"name": "UpperWaterMarkValue",
						"type": "date"
					},
					{
						"name": "IsActive",
						"type": "bit"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Watermark_incremental"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_ASYN_GrowthFactorAnalysis')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_GetMetaDataTargetForecasting')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileSystem": "forecasting"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_LookUp_Names')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"fileSystem": "config"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_Lookup_BHConfig')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileName": {
						"type": "string",
						"defaultValue": "BrandHarmonizationDataLoadConfiguration.json"
					}
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": "BrandHarmonizationConfig",
						"fileSystem": "config"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"Source": {
							"type": "string"
						},
						"LowThreshold": {
							"type": "string"
						},
						"HighThreshold": {
							"type": "string"
						},
						"Description": {
							"type": "string"
						},
						"UpdatedBy": {
							"type": "string"
						},
						"UpdatedDate": {
							"type": "string"
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_MYSQL_BrandHarmonization')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LS_MySQL_BrandHarmonization",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "MySqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LS_MySQL_BrandHarmonization')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DS_TargetSynapse_Forecasting')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "globalbrewdatsynapsegbdev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Country": {
						"type": "string"
					},
					"Path": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().Country",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Path",
							"type": "Expression"
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/globalbrewdatsynapsegbdev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LS_ADLS_SourceForecast')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('LS_ADLS_SourceForecast_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('LS_ADLS_SourceForecast_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LS_ASQL_GrowthFactorAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Azure sql db for loading billing and segment data",
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('LS_ASQL_GrowthFactorAnalysis_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LS_ASQL_RosettaSource')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('LS_ASQL_RosettaSource_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LS_ASYN_GrowthFactorAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "server details of azure synapse workspace",
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('LS_ASYN_GrowthFactorAnalysis_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LS_ASYN_RosettaTarget')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('LS_ASYN_RosettaTarget_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LS_MySQL_BrandHarmonization')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "connection to MYSQL database",
				"annotations": [],
				"type": "MySql",
				"typeProperties": {
					"connectionString": "[parameters('LS_MySQL_BrandHarmonization_connectionString')]"
				},
				"connectVia": {
					"referenceName": "MYSQLIR",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/MYSQLIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PowerBIWorkspaceDev')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "a45bf0aa-b435-4958-9594-81795a6e5868",
					"tenantID": "cef04b19-7776-4a94-b89b-375c77a8f936"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('globalbrewdatsynapsegbdev-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/globalbrewdatsynapsegbdev-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('globalbrewdatsynapsegbdev-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TRIGGER_BH_ActionLog')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "PL_ActionLog_Feedback",
							"type": "PipelineReference"
						},
						"parameters": {
							"DBName": "[parameters('TRIGGER_BH_ActionLog_properties_PL_ActionLog_Feedback_parameters_DBName')]",
							"BATCH_NAME": "[parameters('TRIGGER_BH_ActionLog_properties_PL_ActionLog_Feedback_parameters_BATCH_NAME')]",
							"CURRENT_USER": "[parameters('TRIGGER_BH_ActionLog_properties_PL_ActionLog_Feedback_parameters_CURRENT_USER')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Hour",
						"interval": 1,
						"startTime": "2021-02-05T03:56:00Z",
						"timeZone": "UTC"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL_ActionLog_Feedback')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TRIGGER_BrandHarmonization')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "PL_Master_BrandHarmonization",
							"type": "PipelineReference"
						},
						"parameters": {
							"DBName": "[parameters('TRIGGER_BrandHarmonization_properties_PL_Master_BrandHarmonization_parameters_DBName')]",
							"BATCH_NAME": "[parameters('TRIGGER_BrandHarmonization_properties_PL_Master_BrandHarmonization_parameters_BATCH_NAME')]",
							"CURRENT_USER": "[parameters('TRIGGER_BrandHarmonization_properties_PL_Master_BrandHarmonization_parameters_CURRENT_USER')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Month",
						"interval": 1,
						"startTime": "2021-02-05T06:23:00Z",
						"timeZone": "UTC",
						"schedule": {
							"monthDays": [
								21
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL_Master_BrandHarmonization')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TRIGGER_Forecasting')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Month",
						"interval": 1,
						"startTime": "2020-12-11T14:38:00",
						"timeZone": "India Standard Time",
						"schedule": {
							"minutes": [
								30
							],
							"hours": [
								0
							],
							"monthDays": [
								3
							]
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TRIGGER_GrowthFactor_Incremental')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "PL_DataLoadGrowthFactorAnalysisIncremental",
							"type": "PipelineReference"
						},
						"parameters": {
							"EmailId": "[parameters('TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_EmailId')]",
							"URL": "[parameters('TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_URL')]",
							"StorageAccountName": "[parameters('TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_StorageAccountName')]",
							"IsTraining": "[parameters('TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_IsTraining')]",
							"databaseName": "[parameters('TRIGGER_GrowthFactor_Incremental_properties_PL_DataLoadGrowthFactorAnalysisIncremental_parameters_databaseName')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Month",
						"interval": 1,
						"startTime": "2020-12-01T05:15:00",
						"timeZone": "India Standard Time",
						"schedule": {
							"minutes": [
								30
							],
							"hours": [
								0
							],
							"monthDays": [
								5
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL_DataLoadGrowthFactorAnalysisIncremental')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MYSQLIR')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_brand_matching_framework')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"language_info": {
						"name": "scala"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112,
						"extraHeader": {},
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"import os\n",
							"import pandas as pd\n",
							"import numpy as np\n",
							"from pandas import DataFrame\n",
							"from fuzzywuzzy import fuzz\n",
							"from pyspark.sql.functions import *\n",
							"import warnings\n",
							"warnings.filterwarnings(\"ignore\")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "scala",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"val db_path =\"GrowthFactorDev\""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"val brandmarket_table_name = db_path + \".dbo.BrandMasterDataConsolidated\"\n",
							"val cip_file_line_error_table_name = db_path + \".jobs.cip_file_line_error_intermediate\"\n",
							"val ds_model_config_table_name = db_path + \".dbo.DataScienceModelConfiguration\"\n",
							"val bm_action_config_table_name = db_path +\".dbo.BrandManagerDataLoadConfiguration\"\n",
							"val ds_model_score_config_table_name = db_path +\".dbo.DataScienceScoreConfiguration\"\n",
							"val brand_matching_summary_table_name = db_path + \".dbo.brand_matching_summary\"\n",
							"val brand_matching_performance_table_name = db_path + \".dbo.brand_matching_performance\""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"// scala library imports\n",
							"import org.apache.spark.sql.types._\n",
							"import org.apache.spark.sql._\n",
							"import org.apache.spark.sql.SqlAnalyticsConnector._\n",
							"import org.apache.spark._\n",
							"import org.apache.spark.sql.functions._"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"val brandmarket_df = spark.read.sqlanalytics(brandmarket_table_name)\n",
							"brandmarket_df.createOrReplaceTempView(\"brandmarket\")\n",
							"\n",
							"val cip_file_line_error_df = spark.read.sqlanalytics(cip_file_line_error_table_name)\n",
							"cip_file_line_error_df.createOrReplaceTempView(\"cip_file_line_error_intermediate\")\n",
							"\n",
							"val ds_model_config_df = spark.read.sqlanalytics(ds_model_config_table_name)\n",
							"ds_model_config_df.createOrReplaceTempView(\"ds_matchbrand_configuration\")\n",
							"\n",
							"val bm_action_config_df = spark.read.sqlanalytics(bm_action_config_table_name)\n",
							"bm_action_config_df.createOrReplaceTempView(\"bm_action_matchbrand_configuration\")\n",
							"\n",
							"val model_score_config_df = spark.read.sqlanalytics(ds_model_score_config_table_name)\n",
							"model_score_config_df.createOrReplaceTempView(\"ds_model_score_configuration\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"def read_input_data(table_name):\n",
							"    df = spark.read.table(table_name)\n",
							"    df = df.toPandas()\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"model_config_df = read_input_data(\"ds_matchbrand_configuration\")\n",
							"matching_threshold=model_config_df.iloc[0,3]\n",
							"score_config_df = read_input_data(\"bm_action_matchbrand_configuration\")\n",
							"score_seg_df = read_input_data(\"ds_model_score_configuration\")\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"#Output function\n",
							"def write_output_data(df):\n",
							"    sparkdf = spark.createDataFrame(df)\n",
							"    sparkdf = sparkdf\\\n",
							"        .withColumn('date', current_date())\n",
							"    return sparkdf"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# Master Data Processing\n",
							"def country_master_data(master_data):\n",
							"    master_data=master_data[['BrandName','CountryCode','SourceSystem']]\n",
							"    master_data.rename(columns = {'BrandName':'brand'}, inplace = True)\n",
							"    master_data=master_data.drop_duplicates(subset='brand', keep=\"last\")\n",
							"    return master_data\n",
							"\n",
							"def mbarn_SplCharRemove(mdf):\n",
							"    spec_chars = [\"%\",\"/\",\"'\",\"(\",\")\"]\n",
							"    for char in spec_chars:\n",
							"        mdf['brand'] = mdf['brand'].str.replace(char,'')\n",
							"    return mdf\n",
							"    \n",
							"def mbarn_replace(mdf):\n",
							"    # This function will help to increase confidance scope\n",
							"    mdf[\"brand\"].replace({\"\": \"o\", \"\": \"o\"}, inplace=True)\n",
							"    mdf['brand'].dropna(axis=0, how='all',inplace = True)\n",
							"    return mdf"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# CIP Survey Data Processing\n",
							"\n",
							"def cip_errorlog_processing(error_log):\n",
							"    error_log=error_log.fillna(0)\n",
							"    error_log=error_log.astype({'file_id': 'int', 'severity_id': 'int',\\\n",
							"                                        'row_number': 'int','error_id': 'int'})\n",
							"    error_log= error_log[['survey_type','severity_id','error_id',\\\n",
							"                                  'error_field','error_message',\\\n",
							"                                  'error_description','created_date',\\\n",
							"                                  'country_code']]\n",
							"    error_log= error_log[(error_log.error_field==\"DerievedBrandID\")]\n",
							"    error_log=error_log.loc[0:3999,:]\n",
							"    return error_log"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# CIP Survey Data pre-processing\n",
							"def brand_extraction(processed_data):\n",
							"    processed_data['H_Brand'] = processed_data.\\\n",
							"    loc[processed_data['error_field'].isin(['DerievedBrandID'])]\\\n",
							"            ['error_description'].str.split('-').str[1]        \n",
							"    processed_data['H_Brand'].fillna('',inplace = True)\n",
							"    processed_data['H_Brand'] = processed_data['H_Brand'].astype('str')\n",
							"    return processed_data\n",
							"\n",
							"def garbage_char_remove(logdf):\n",
							"    spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
							"                          \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
							"                          \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
							"                          \"`\",\"{\",\"|\",\"}\",\"~\",\"\"]\n",
							"    for char in spec_chars:\n",
							"        logdf['H_Brand'] = logdf['H_Brand'].str.replace(char,'')\n",
							"    return logdf\n",
							"\n",
							"def remove_spl_char(char_df):\n",
							"    spec_chars = [\"194\",'195',\"MILLER LITE SSNET\",\"Chandon\",\n",
							"                          \"MGD 64\"]\n",
							"        \n",
							"    for char in spec_chars:\n",
							"        char_df['H_Brand'] = char_df['H_Brand'].str.replace(char,'')\n",
							"    return char_df\n",
							"\n",
							"def date_processing(clean_df):\n",
							"    clean_df['created_date'] = pd.to_datetime(clean_df['created_date'], errors='coerce')\n",
							"    clean_df['BH_Year_Month'] = clean_df['created_date'].dt.strftime('%Y-%m')\n",
							"    clean_df['BH_Year'] = clean_df['created_date'].dt.strftime('%Y')\n",
							"    clean_df = clean_df.drop_duplicates(subset='H_Brand', keep=\"first\")\n",
							"    return clean_df"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# Brand Matching Algorithm for the Brand Harmonization issue handling\n",
							"def brand_harmonization(brand_data,BM_master,match_thr,score_seg_df):\n",
							"    matched_brands = []\n",
							"    high_sc=int(score_seg_df.iloc[0,1])\n",
							"    mod_low_sc=int(score_seg_df.iloc[1,1])\n",
							"    mod_high_sc=int(score_seg_df.iloc[1,2])\n",
							"    low_sc=int(score_seg_df.iloc[2,1])\n",
							"    low_high_sc=int(score_seg_df.iloc[2,2])\n",
							"    high=score_seg_df.iloc[0,3]\n",
							"    mod=score_seg_df.iloc[1,3]\n",
							"    low=score_seg_df.iloc[2,3]\n",
							"    vlow=score_seg_df.iloc[3,3]\n",
							"\n",
							"    for row in brand_data.index:\n",
							"        brand_name = brand_data.get_value(row,\"H_Brand\")\n",
							"        brand_name=brand_name.strip()\n",
							"        brand_cc = brand_data.get_value(row,\"country_code\")\n",
							"        for row_label in BM_master.index:\n",
							"            BM_master=BM_master.astype(str)\n",
							"            master_brand_name=BM_master.get_value(row_label,\"brand\") \n",
							"            master_brand_name=master_brand_name.strip()\n",
							"            mbrand_source_name=BM_master.get_value(row_label,\"SourceSystem\")\n",
							"            mbrand_country_name=BM_master.get_value(row_label,\"CountryCode\")\n",
							"            matched_token=fuzz.ratio(brand_name,master_brand_name)\n",
							"            \n",
							"            if matched_token> high_sc:\n",
							"                matched_category= high\n",
							"            elif (matched_token> mod_low_sc and matched_token<mod_high_sc):\n",
							"                matched_category= mod\n",
							"            elif (matched_token> low_sc and matched_token<low_high_sc):\n",
							"                matched_category= low\n",
							"            else:\n",
							"                matched_category= vlow\n",
							"            \n",
							"            if matched_token> match_thr:\n",
							"                matched_brands.append([brand_name,brand_cc,master_brand_name,matched_token,\\\n",
							"                                       matched_category,mbrand_source_name,\\\n",
							"                                       mbrand_country_name])\n",
							"    return matched_brands"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# Brand Matching Algorithm output table formating\n",
							"def output_formating(Brand_Matching,score_config_df):\n",
							"    lst=[]\n",
							"    lsti=[]\n",
							"    lstii=[]\n",
							"    lstsi=[]\n",
							"    lstci=[]\n",
							"    brand_unq=[]\n",
							"    bcc=[]\n",
							"    ls=[]\n",
							"    score_seg = []\n",
							"\n",
							"    NA_low_thr=int(score_config_df.iloc[2,1])\n",
							"    NA_high_thr=int(score_config_df.iloc[2,2])\n",
							"    VR_low_thr=int(score_config_df.iloc[0,1])\n",
							"    VR_high_thr=int(score_config_df.iloc[0,2])\n",
							"    DR_low_thr=int(score_config_df.iloc[1,1])\n",
							"    DR_high_thr=int(score_config_df.iloc[1,2])\n",
							"    NA=score_config_df.iloc[2,3]\n",
							"    VR=score_config_df.iloc[0,3]\n",
							"    DR=score_config_df.iloc[1,3]\n",
							"\n",
							"    for i in Brand_Matching.BH.unique():\n",
							"        agg_bcc=Brand_Matching.loc[Brand_Matching.BH==i, 'brand_cc'].unique().tolist()\n",
							"        agg_brand=Brand_Matching.loc[Brand_Matching.BH==i, 'Matched_Brand'].values.tolist()\n",
							"        agg_score=Brand_Matching.loc[Brand_Matching.BH==i, 'Score'].values.tolist()\n",
							"        agg_scorecat=Brand_Matching.loc[Brand_Matching.BH==i, 'Score_categroty'].values.tolist()\n",
							"        agg_si=Brand_Matching.loc[Brand_Matching.BH==i, 'mSource_info'].values.tolist()\n",
							"        agg_ci=Brand_Matching.loc[Brand_Matching.BH==i, 'mCountry_info'].values.tolist()\n",
							"        \n",
							"        cond1 = True in ((i >= NA_low_thr and i<=NA_high_thr) for i in agg_score) \n",
							"        cond2 = True in ((i >= VR_low_thr and i<VR_high_thr) for i in agg_score) \n",
							"        cond3 = True in ((i >= DR_low_thr and i<DR_high_thr) for i in agg_score) \n",
							"\n",
							"        if(cond1):\n",
							"            action = NA #\"No Action\"\n",
							"        elif (cond2):\n",
							"            action = VR #\"Prediction Validation to be suggested to BM\"\n",
							"        elif (cond3):\n",
							"            action = DR #\"Disregard or suggestion to be made by BM\"\n",
							"        else:\n",
							"            action = \"\"\n",
							"\n",
							"        lst.append(agg_brand)\n",
							"        lsti.append(agg_score)\n",
							"        lstii.append(agg_scorecat)\n",
							"        lstsi.append(agg_si)\n",
							"        lstci.append(agg_ci)\n",
							"        brand_unq.append(i)\n",
							"        bcc.append(agg_bcc)\n",
							"        score_seg.append(action)\n",
							"    \n",
							"    data = {'Brand_Harmonized':brand_unq,'Brand_CC':bcc, 'Matched_Brands[Country]':lst,\\\n",
							"            'Score': lsti,'Score_Category':lstii,'mSource_info':lstsi,'mCountry_info':lstci,\\\n",
							"             'Score_Segmentation': score_seg}\n",
							"    newdf = pd.DataFrame(data)\n",
							"    return newdf\n",
							""
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# Survey-Data pre-processing function call\n",
							"def process_data(brand_error_log):\n",
							"    brand_error_log_final = cip_errorlog_processing(brand_error_log)\n",
							"    brand_ext= brand_extraction(brand_error_log_final)\n",
							"    clean_brand_ext = garbage_char_remove(brand_ext)\n",
							"    clean_brand_df = remove_spl_char(clean_brand_ext)\n",
							"    brand_error_log = date_processing(clean_brand_df)\n",
							"    return brand_error_log, brand_error_log_final"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"#Brand Matching function call\n",
							"def matching_score(bm_master, brand_error_log, matching_thr, score_config_df, score_seg_df):\n",
							"    matched_brands_score = []\n",
							"    matched_brands_score = brand_harmonization(brand_error_log, bm_master, matching_thr, score_seg_df)\n",
							"    matching_dataset = pd.DataFrame(matched_brands_score, columns=['BH','brand_cc',\\\n",
							"                                            'Matched_Brand','Score','Score_categroty',\\\n",
							"                                            'mSource_info','mCountry_info'])\n",
							"    matched_brands = output_formating(matching_dataset, score_config_df)\n",
							"    return matched_brands"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# Output processing in two intermediate table[summary and performance]\n",
							"def brand_matching(matching_threshold,score_config_df,score_seg_df):\n",
							"    # Get the Brand Market data\n",
							"    bm_master = read_input_data(\"brandmarket\")\n",
							"    # add this line in masterdata processing function\n",
							"    bm_master[\"CountryCode\"].fillna(\"global\", inplace = True)\n",
							"    bm_master[\"SourceSystem\"].fillna(\"NA\", inplace = True)\n",
							"    master_source=bm_master['SourceSystem'].unique()\n",
							"    Master_Source='_'.join(master_source)\n",
							"    master_cc=bm_master['CountryCode'].unique()\n",
							"    Master_CC='_'.join(master_cc)\n",
							"    # Get the CIP File Line Error Incremental data\n",
							"    brand_error_log = read_input_data(\"cip_file_line_error_intermediate\")\n",
							"    # Perform Data Processing\n",
							"    bm_master= country_master_data(bm_master)\n",
							"    bm_master=mbarn_replace(bm_master)\n",
							"    brand_error_log, brand_error_log_final = process_data(brand_error_log)\n",
							"    # Matching Score using Fuzzy Matching\n",
							"    matched_brands = matching_score(bm_master, brand_error_log,\\\n",
							"                            matching_threshold,score_config_df,score_seg_df)\n",
							"    #return matched_brands\n",
							"    if(len(matched_brands) > 0):\n",
							"        # Write the Output to Delta Table\n",
							"        sum_df=write_output_data(matched_brands)\n",
							"    else:\n",
							"        print('No records to write in the output table.')\n",
							"    \n",
							"    #return matched_brands performance\n",
							"    if(brand_error_log_final['H_Brand'].unique().shape[0]>0):\n",
							"        perf_mx_master_local=(matched_brands['Brand_Harmonized'].unique().shape[0]/\n",
							"                          brand_error_log_final['H_Brand'].unique().shape[0])*100\n",
							"        cc=brand_error_log['country_code'].unique()\n",
							"        BH_CC='_'.join(cc)\n",
							"        BH_Source=\"CIP\" #hardcoding as this information is not available in Source\n",
							"        act_brand_proc=brand_error_log_final.shape[0]\n",
							"        uniq_brand_proc=brand_error_log.shape[0]\n",
							"        matched_brand=matched_brands['Brand_Harmonized'].unique().shape[0]\n",
							"    else:\n",
							"        perf_mx_master_local=0\n",
							"        BH_CC=\"NA\"\n",
							"        BH_Source=\"CIP\"\n",
							"        act_brand_proc=0\n",
							"        uniq_brand_proc=0\n",
							"        matched_brand=0\n",
							"\n",
							"\n",
							"    datapf = {'Master_Source': Master_Source,'Master_CC':Master_CC,'BH_Source':BH_Source,\\\n",
							"        'BH_CC':BH_CC,'Actual_Brand_Processed':act_brand_proc,\\\n",
							"        'Unique_Brand_Processed':uniq_brand_proc,'Matched_Brand':matched_brand,\\\n",
							"        'Performance_in_perc':perf_mx_master_local}\n",
							"    output_df = pd.DataFrame(datapf, index=[0])\n",
							"\n",
							"    perf_df=write_output_data(output_df)\n",
							"    return sum_df, perf_df"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# consolidated function call\n",
							"# for Brandmatching and output processing\n",
							"sum_df, perf_df =brand_matching(matching_threshold,score_config_df, score_seg_df)"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Brand_Harmonized"
									],
									"values": [
										"Brand_Harmonized"
									],
									"yLabel": "Brand_Harmonized",
									"xLabel": "Brand_Harmonized",
									"aggregation": "COUNT",
									"aggByBackend": false
								},
								"aggData": "{\"Brand_Harmonized\":{\"Absolut\":1,\"Amarula\":1,\"Bacardi\":1,\"Ballantines\":1,\"Gilbeys\":1,\"Gordons\":1,\"Hennessy\":1,\"Jack Daniels\":1,\"Jameson\":1,\"Johnnie Walker\":1,\"Konyagi\":1,\"Rider\":1,\"Stout\":1}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"%%pyspark\n",
							"# Create table for Brandmatching Summary\n",
							"sum_df.createOrReplaceTempView(\"matched_brands_temp\")"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Erroneous_Brand"
									],
									"values": [
										"Erroneous_Brand"
									],
									"yLabel": "Erroneous_Brand",
									"xLabel": "Erroneous_Brand",
									"aggregation": "COUNT",
									"aggByBackend": false
								},
								"aggData": "{\"Erroneous_Brand\":{\"Absolut\":1,\"Amarula\":1,\"Bacardi\":1,\"Ballantines\":1,\"Busch\":1,\"Gilbeys\":1,\"Gordons\":1,\"Hennessy\":1,\"Jack Daniels\":1,\"Jameson\":1,\"Johnnie Walker\":1,\"Konyagi\":1,\"Rider\":1,\"Smirnoff\":1,\"VAT 69\":1,\"William Grants\":1}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"val mbdf = spark.sqlContext.sql (\"select * from matched_brands_temp\").\n",
							"                    withColumn(\"Brand_CC\", concat_ws(\",\", $\"Brand_CC\")).\n",
							"                    withColumn(\"Matched_Brands[Country]\", concat_ws(\",\", $\"Matched_Brands[Country]\")).\n",
							"                    withColumn(\"Score\", concat_ws(\",\", $\"Score\")).\n",
							"                    withColumn(\"Score_Category\", concat_ws(\",\", $\"Score_Category\")).\n",
							"                    withColumn(\"mSource_info\", concat_ws(\",\", $\"mSource_info\")).\n",
							"                    withColumn(\"mCountry_info\", concat_ws(\",\", $\"mCountry_info\")).\n",
							"                    drop(\"Matched_Brands_Country\").\n",
							"                    withColumnRenamed(\"Matched_Brands[Country]\",\"Matched_brands_Suggestions\").\n",
							"                    withColumnRenamed(\"Brand_Harmonized\",\"Erroneous_Brand\")\n",
							"              \n",
							"display(mbdf)"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mbdf.write.synapsesql(brand_matching_summary_table_name, com.microsoft.spark.sqlanalytics.utils.Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%%pyspark\n",
							"# Create table for Brandmatching ML modle performance\n",
							"perf_df.createOrReplaceTempView(\"matched_brands_perf_temp\")"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Master_Source"
									],
									"values": [
										"Actual_Brand_Processed"
									],
									"yLabel": "Actual_Brand_Processed",
									"xLabel": "Master_Source",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"Actual_Brand_Processed\":{\"CIP_Rosetta_BM_UI\":31}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"val mbpdf = spark.sqlContext.sql (\"select * from matched_brands_perf_temp\").\n",
							"                    withColumn(\"Master_Source\", concat_ws(\"_\", $\"Master_Source\")).\n",
							"                    withColumn(\"Master_CC\", concat_ws(\"_\", $\"Master_CC\")).\n",
							"                    withColumn(\"BH_CC\", concat_ws(\"_\", $\"BH_CC\"))              \n",
							"display(mbpdf)"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mbpdf.write.synapsesql(brand_matching_performance_table_name, com.microsoft.spark.sqlanalytics.utils.Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_brand_matching_scoring')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 4,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "python3",
						"display_name": "Python 3"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import os\n",
							"import pandas as pd \n",
							"import numpy as np\n",
							"from pandas import DataFrame\n",
							"from fuzzywuzzy import fuzz\n",
							"from pyspark.sql.functions import *\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Parameters\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"val brandmarket_table_name = \"GrowthFactorDev.bg_data_governance.brandmarket\"\n",
							"val cip_file_line_error_table_name = \"GrowthFactorDev.jobs.cip_file_line_error_incremental\""
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"root_path = 'abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/'\n",
							"folder_path = 'synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/'\n",
							"output_name = 'matched_brand_data_incremental'\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Read SQL Data -  Brand Master (Country level) and CIP BH error log"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"// scala library imports\n",
							"import org.apache.spark.sql.types._\n",
							"import org.apache.spark.sql._\n",
							"import org.apache.spark.sql.SqlAnalyticsConnector._\n",
							"import org.apache.spark._\n",
							"import org.apache.spark.sql.functions._\n",
							""
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"val brandmarket_df = spark.read.sqlanalytics(brandmarket_table_name) \n",
							"brandmarket_df.createOrReplaceTempView(\"brandmarket\")"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"val cip_file_line_error_df = spark.read.sqlanalytics(cip_file_line_error_table_name) \n",
							"cip_file_line_error_df.createOrReplaceTempView(\"cip_file_line_error_incremental\")"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Brand Harmonization Functions\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"def read_input_data(table_name):\n",
							"    df = spark.read.table(table_name)\n",
							"    df = df.toPandas()\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"def write_output_data(df):\n",
							"    sparkdf = spark.createDataFrame(df)\n",
							"    sparkdf = sparkdf\\\n",
							"        .withColumn('month', lit(month(current_date())))\\\n",
							"        .withColumn('year', lit(year(current_date())))\n",
							"    delta_table_path = root_path + folder_path + output_name\n",
							"    sparkdf.write\\\n",
							"        .format(\"delta\")\\\n",
							"        .mode(\"overwrite\")\\\n",
							"        .option(\"mergeSchema\", \"true\")\\\n",
							"        .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data - Input/ Ouput Functions\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"def country_master_data(master_data):\n",
							"    master_data=master_data.loc[master_data['CountryCode'] == \"MX\"]\n",
							"    master_data=master_data[['BrandMarketID', 'DisplayBrandName','FocusBrandInd',\\\n",
							"                                'BrandFamilyCode', 'BrandVariantCode',\\\n",
							"                                'CountryCode','source_code','HarmonizedBrandID',\\\n",
							"                                'BrandBeverageCode', 'AlcoholByVolume','MainVariant']]\n",
							"    return master_data"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"def cip_errorlog_processing(error_log):\n",
							"        error_log=error_log.loc[error_log['country_code'] == \"MX\"]\n",
							"        error_log=error_log.fillna(0)\n",
							"        error_log=error_log.astype({'file_id': 'int', 'severity_id': 'int',\\\n",
							"                                    'row_number': 'int','error_id': 'int'})\n",
							"        error_log= error_log[['survey_type','severity_id','error_id',\\\n",
							"                              'error_field','error_message',\\\n",
							"                              'error_description','created_date']]\n",
							"        error_log= error_log[(error_log.error_field==\"DerievedBrandID\")]\n",
							"        return error_log"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"def brand_extraction(processed_data):\n",
							"        processed_data['H_Brand'] = processed_data.\\\n",
							"        loc[processed_data['error_field'].isin(['DerievedBrandID'])]\\\n",
							"        ['error_description'].str.split('-').str[1]\n",
							"        \n",
							"        processed_data['H_Brand'].fillna('',inplace = True)\n",
							"        processed_data['H_Brand'] = processed_data['H_Brand'].astype('str')\n",
							"        return processed_data"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"def garbage_char_remove(logdf):\n",
							"        spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
							"                      \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
							"                      \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
							"                      \"`\",\"{\",\"|\",\"}\",\"~\",\"\"]\n",
							"        for char in spec_chars:\n",
							"            logdf['H_Brand'] = logdf['H_Brand'].str.replace(char,'')\n",
							"        return logdf"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"source": [
							"def remove_spl_char(char_df):\n",
							"        spec_chars = [\"194\",'195',\"MILLER LITE SSNET\",\"Chandon\",\n",
							"                      \"MGD 64\"]\n",
							"        \n",
							"        for char in spec_chars:\n",
							"            char_df['H_Brand'] = char_df['H_Brand'].str.replace(char,'')\n",
							"        return char_df"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"source": [
							"def date_processing(clean_df):\n",
							"        clean_df['created_date'] = pd.to_datetime(clean_df['created_date'], errors='coerce')\n",
							"        clean_df['BH_Year_Month'] = clean_df['created_date'].dt.strftime('%Y-%m')\n",
							"        clean_df['BH_Year'] = clean_df['created_date'].dt.strftime('%Y')\n",
							"        clean_df = clean_df.drop_duplicates(subset='H_Brand', keep=\"first\")\n",
							"        return clean_df"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"source": [
							"def brand_harmonization(brand_data, bm_master):\n",
							"        matched_brands = []\n",
							"        for row in brand_data.index:\n",
							"            brand_name = brand_data.get_value(row,\"H_Brand\")\n",
							"            brand_name=brand_name.strip()\n",
							"            for row_label in bm_master.index:\n",
							"                master_brand_name=bm_master.get_value(row_label,\"DisplayBrandName\")\n",
							"                matched_token=fuzz.ratio(brand_name,master_brand_name)\n",
							"                if matched_token> 67:\n",
							"                    matched_brands.append([brand_name,master_brand_name,matched_token])\n",
							"        return matched_brands"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"source": [
							"def output_formating(brand_matching):\n",
							"        lst=[]\n",
							"        lsti=[]\n",
							"        brand_unq=[]\n",
							"        for i in brand_matching.BH.unique():\n",
							"            agg_brand=brand_matching.loc[brand_matching.BH==i, 'Matched_Brand'].values.tolist()\n",
							"            agg_score=brand_matching.loc[brand_matching.BH==i, 'Score'].values.tolist()\n",
							"            lst.append(agg_brand)\n",
							"            lsti.append(agg_score)\n",
							"            brand_unq.append(i)\n",
							"        data = {'Brand_Harmonized':brand_unq,'Matched_Brands[Country]':lst, 'Score': lsti}\n",
							"        newdf = pd.DataFrame(data)\n",
							"        return newdf"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"source": [
							"def process_data(brand_error_log):\n",
							"    brand_error_log_final = cip_errorlog_processing(brand_error_log)\n",
							"    brand_ext= brand_extraction(brand_error_log_final)\n",
							"    clean_brand_ext = garbage_char_remove(brand_ext)\n",
							"    clean_brand_df = remove_spl_char(clean_brand_ext)\n",
							"    brand_error_log = date_processing(clean_brand_df)\n",
							"    return brand_error_log"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"source": [
							"def matching_score(bm_master, brand_error_log):\n",
							"    matched_brands_score = []\n",
							"    matched_brands_score = brand_harmonization(brand_error_log, bm_master)\n",
							"    matching_dataset = DataFrame (matched_brands_score, columns=['BH','Matched_Brand','Score'])\n",
							"    matched_brands = output_formating(matching_dataset)\n",
							"    return matched_brands"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"source": [
							"def brand_matching():\n",
							"    # Get the Brand Market data\n",
							"    bm_master = read_input_data(\"brandmarket\")\n",
							"    # Get the CIP File Line Error Incremental data\n",
							"    brand_error_log = read_input_data(\"cip_file_line_error_incremental\")\n",
							"    # Perform Data Processing\n",
							"    bm_master= country_master_data(bm_master)\n",
							"    brand_error_log = process_data(brand_error_log)\n",
							"    # Matching Score using Fuzzy Matching\n",
							"    matched_brands = matching_score(bm_master, brand_error_log)\n",
							"    if(len(matched_brands) > 0):\n",
							"        # Write the Output to Delta Table\n",
							"        write_output_data(matched_brands)\n",
							"    else:\n",
							"        print('No records to write in the output table.')"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"source": [
							"brand_matching()"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Brand_Harmonized"
									],
									"values": [
										"Brand_Harmonized"
									],
									"yLabel": "Brand_Harmonized",
									"xLabel": "Brand_Harmonized",
									"aggregation": "COUNT",
									"aggByBackend": false
								},
								"aggData": "{\"Brand_Harmonized\":{\" 1664 Blanc\":1,\" Amstel Ultra\":1,\" Atlas\":1,\" Balboa\":1,\" Ballast Point\":1,\" Baltica\":1,\" Beer\":1,\" Belhaven\":1,\" Berliner Kindl\":1,\" Blue Star\":1,\" Brew Dog\":1,\" Brooklyn Brewery\":1,\" Busch Light\":1,\" Cobra\":1,\" CoronaLight\":1,\" Cucapa\":1,\" DarkDunkel\":1,\" Dorada Draft\":1,\" Eristoff\":1,\" Estrella Damm\":1,\" Estrella Jalisco\":1,\" Fullers\":1,\" Grimbergen\":1,\" Hard Root BeerSoda\":1,\" Hollandia\":1,\" Iguana\":1,\" Insurgente\":1,\" Itaipava\":1,\" Jim Beam\":1,\" Kilkenny\":1,\" Kiss\":1,\" Light\":1,\" Lwenbru\":1,\" Miller 64\":1,\" ModeloLight\":1,\" Oasis\":1,\" Pacifico\":1,\" Pacifico Light\":1,\" PacificoLight\":1,\" Pacfico Suave\":1,\" Panama Light\":1,\" Pilsener Light\":1,\" SAB MILLER SSNET\":1,\" Shepherd Neame\":1,\" Shock Top\":1,\" SolCero\":1,\" SolClamato\":1,\" Solera\":1,\" Star\":1,\" Stone\":1,\" TecateLight\":1,\" TecateTecateRoja\":1,\" Tuborg\":1,\" Vicky\":1,\" Vickys\":1,\" WheatWeissHefeweissen\":1,\" XX Ambar\":1}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"delta_table_path = root_path + folder_path + output_name\n",
							"output_df = spark.read.format(\"delta\").load(delta_table_path)\n",
							"display(output_df)"
						],
						"outputs": [],
						"execution_count": 21
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_data_load')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 15,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "15",
						"spark.dynamicAllocation.maxExecutors": "15"
					}
				},
				"metadata": {
					"saveOutput": false,
					"kernelspec": {
						"name": "python3",
						"display_name": "Python 3"
					},
					"language_info": {
						"name": "scala"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# ML Data Load"
						],
						"attachments": null
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Import required Libraries\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"// scala library imports\n",
							"import org.apache.spark.sql.types._\n",
							"import org.apache.spark.sql._\n",
							"import org.apache.spark.sql.SqlAnalyticsConnector._\n",
							"import org.apache.spark._"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Parameters\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "scala",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"val databaseName = \"growthfactordev\";\n",
							"val schema = \"dbo\";\n",
							"val delta_table_path = \"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/\";\n",
							"val isTraining: Boolean = false"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Read Billing Data \n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"var billingDataTable = \"\"\n",
							"var orderCompletedTable = \"\"\n",
							"var productAddedTable = \"\"\n",
							"var cardViewedTable = \"\"\n",
							"var pointsRedeemedTable = \"\"\n",
							"var pointsActivityListTable = \"\"\n",
							"var appOpenedTable = \"\"\n",
							"var deliveryRatingTable = \"\"\n",
							"\n",
							"if(isTraining == true){  \n",
							"    billingDataTable = databaseName + \".\" + schema + \".\" + \"BillingDataConsolidated\"\n",
							"    orderCompletedTable = databaseName + \".\" + schema + \".\" + \"OrderCompletedDataset\"\n",
							"    productAddedTable = databaseName + \".\" + schema + \".\" + \"ProductAddedDataset\"\n",
							"    cardViewedTable = databaseName + \".\" + schema + \".\" + \"CardViewedDataset\"\n",
							"    pointsRedeemedTable = databaseName + \".\" + schema + \".\" + \"PointsRedeemed\"\n",
							"    pointsActivityListTable = databaseName + \".\" + schema + \".\" + \"PointsActivity\"\n",
							"    appOpenedTable = databaseName + \".\" + schema + \".\" + \"AppOpened\"\n",
							"    deliveryRatingTable = databaseName + \".\" + schema + \".\" + \"DeliveryRating\"\n",
							"\n",
							"} else {  \n",
							"    billingDataTable = databaseName + \".\" + schema + \".\" + \"BillingDataConsolidated_incremental\"\n",
							"    orderCompletedTable = databaseName + \".\" + schema + \".\" + \"OrderCompletedDataset_incremental\"\n",
							"    productAddedTable = databaseName + \".\" + schema + \".\" + \"ProductAddedDataset_incremental\"\n",
							"    cardViewedTable = databaseName + \".\" + schema + \".\" + \"CardViewedDataset_incremental\"\n",
							"    pointsRedeemedTable = databaseName + \".\" + schema + \".\" + \"PointsRedeemed_incremental\"\n",
							"    pointsActivityListTable = databaseName + \".\" + schema + \".\" + \"PointsActivity_incremental\"\n",
							"    appOpenedTable = databaseName + \".\" + schema + \".\" + \"AppOpened_incremental\"\n",
							"    deliveryRatingTable = databaseName + \".\" + schema + \".\" + \"DeliveryRating_incremental\"\n",
							"}  \n",
							""
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Read Billing Data \n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"val billingData = spark.read.sqlanalytics(billingDataTable)\n",
							"billingData.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"BillingData_Intermediate\")"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Read Segment Data\n",
							"\n",
							" "
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"val order_completed = spark.read.sqlanalytics(orderCompletedTable) \n",
							"order_completed.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"OrderCompletedDataset_Intermediate\")\n",
							"\n",
							"val product_added = spark.read.sqlanalytics(productAddedTable) \n",
							"product_added.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"ProductAddedDataset_Intermediate\")\n",
							"\n",
							"val card_viewed = spark.read.sqlanalytics(cardViewedTable) \n",
							"card_viewed.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"CardViewedDataset_Intermediate\")\n",
							"\n",
							"val points_redeemed = spark.read.sqlanalytics(pointsRedeemedTable) \n",
							"points_redeemed.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"PointsRedeemed_Intermediate\")\n",
							"\n",
							"val points_activity_list = spark.read.sqlanalytics(pointsActivityListTable)\n",
							"points_activity_list.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"PointsActivity_Intermediate\")\n",
							"\n",
							"val app_opened = spark.read.sqlanalytics(appOpenedTable) \n",
							"app_opened.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"AppOpened_Intermediate\")\n",
							"\n",
							"val delivery_rating = spark.read.sqlanalytics(deliveryRatingTable) \n",
							"delivery_rating.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path + \"DeliveryRating_Intermediate\")\n",
							""
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 5
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_export_automl')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Growth Factor"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"## Azure Machine Learning / AutoML Integration\n",
							"\n",
							"This notebook takes the output from the Azure ML / AutoML model and transforms it for reporting and display in Power BI.\n",
							"\n",
							"Steps:\n",
							"\n",
							"1. Initialize spark environment, import libraries, define functions and variables\n",
							"2.\tConnect to Azure Machine Learning Workspace\n",
							"3.\tPull model metrics from the best model\n",
							"Transform and persist these metrics as a CSV file to the Azure Data Lake so they can be displayed in Power BI.\n",
							"    * AUC, accuracy, precision, recall, F1\n",
							"    * Saved to **model_metrics_aml**\n",
							"4.\tPull the feature importances from AutoML using the Azure Storage python SDK.\n",
							"Transform and persist the feature importances as a CSV file to the Azure Data Lake so they can be displayed in Power BI.\n",
							"    * Saved to **feature_importances**\n",
							"5.\tRegister and store AutoML model for reusing in batch scoring\n",
							"Register and persist the model serialized file to **automl_model**"
						]
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 1: Initialize spark environment, import libraries, define functions and variables"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Define spark environment\n",
							"import pyspark\n",
							"spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
							"    .config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1\") \\\n",
							"    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
							"    .getOrCreate()"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "python",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Define variables\n",
							"## Azure Machine Learning Workspace\n",
							"subscription_id = '73f88e6b-3a35-4612-b550-555157e7059f'\n",
							"workspace_name = 'globalbrewdattestamlgbdev'\n",
							"resource_group = 'GLOBAL-BREWDAT-TEST-RG-GB-DEV'\n",
							"automl_run_id = 'AutoML_ec3cff88-f914-41b4-b7aa-5d20f0f3e43d'\n",
							"experiment_name = 'synapse-poc-automl'\n",
							"## Storagehttps://abigrowthfactoradls.dfs.core.windows.net\n",
							"storage_root_path = 'abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/'\n",
							"metrics_path = storage_root_path + 'model_metrics_aml'\n",
							"feature_importances_path = storage_root_path + 'feature_importances'\n",
							"aml_model_serialized_path = storage_root_path + 'aml_model_serialized'\n",
							"## Azure ML blob info\n",
							"connect_str = 'DefaultEndpointsProtocol=https;AccountName=globalbrewdatt7205937270;EndpointSuffix=core.windows.net'\n",
							"container_name = 'azureml'"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"# Define functions\n",
							"## Azure Machine Learning\n",
							"def connect_to_azure_machine_learning_workspace(\n",
							"    subscription_id,\n",
							"    resource_group,\n",
							"    workspace_name\n",
							"):\n",
							"    from azureml.core import Workspace\n",
							"    ws = Workspace(\n",
							"        subscription_id = subscription_id,\n",
							"        resource_group = resource_group,\n",
							"        workspace_name = workspace_name\n",
							"    )\n",
							"    return ws\n",
							"def get_metrics(experiment_name, run_id):\n",
							"    from azureml.core import Experiment, Run\n",
							"    experiment = Experiment(\n",
							"        workspace=ws,\n",
							"        name=experiment_name,\n",
							"    )\n",
							"    fetched_run = Run(experiment, automl_run_id)\n",
							"    metrics = fetched_run.get_metrics()\n",
							"    auc = metrics.get(\"AUC_weighted\")\n",
							"    accuracy = metrics.get(\"accuracy\")\n",
							"    precision = metrics.get(\"precision_score_weighted\")\n",
							"    recall = metrics.get(\"recall_score_weighted\")\n",
							"    f1 = metrics.get(\"f1_score_weighted\")\n",
							"    metrics_df = sc.parallelize([[\"AUC\", auc], [\"Accuracy\", accuracy], [\"Precision\", precision], [\"Recall\", recall], [\"F1\", f1]]).toDF((\"Metric\", \"Value\"))\n",
							"    return metrics_df\n",
							"def extract_features_importance(\n",
							"    azureml_blob_connection_string,\n",
							"    azureml_blob_container_name,\n",
							"    run_id,\n",
							"):\n",
							"    from azure.storage.blob import BlobServiceClient\n",
							"    from ast import literal_eval\n",
							"    from pyspark.sql.functions import desc\n",
							"    # Get file names for feature names and values\n",
							"    blob_service_client = BlobServiceClient.from_connection_string(azureml_blob_connection_string)\n",
							"    container_client = blob_service_client.get_container_client(azureml_blob_container_name)\n",
							"    blob_names = [b.name for b in container_client.list_blobs() if 'ExperimentRun/dcid.' + run_id in b.name and '/explanation/' in b.name and ('/global_names/0.interpret.json' in b.name or '/global_values/0.interpret.json' in b.name)]\n",
							"    feature_name_blob = next(b for b in blob_names if 'global_names' in b)\n",
							"    feature_values_blob = next(b for b in blob_names if 'global_values' in b)\n",
							"    # Extract feature names and values\n",
							"    feature_name_blob_client = container_client.get_blob_client(feature_name_blob)\n",
							"    feature_values_blob_client = container_client.get_blob_client(feature_values_blob)\n",
							"    feature_names = literal_eval(feature_name_blob_client.download_blob().content_as_text())\n",
							"    feature_values = literal_eval(feature_values_blob_client.download_blob().content_as_text())\n",
							"    # Create dataframe\n",
							"    feature_importances = sqlContext.createDataFrame(zip(feature_names, feature_values), schema=['feature_names', 'feature_values']).sort(desc('feature_values'))\n",
							"    return feature_importances\n",
							"def persist_to_datalake(\n",
							"    dataframe,\n",
							"    export_path,\n",
							"    write_mode = 'overwrite',\n",
							"):\n",
							"    dataframe.write.mode(write_mode).csv(export_path)\n",
							"def extract_best_model(run):\n",
							"    best_algorithm = list(fetched_run.get_children())[0]\n",
							"    model = best_algorithm.register_model(model_name=\"automl_model\", model_path='outputs/model.pkl')\n",
							"    sas_url = model.get_sas_urls()['model.pkl']\n",
							"    import requests\n",
							"    import io\n",
							"    content = requests.get(sas_url).content\n",
							"    import joblib\n",
							"    binary_buffer = io.BytesIO()\n",
							"    binary_buffer.write(content)\n",
							"    binary_buffer.seek(0)\n",
							"    model2 = joblib.load(binary_buffer)\n",
							"    return model2\n",
							"def serialize_model_to_dataframe(model):\n",
							"    import joblib\n",
							"    import io\n",
							"    binary_buffer = io.BytesIO()\n",
							"    joblib.dump(model, binary_buffer)\n",
							"    binary_buffer.seek(0)\n",
							"    bytes = binary_buffer.read()\n",
							"    df_model = spark.createDataFrame(\n",
							"        [\n",
							"            (1, ' '.join([str(b) for b in bytes])),\n",
							"        ],\n",
							"        ['id', 'content']\n",
							"    )\n",
							"    return df_model\n",
							"def deserialize_model_from_dataframe(df_model):\n",
							"    import io\n",
							"    import joblib\n",
							"    serialized_model = bytearray([int(b) for b in df_model.first().content.split(' ')])\n",
							"    binary_buffer = io.BytesIO()\n",
							"    binary_buffer.write(serialized_model)\n",
							"    binary_buffer.seek(0)\n",
							"    model_deserialized = joblib.load(binary_buffer)\n",
							"    return model_deserialized"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 2: Connect to Azure Machine Learning Workspace"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"ws = connect_to_azure_machine_learning_workspace(\n",
							"    subscription_id = subscription_id,\n",
							"    resource_group = resource_group,\n",
							"    workspace_name = workspace_name\n",
							")"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"from azureml.core import Experiment, Run\n",
							"experiment = Experiment(\n",
							"    workspace=ws,\n",
							"    name=experiment_name,\n",
							")\n",
							"fetched_run = Run(\n",
							"    experiment = experiment,\n",
							"    run_id = automl_run_id\n",
							")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 3: Pull model metrics from the best model\n",
							"Transform and persist these metrics as a CSV file to the Azure Data Lake so they can be displayed in Power BI.\n",
							"    * AUC, accuracy, precision, recall, F1\n",
							"    * Saved to **model_metrics_aml**"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"metrics_df = get_metrics(\n",
							"    experiment_name = experiment_name,\n",
							"    run_id = automl_run_id,\n",
							")\n",
							"persist_to_datalake(\n",
							"    dataframe = metrics_df,\n",
							"    export_path = metrics_path\n",
							")"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 4: Pull the feature importances from AutoML using the Azure Storage python SDK.\n",
							"Transform and persist the feature importances as a CSV file to the Azure Data Lake so they can be displayed in Power BI. Saved to **feature_importances**\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"feature_importances = extract_features_importance(\n",
							"    azureml_blob_connection_string = connect_str,\n",
							"    azureml_blob_container_name = container_name,\n",
							"    run_id = automl_run_id,\n",
							")\n",
							"persist_to_datalake(\n",
							"    dataframe = feature_importances,\n",
							"    export_path = feature_importances_path,\n",
							")"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 5:\tRegister and store AutoML model for reusing in batch scoring\n",
							"Register and persist the model serialized file to **automl_model**"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"model = extract_best_model(fetched_run)\n",
							"df_model = serialize_model_to_dataframe(model)\n",
							"persist_to_datalake(\n",
							"    dataframe = df_model,\n",
							"    export_path = aml_model_serialized_path,\n",
							")"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"model_deserialized = deserialize_model_from_dataframe(df_model)\n",
							"'predict' in dir(model_deserialized)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": 10
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_export_predictions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 10,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "10",
						"spark.dynamicAllocation.maxExecutors": "10"
					}
				},
				"metadata": {
					"saveOutput": true,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"## Export predictions\n",
							"\n",
							"This notebook takes as an input the data and appends predictions to be consumed by PowerBI.\n",
							""
						]
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Initialize Spark, parameters, functions"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Define spark environment\n",
							"import pyspark\n",
							"spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
							"    .config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1\") \\\n",
							"    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
							"    .getOrCreate()"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "python",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Define variables\n",
							"## Pipeline parameters\n",
							"isTraining = False\n",
							"## Data\n",
							"target_column = 'growth'\n",
							"key_columns = ['PocID', 'Year', 'Month']\n",
							"## Storage\n",
							"storage_root_path = 'abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/'\n",
							"if (isTraining):\n",
							"    aml_model_serialized_path = storage_root_path + 'aml_model_serialized'\n",
							"    transformed_data_path = storage_root_path + 'transformed_data'\n",
							"    predictions_path = storage_root_path + 'predicted_data'\n",
							"    write_mode = 'overwrite'\n",
							"else:\n",
							"    aml_model_serialized_path = storage_root_path + 'aml_model_serialized'\n",
							"    transformed_data_path = storage_root_path + 'transformed_data_incremental'\n",
							"    predictions_path = storage_root_path + 'predicted_data_incremental'\n",
							"    metrics_path = storage_root_path + 'metrics_incremental'\n",
							"    features_importances_path = storage_root_path + 'features_importances_incremental'\n",
							"    write_mode = 'append'"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"# Define functions\n",
							"## Load data\n",
							"def load_transformed_data(transformed_data_path, transformed_data_mode = 'delta'):\n",
							"    return spark.read.format(transformed_data_mode).load(transformed_data_path)\n",
							"def test_transformed_data(df, target_column):\n",
							"    if target_column not in df.columns:\n",
							"        raise Exception('Column ' + target_column + ' not found in the dataset')\n",
							"    if len(df.columns) < 2:\n",
							"        raise Exception('No features provided')\n",
							"    if df.count() < 100:\n",
							"        raise Exception('Not enough rows to train model')\n",
							"    for col in key_columns:\n",
							"        if col not in df.columns:\n",
							"            raise Exception('Key column ' + col + ' not found')\n",
							"def load_serialized_model(model_data_path):\n",
							"    return spark.read.format('csv').load(model_data_path)\n",
							"## Model\n",
							"def deserialize_model_from_dataframe(df_model):\n",
							"    import io\n",
							"    import joblib\n",
							"    serialized_model = bytearray([int(b) for b in df_model.first()[1].split(' ')])\n",
							"    binary_buffer = io.BytesIO()\n",
							"    binary_buffer.write(serialized_model)\n",
							"    binary_buffer.seek(0)\n",
							"    model_deserialized = joblib.load(binary_buffer)\n",
							"    return model_deserialized\n",
							"def append_predictions(\n",
							"    df,\n",
							"    target_column,\n",
							"    model_deserialized,\n",
							"):\n",
							"    df_pandas = df.toPandas()\n",
							"    del df_pandas[target_column]\n",
							"    df_pandas['year'] = df_pandas['Year']\n",
							"    del df_pandas['Year']\n",
							"    df_pandas['month'] = df_pandas['Month']\n",
							"    del df_pandas['Month']\n",
							"    df_prediction = model_deserialized.predict(df_pandas)\n",
							"    df_proba = [p[1] for p in model_deserialized.predict_proba(df_pandas)]\n",
							"    df_pandas_predicted = df.toPandas()\n",
							"    df_pandas_predicted[target_column + '_predicted'] = df_prediction\n",
							"    df_pandas_predicted[target_column + '_probability'] = df_proba\n",
							"    return df_pandas_predicted\n",
							"def convert_pandas_to_spark_dataframe(\n",
							"    df_pandas_predicted,\n",
							"):\n",
							"    df_pandas_predicted_result = df_pandas_predicted.copy()\n",
							"    for col in df_pandas_predicted_result.columns:\n",
							"        df_pandas_predicted_result[col] = df_pandas_predicted_result[col].astype(str)\n",
							"    df_pandas_predicted_result = spark.createDataFrame(df_pandas_predicted_result)\n",
							"    return df_pandas_predicted_result\n",
							"def persist_csv_to_datalake(\n",
							"    dataframe,\n",
							"    export_path,\n",
							"    write_mode = 'overwrite',\n",
							"):\n",
							"    dataframe.repartition(1).write.mode(write_mode).option(\"header\",\"true\").csv(export_path)\n",
							"def compute_performance(\n",
							"    df_pandas_performance\n",
							"):\n",
							"    import pandas as pd\n",
							"    from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef\n",
							"    result = []\n",
							"    for index, row in df_pandas_performance[['Year','Month']].drop_duplicates().iterrows():    \n",
							"        accuracy = accuracy_score(df_pandas_performance['growth'], df_pandas_performance['growth_predicted'])\n",
							"        precision = precision_score(df_pandas_performance['growth'], df_pandas_performance['growth_predicted'])\n",
							"        recall = recall_score(df_pandas_performance['growth'], df_pandas_performance['growth_predicted'])\n",
							"        auc = roc_auc_score(df_pandas_performance['growth'], df_pandas_performance['growth_predicted'])\n",
							"        f1 = f1_score(df_pandas_performance['growth'], df_pandas_performance['growth_predicted'])\n",
							"        matthews = matthews_corrcoef(df_pandas_performance['growth'], df_pandas_performance['growth_predicted'])\n",
							"        metrics = {\n",
							"            'Accuracy': accuracy,\n",
							"            'Precision': precision,\n",
							"            'Recall': recall,\n",
							"            'AUC': auc,\n",
							"            'F1 Score': f1,\n",
							"            'Matthews correlation': matthews,\n",
							"        }\n",
							"        for metric in metrics.keys():\n",
							"            result.append(\n",
							"                {\n",
							"                    'Year': row.Year,\n",
							"                    'Month': row.Month,\n",
							"                    'Metric': metric,\n",
							"                    'Value': metrics[metric],\n",
							"                }\n",
							"            )\n",
							"    performance = pd.DataFrame(result)\n",
							"    performance_df = spark.createDataFrame(performance)\n",
							"    return performance_df\n",
							"\n",
							"def extract_features_importance(df_pandas_performance, model_deserialized):\n",
							"    from sklearn.inspection import permutation_importance\n",
							"    import pandas as pd\n",
							"    result = []\n",
							"    for index, row in df_pandas_performance[['Year','Month']].drop_duplicates().iterrows():\n",
							"        X_val = df_pandas_performance.copy()\n",
							"        del X_val['growth']\n",
							"        del X_val['growth_predicted']\n",
							"        del X_val['growth_probability']\n",
							"        X_val['year'] = X_val['Year']\n",
							"        del X_val['Year']\n",
							"        X_val['month'] = X_val['Month']\n",
							"        del X_val['Month']\n",
							"        y_val = df_pandas_performance.copy()\n",
							"        y_val = y_val['growth']\n",
							"        r = permutation_importance(\n",
							"            model_deserialized,\n",
							"            X_val,\n",
							"            y_val,\n",
							"            n_repeats=1,\n",
							"            random_state=0\n",
							"        )\n",
							"        for i in r.importances_mean.argsort()[::-1]:\n",
							"            result.append(\n",
							"                {\n",
							"                    'Year': row.Year,\n",
							"                    'Month': row.Month,\n",
							"                    'Name': X_val.columns[i],\n",
							"                    'Importance': r.importances_mean[i]*10,\n",
							"                }\n",
							"            )\n",
							"    features_importance = pd.DataFrame(result)\n",
							"    return features_importance\n",
							"\n",
							"def subset_pandas_dataframe(\n",
							"        df_pandas_predicted,\n",
							"        target_column,\n",
							"    ):\n",
							"        df_pandas_performance = df_pandas_predicted.copy()\n",
							"        df_pandas_performance = df_pandas_performance.dropna(subset=[target_column,target_column + '_predicted'])\n",
							"        return df_pandas_performance\n",
							"\n",
							"def ml_export_predictions():\n",
							"\n",
							"    # Load model\n",
							"    df_model = load_serialized_model(aml_model_serialized_path)\n",
							"    model_deserialized = deserialize_model_from_dataframe(df_model)\n",
							"    'predict' in dir(model_deserialized)\n",
							"\n",
							"    # Load data\n",
							"    df = load_transformed_data(transformed_data_path)\n",
							"    test_transformed_data(df, target_column)\n",
							"\n",
							"    # Compute predictions\n",
							"    df_pandas_predicted = append_predictions(\n",
							"        df = d,\n",
							"        target_column = target_column,\n",
							"        model_deserialized = model_deserialized,\n",
							"    )\n",
							"\n",
							"    # Export predictions\n",
							"    df_spark_predicted_export = convert_pandas_to_spark_dataframe(\n",
							"    df_pandas_predicted = df_pandas_predicted,\n",
							"    )\n",
							"    persist_csv_to_datalake(\n",
							"        dataframe = df_spark_predicted_export,\n",
							"        export_path = predictions_path,\n",
							"        write_mode = write_mode,\n",
							"    )\n",
							"\n",
							"    if not isTraining:\n",
							"        df_pandas_performance = subset_pandas_dataframe(\n",
							"            df_pandas_predicted,\n",
							"            target_column = target_column,\n",
							"        )\n",
							"\n",
							"        # Compute and export performance\n",
							"        performance_df = compute_performance(\n",
							"            df_pandas_performance\n",
							"        )\n",
							"        persist_csv_to_datalake(\n",
							"            dataframe = performance_df,\n",
							"            export_path = predictions_path,\n",
							"            write_mode = write_mode,\n",
							"        )\n",
							"\n",
							"        # Compute and export features importance\n",
							"        features_importance = extract_features_importance(df_pandas_performance, model_deserialized)\n",
							"        features_importance_df = convert_pandas_to_spark_dataframe(features_importance)\n",
							"        persist_csv_to_datalake(\n",
							"            dataframe = features_importance_df,\n",
							"            export_path = features_importance_path,\n",
							"            write_mode = write_mode,\n",
							"        )\n",
							"        "
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Export predictions\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Load model\n",
							"df_model = load_serialized_model(aml_model_serialized_path)\n",
							"model_deserialized = deserialize_model_from_dataframe(df_model)\n",
							"'predict' in dir(model_deserialized)"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"# Load data\n",
							"df = load_transformed_data(transformed_data_path)\n",
							"test_transformed_data(df, target_column)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"source": [
							"# Compute predictions\n",
							"df_pandas_predicted = append_predictions(\n",
							"    df = df,\n",
							"    target_column = target_column,\n",
							"    model_deserialized = model_deserialized,\n",
							")"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"source": [
							"# Export predictions\n",
							"df_spark_predicted_export = convert_pandas_to_spark_dataframe(\n",
							"    df_pandas_predicted = df_pandas_predicted,\n",
							")\n",
							"persist_csv_to_datalake(\n",
							"    dataframe = df_spark_predicted_export,\n",
							"    export_path = predictions_path,\n",
							"    write_mode = write_mode,\n",
							")"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"# Remove NAs\n",
							"if not isTraining:\n",
							"    df_pandas_performance = subset_pandas_dataframe(\n",
							"        df_pandas_predicted,\n",
							"        target_column = target_column,\n",
							"    )"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Metric"
									],
									"values": [
										"Value"
									],
									"yLabel": "Value",
									"xLabel": "Metric",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"Value\":{\"AUC\":0.5088986549908758,\"Accuracy\":0.4158992889614174,\"F1 Score\":0.3642476528799797,\"Matthews correlation\":0.019444404807438823,\"Precision\":0.6936458081662237,\"Recall\":0.24696774193548388}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"# Compute and export performance\n",
							"if not isTraining:\n",
							"    performance_df = compute_performance(\n",
							"        df_pandas_performance\n",
							"    )\n",
							"    persist_csv_to_datalake(\n",
							"        dataframe = performance_df,\n",
							"        export_path = metrics_path,\n",
							"        write_mode = write_mode,\n",
							"    )"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"source": [
							"# Compute and export features importance\n",
							"if not isTraining:\n",
							"    features_importance = extract_features_importance(df_pandas_performance, model_deserialized)\n",
							"    features_importance_df = convert_pandas_to_spark_dataframe(features_importance)\n",
							"    persist_csv_to_datalake(\n",
							"        dataframe = features_importance_df,\n",
							"        export_path = features_importances_path,\n",
							"        write_mode = write_mode,\n",
							"    )"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": 11
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_feature_engineering')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 10,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "10",
						"spark.dynamicAllocation.maxExecutors": "10"
					}
				},
				"metadata": {
					"saveOutput": false,
					"kernelspec": {
						"name": "python3",
						"display_name": "Python 3"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# ML Feature Engineering"
						],
						"attachments": null
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Import required Libraries\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"# python libary imports\n",
							"import pyspark\n",
							"from pyspark.sql import functions as F\n",
							"from pyspark.sql.functions import *\n",
							"from pyspark.sql import *\n",
							"from pyspark.sql.types import *\n",
							"from functools import reduce"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Parameters\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "python",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"is_training = False\n",
							"delta_path = 'abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/'"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"delta_output_path = \"\"\n",
							"if(is_training):\n",
							"    delta_output_path = delta_path + \"transformed_data\"\n",
							"else:\n",
							"    delta_output_path = delta_path + \"transformed_data_incremental\""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Read Billing Data \n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"# read billing table intermediate spark table\n",
							"billing = spark.read.format(\"delta\").load(delta_path + \"BillingData_Intermediate\")"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Billing Feature Extraction Functions\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"def promotions_invoiced():\n",
							"    # count the number of promotions invoiced per user per month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    return billing.groupBy('PocID', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('PromoType').isNotNull()).alias(\n",
							"            'num_promotions_invoiced')\n",
							"    )"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"source": [
							"def b2b_customers():\n",
							"    # count how many times a user purchased via B2B in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    b2b = billing.groupBy('PocID', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('OrigenSystem') == 'B2B').alias('B2B')\n",
							"    )\n",
							"\n",
							"    # change this to binary\n",
							"    return b2b.withColumn('B2B', when(b2b['B2B'] >= 1, 1).otherwise(b2b['B2B']))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"source": [
							"def b2b_net_revenue():\n",
							"    # calculate percent of revenue that is coming from B2B per customer per month\n",
							"    def rev_sum_cond(cond): return F.sum(\n",
							"        F.when(cond, F.col('NetRevenue')).otherwise(0))\n",
							"    return billing.groupBy('PocID', 'Year', 'Month') \\\n",
							"        .agg(\n",
							"        rev_sum_cond(F.col('OrigenSystem') == 'B2B').alias('b2b_revenue'),\n",
							"        rev_sum_cond(F.col('OrigenSystem') ==\n",
							"                     'No B2B').alias('non_b2b_revenue')\n",
							"    ) \\\n",
							"        .withColumn('per_of_rev_from_b2b', (F.col('b2b_revenue') / (F.col('b2b_revenue') + F.col('non_b2b_revenue'))))\\\n",
							"        .drop('b2b_revenue', 'non_b2b_revenue')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"def third_party_marketplace_purchases():\n",
							"    # count how many times a user purchased via marketplace 3rd party in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    third_party = billing.groupBy('PocID', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('ThirdParty') == 1).alias('third_party')\n",
							"    )\n",
							"\n",
							"    # change this to binary\n",
							"    return third_party.withColumn('third_party',\n",
							"                                  when(third_party['third_party'] >= 1, 1)\n",
							"                                  .otherwise(third_party['third_party']))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"def third_party_revenue():\n",
							"    # calculate percent of revenue that is coming from 3rd party market place per customer per month\n",
							"    def rev_sum_cond(cond): return F.sum(\n",
							"        F.when(cond, F.col('NetRevenue')).otherwise(0))\n",
							"    return billing.groupBy('PocID', 'Year', 'Month') \\\n",
							"        .agg(\n",
							"        rev_sum_cond(F.col('ThirdParty') == 1).alias('third_party_revenue'),\n",
							"        rev_sum_cond(F.col('ThirdParty') == 0).alias('abi_revenue')\n",
							"    ) \\\n",
							"        .withColumn('per_of_rev_from_third_party', (F.col('third_party_revenue') / (F.col('third_party_revenue') + F.col('abi_revenue'))))\\\n",
							"        .drop('abi_revenue', 'third_party_revenue')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"source": [
							"def brands():\n",
							"    # count how many times a user purchased a major brand in a particular month\n",
							"    cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
							"    brands = billing.groupBy('PocID', 'Year', 'Month')\\\n",
							"                    .agg(\n",
							"                        cnt_cond(F.col('Brand') == 'BOHEMIA').alias('bohemia'),\n",
							"                        cnt_cond(F.col('Brand') == 'BRAHMA').alias('brahma'),\n",
							"                        cnt_cond(F.col('Brand') == 'CORONA').alias('corona'),\n",
							"                        cnt_cond(F.col('Brand') == 'MODELO').alias('modelo'),\n",
							"                        cnt_cond(F.col('Brand') == 'PRESIDENTE').alias(\n",
							"                            'presidente'),\n",
							"                        cnt_cond(F.col('Brand') == 'THE ONE').alias('the_one')\n",
							"                        )\n",
							"    return brands.withColumn('bohemia', when(brands['bohemia'] >= 1, 1).otherwise(brands['bohemia'])) \\\n",
							"                    .withColumn('brahma', when(brands['brahma'] >= 1, 1).otherwise(brands['brahma'])) \\\n",
							"                    .withColumn('corona', when(brands['corona'] >= 1, 1).otherwise(brands['corona'])) \\\n",
							"                    .withColumn('modelo', when(brands['modelo'] >= 1, 1).otherwise(brands['modelo'])) \\\n",
							"                    .withColumn('presidente', when(brands['presidente'] >= 1, 1).otherwise(brands['presidente'])) \\\n",
							"                    .withColumn('the_one', when(brands['the_one'] >= 1, 1).otherwise(brands['the_one'])) \\"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"def packaging():\n",
							"    # translate spanish and combine 12 oz and 355 ml into a single value\n",
							"    billingUpdated = billing.withColumn('Packaging', regexp_replace('Packaging', 'LITRO', 'LITER')) \\\n",
							"        .withColumn('Packaging', regexp_replace('Packaging', '^12 OZ', '12 OZ/355 ML')) \\\n",
							"        .withColumn('Packaging', regexp_replace('Packaging', '^355 ML', '12 OZ/355 ML'))\n",
							"\n",
							"    # count how many times a user purchased a major brand in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    packaging = billingUpdated.groupBy('PocID', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('Packaging') == '12 OZ/355 ML').alias('12_oz_355_ml'),\n",
							"        cnt_cond(F.col('Packaging') == '22 OZ').alias('22_oz'),\n",
							"        cnt_cond(F.col('Packaging') == 'LITER').alias('liter')\n",
							"    )\n",
							"\n",
							"    return packaging.withColumn('12_oz_355_ml', when(packaging['12_oz_355_ml'] >= 1, 1).otherwise(packaging['12_oz_355_ml'])) \\\n",
							"                    .withColumn('22_oz', when(packaging['22_oz'] >= 1, 1).otherwise(packaging['22_oz'])) \\\n",
							"                    .withColumn('liter', when(packaging['liter'] >= 1, 1).otherwise(packaging['liter']))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"def payment_type():\n",
							"    # translate spanish\n",
							"    billingUpdated = billing.withColumn('PaymentType', regexp_replace('PaymentType', 'Contado', 'Cash')) \\\n",
							"        .withColumn('PaymentType', regexp_replace('PaymentType', 'Cr?dito', 'Credit'))\n",
							"\n",
							"    # count how many times a customer used cash or credit in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    payment_type = billingUpdated.groupBy('PocID', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('PaymentType') ==\n",
							"                 'Credit').alias('credit')\n",
							"    )\n",
							"    return payment_type.withColumn('credit', when(payment_type['credit'] >= 1, 1).otherwise(payment_type['credit']))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"source": [
							"def credit_card_revenue():\n",
							"    # calculate percent of revenue that is spent using credit per customer per month\n",
							"    def rev_sum_cond(cond): return F.sum(\n",
							"        F.when(cond, F.col('NetRevenue')).otherwise(0))\n",
							"    return billing.groupBy('PocID', 'Year', 'Month') \\\n",
							"        .agg(\n",
							"        rev_sum_cond(F.col('PaymentType') == 'Cash').alias(\n",
							"            'cash_revenue'),\n",
							"        rev_sum_cond(F.col('PaymentType') == 'Credit').alias(\n",
							"            'credit_revenue')\n",
							"    ) \\\n",
							"        .withColumn('per_of_rev_from_credit', (F.col('credit_revenue') / (F.col('credit_revenue') + F.col('cash_revenue'))))\\\n",
							"        .drop('cash_revenue', 'credit_revenue')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"source": [
							"def join_billing_features(num_promotions_invoiced, b2b, per_of_rev_from_b2b, third_party, per_of_rev_from_third_party, brands, packaging, payment_type, per_of_rev_from_credit):\n",
							"    # create table with the unique set of composite IDs to be able to left join and keep all rows that have any Segment data\n",
							"    billing_filtered = billing.select('PocID', 'Year', 'Month')\\\n",
							"        .drop_duplicates()\n",
							"\n",
							"    # left on all billing feature tables join on poc_ids and year month composite key\n",
							"    joinType = 'left'\n",
							"\n",
							"    return billing_filtered.join(num_promotions_invoiced, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(third_party, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(per_of_rev_from_third_party, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(b2b, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(per_of_rev_from_b2b, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(brands, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(packaging, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(payment_type, ['PocID', 'Year', 'Month'], how=joinType)\\\n",
							"        .join(per_of_rev_from_credit, ['PocID', 'Year', 'Month'], how=joinType)"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Read Segment Data "
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"# read segment tables intermediate spark table\n",
							"order_completed = spark.read.format(\"delta\").load(delta_path + \"OrderCompletedDataset_Intermediate\")\n",
							"product_added = spark.read.format(\"delta\").load(delta_path + \"ProductAddedDataset_Intermediate\")\n",
							"card_viewed = spark.read.format(\"delta\").load(delta_path + \"CardViewedDataset_Intermediate\")\n",
							"points_redeemed = spark.read.format(\"delta\").load(delta_path + \"PointsRedeemed_Intermediate\")\n",
							"points_activity_list = spark.read.format(\"delta\").load(delta_path + \"PointsActivity_Intermediate\")\n",
							"app_opened = spark.read.format(\"delta\").load(delta_path + \"AppOpened_Intermediate\")\n",
							"delivery_rating = spark.read.format(\"delta\").load(delta_path + \"DeliveryRating_Intermediate\")"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Segment Data Transformations\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"# drop rows missing a timestamp\n",
							"order_completed = order_completed.dropna(subset=['timestamp'])\n",
							"\n",
							"# combined T and true from is_suggested into a single value\n",
							"order_completed = order_completed.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', 'true', 'T'))\n",
							"order_completed = order_completed.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', '1', 'T'))\n",
							"order_completed = order_completed.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', 'false', 'F'))\n",
							"order_completed = order_completed.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', '0', 'F'))\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"product_added = product_added.dropna(subset=['timestamp'])\n",
							"\n",
							"# fix true/false values\n",
							"product_added = product_added.withColumn(\n",
							"    'IsReorder', regexp_replace('IsReorder', 'true', 'T'))\n",
							"product_added = product_added.withColumn('IsReorder',\n",
							"                                         regexp_replace('IsReorder', '1', 'T'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsReorder', regexp_replace('IsReorder', 'false', 'F'))\n",
							"product_added = product_added.withColumn('IsReorder',\n",
							"                                         regexp_replace('IsReorder', '0', 'F'))\n",
							"\n",
							"product_added = product_added.withColumn(\n",
							"    'IsRedemption', regexp_replace('IsRedemption', 'true', 'T'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsRedemption', regexp_replace('IsRedemption', '1', 'T'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsRedemption', regexp_replace('IsRedemption', 'false', 'F'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsRedemption', regexp_replace('IsRedemption', '0', 'F'))\n",
							"\n",
							"product_added = product_added.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', 'true', 'T'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', '1', 'T'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', 'false', 'F'))\n",
							"product_added = product_added.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', '0', 'F'))\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"card_viewed = card_viewed.dropna(subset=['timestamp'])\n",
							"\n",
							"# fix true/false columns\n",
							"card_viewed = card_viewed.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', 'true', 'T'))\n",
							"card_viewed = card_viewed.withColumn('IsSuggested',\n",
							"                                     regexp_replace('IsSuggested', '1', 'T'))\n",
							"card_viewed = card_viewed.withColumn(\n",
							"    'IsSuggested', regexp_replace('IsSuggested', 'false', 'F'))\n",
							"card_viewed = card_viewed.withColumn('IsSuggested',\n",
							"                                     regexp_replace('IsSuggested', '0', 'F'))\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"points_redeemed = points_redeemed.dropna(subset=['timestamp'])\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"points_activity_list = points_activity_list.dropna(subset=['timestamp'])\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"app_opened = app_opened.dropna(subset=['timestamp'])"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Segment Feature Extraction Functions\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"def recommendation_type_orders():\n",
							"    # count how many times a customer ordered a recommended product by recommendation type in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    recommendation = order_completed.groupBy('ContextTraitsPocId', 'Year', 'Month')\\\n",
							"                                    .agg(\n",
							"                                        cnt_cond(F.col('RecommendationType') == 'FORGOTTEN_ITEMS').alias(\n",
							"                                            'forgotten_items'),\n",
							"                                        cnt_cond(F.col('RecommendationType') == 'QUICK_ORDER').alias(\n",
							"                                            'quick_order'),\n",
							"                                        cnt_cond(F.col('RecommendationType') == 'CROSS_SELL_UP_SELL').alias(\n",
							"                                            'cross_sell_up_sell'),\n",
							"    )\n",
							"\n",
							"    # change this to binary\n",
							"    return recommendation.withColumn('forgotten_items', when(recommendation['forgotten_items'] >= 1, 1).otherwise(recommendation['forgotten_items'])) \\\n",
							"        .withColumn('quick_order', when(recommendation['quick_order'] >= 1, 1).otherwise(recommendation['quick_order'])) \\\n",
							"        .withColumn('cross_sell_up_sell', when(recommendation['cross_sell_up_sell'] >= 1, 1).otherwise(recommendation['cross_sell_up_sell']))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"source": [
							"def recommendation_type_order_revenue():\n",
							"    # calculate percent of revenue that is ordered from recommended orders per customer per month\n",
							"    def rev_sum_cond(cond): return F.sum(\n",
							"        F.when(cond, F.col('Price')).otherwise(0))\n",
							"    return order_completed.groupBy('ContextTraitsPocId', 'Year', 'Month') \\\n",
							"        .agg(\n",
							"        rev_sum_cond(F.col('RecommendationType') ==\n",
							"                     'FORGOTTEN_ITEMS').alias('forgotten_rev'),\n",
							"        rev_sum_cond(F.col('RecommendationType') ==\n",
							"                     'QUICK_ORDER').alias('quick_order_rev'),\n",
							"        rev_sum_cond(F.col('RecommendationType') ==\n",
							"                     'CROSS_SELL_UP_SELL').alias('cross_sell_rev'),\n",
							"        rev_sum_cond(F.col('RecommendationType').isNull()\n",
							"                     ).alias('total_revenue')\n",
							"    ) \\\n",
							"        .withColumn('per_of_rev_from_forgotten', (F.col('forgotten_rev') / (F.col('total_revenue')))) \\\n",
							"        .withColumn('per_of_rev_from_quick_sell', (F.col('quick_order_rev') / (F.col('total_revenue')))) \\\n",
							"        .withColumn('per_of_rev_from_cross_sell', (F.col('cross_sell_rev') / (F.col('total_revenue')))) \\\n",
							"        .drop('forgotten_rev', 'quick_order_rev', 'cross_sell_rev', 'total_revenue', 'forgotten_rev', 'quick_order_rev', 'cross_sell_rev')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"source": [
							"def promotions_viewed():\n",
							"    # count how many times a customer viewed promotions in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    return card_viewed.groupBy('ContextTraitsPocId', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('PromotionType').isNotNull()).alias(\n",
							"            'num_promo_viewed')\n",
							"    )"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"source": [
							"def promotions_added():\n",
							"    # count how many times a customer added promotions in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    return product_added.groupBy('ContextTraitsPocId', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('PromotionType').isNotNull()).alias(\n",
							"            'num_promo_added')\n",
							"    )"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"source": [
							"def points_redeemed_func():\n",
							"    # merge order completed with points_redeemed\n",
							"    points = order_completed.join(points_redeemed,\n",
							"                                  (order_completed['ContextTraitsPocId'] ==\n",
							"                                   points_redeemed['ContextTraitsPocId'])\n",
							"                                  & (order_completed['Year'] == points_redeemed['Year'])\n",
							"                                  & (order_completed['Month'] == points_redeemed['Month']), how='left') \\\n",
							"        .drop(points_redeemed['ContextTraitsPocId']) \\\n",
							"        .drop(points_redeemed['Year']) \\\n",
							"        .drop(points_redeemed['Month']) \\\n",
							"        .dropna(subset=['ContextTraitsPocId', 'Year', 'Month']) \\\n",
							"        .fillna(0, subset=['PointsRedeemed', 'IsPointsRedeemed']) \\\n",
							"        .select('ContextTraitsPocId', 'Year', 'Month', 'PointsRedeemed', 'PointsEarned', 'IsPointsRedeemed')\n",
							"\n",
							"    # count how many times a customer redeemed points in a particular month\n",
							"    def cnt_cond(cond): return F.sum(F.when(cond, 1).otherwise(0))\n",
							"    points_redeemed_binary = points.groupBy('ContextTraitsPocId', 'Year', 'Month')\\\n",
							"        .agg(\n",
							"        cnt_cond(F.col('IsPointsRedeemed') == 1).alias(\n",
							"            'points_redeemed_binary')\n",
							"    )\n",
							"\n",
							"    # change this to binary\n",
							"    return points_redeemed_binary.withColumn('points_redeemed_binary',\n",
							"                                             when(\n",
							"                                                 points_redeemed_binary['points_redeemed_binary'] >= 1, 1)\n",
							"                                             .otherwise(points_redeemed_binary['points_redeemed_binary']))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"source": [
							"def redeemed_points_ratio():\n",
							"\n",
							"    # merge order completed with points_redeemed\n",
							"    points = order_completed.join(points_redeemed,\n",
							"                                  (order_completed['ContextTraitsPocId'] ==\n",
							"                                   points_redeemed['ContextTraitsPocId'])\n",
							"                                  & (order_completed['Year'] == points_redeemed['Year'])\n",
							"                                  & (order_completed['Month'] == points_redeemed['Month']), how='left') \\\n",
							"        .drop(points_redeemed['ContextTraitsPocId']) \\\n",
							"        .drop(points_redeemed['Year']) \\\n",
							"        .drop(points_redeemed['Month']) \\\n",
							"        .dropna(subset=['ContextTraitsPocId', 'Year', 'Month']) \\\n",
							"        .fillna(0, subset=['PointsRedeemed', 'IsPointsRedeemed']) \\\n",
							"        .select('ContextTraitsPocId', 'Year', 'Month', 'PointsRedeemed', 'PointsEarned', 'IsPointsRedeemed')\n",
							"\n",
							"    # redeemed points / earned points ratio\n",
							"    points_redeemed_per_month = points.groupBy('ContextTraitsPocId', 'Month', 'Year').agg(\n",
							"        sum('PointsRedeemed').alias('points_redeemed_per_month'))\n",
							"    points_earned_per_month = points.groupBy('ContextTraitsPocId', 'Month', 'Year').agg(\n",
							"        sum('PointsEarned').alias('points_earned_per_month'))\n",
							"\n",
							"    return points_redeemed_per_month.join(points_earned_per_month,\n",
							"                                          (points_redeemed_per_month['ContextTraitsPocId']\n",
							"                                           == points_earned_per_month['ContextTraitsPocId'])\n",
							"                                          & (points_redeemed_per_month['Year'] == points_earned_per_month['Year'])\n",
							"                                          & (points_redeemed_per_month['Month'] == points_earned_per_month['Month']),\n",
							"                                          how='inner') \\\n",
							"        .drop(points_earned_per_month['ContextTraitsPocId']) \\\n",
							"        .drop(points_earned_per_month['Year']) \\\n",
							"        .drop(points_earned_per_month['Month']) \\\n",
							"        .withColumn('redeemed_to_earned_points_ratio', F.col('points_redeemed_per_month') / F.col('points_earned_per_month')) \\\n",
							"        .fillna(0, subset=['redeemed_to_earned_points_ratio']) \\\n",
							"        .drop('points_redeemed_per_month', 'points_earned_per_month')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"source": [
							"def activity_list_views():\n",
							"    # number of activity list views\n",
							"    return points_activity_list.groupBy('ContextTraitsPocId', 'Month', 'Year')\\\n",
							"        .agg(sum('IsPointsActivity')\n",
							"             .alias('num_activity_list_views'))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"source": [
							"def average_delivery_rating():\n",
							"    # avg delivery rating viewed user/mo\n",
							"    return delivery_rating.groupBy('ContextTraitsPocId', 'Month', 'Year').agg(avg('RatingGiven').alias('avg_delivery_rating'))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"source": [
							"def app_opens():\n",
							"    # number of app opens per user/mo\n",
							"    return app_opened.groupBy('ContextTraitsPocId', 'Month', 'Year').agg(sum('IsAppOpened').alias('num_app_opens'))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"source": [
							"def join_segment_features(recommendation, per_of_rev_from_rec, num_promo_viewed, num_promo_added, points_redeemed_binary, points_redeemed_earned, num_activity_list_views, avg_delivery_rating, num_app_opens):\n",
							"    # create a table with the unique set of composite keys where there is Segment data\n",
							"    segment_users_unique = recommendation.select('ContextTraitsPocId', 'Year', 'Month')\\\n",
							"        .union(per_of_rev_from_rec.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(num_promo_viewed.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(num_promo_added.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(points_redeemed_binary.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(points_redeemed_earned.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(num_activity_list_views.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(avg_delivery_rating.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .union(num_app_opens.select('ContextTraitsPocId', 'Year', 'Month'))\\\n",
							"        .dropDuplicates()\\\n",
							"        .dropna(subset=['ContextTraitsPocId', 'Year', 'Month'], how='any')\\\n",
							"        .withColumnRenamed('ContextTraitsPocId', 'ContextTraitsPocId2')\\\n",
							"        .withColumnRenamed('Year', 'Year2')\\\n",
							"        .withColumnRenamed('Month', 'Month2')\n",
							"\n",
							"    # left join all of the segment features to this table\n",
							"    return segment_users_unique.join(recommendation,\n",
							"                                     (segment_users_unique['ContextTraitsPocId2']\n",
							"                                      == recommendation['ContextTraitsPocId'])\n",
							"                                     & (segment_users_unique['Year2'] == recommendation['Year'])\n",
							"                                     & (segment_users_unique['Month2'] == recommendation['Month']),\n",
							"                                     how='left')\\\n",
							"        .drop(recommendation['ContextTraitsPocId'])\\\n",
							"        .drop(recommendation['Year'])\\\n",
							"        .drop(recommendation['Month'])\\\n",
							"        .join(per_of_rev_from_rec,\n",
							"              (segment_users_unique['ContextTraitsPocId2']\n",
							"               == per_of_rev_from_rec['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == per_of_rev_from_rec['Year'])\n",
							"              & (segment_users_unique['Month2'] == per_of_rev_from_rec['Month']),\n",
							"              how='left')\\\n",
							"        .drop(per_of_rev_from_rec['ContextTraitsPocId'])\\\n",
							"        .drop(per_of_rev_from_rec['Year'])\\\n",
							"        .drop(per_of_rev_from_rec['Month'])\\\n",
							"        .join(num_promo_viewed,\n",
							"              (segment_users_unique['ContextTraitsPocId2']\n",
							"               == num_promo_viewed['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == num_promo_viewed['Year'])\n",
							"              & (segment_users_unique['Month2'] == num_promo_viewed['Month']),\n",
							"              how='left')\\\n",
							"        .drop(num_promo_viewed['ContextTraitsPocId'])\\\n",
							"        .drop(num_promo_viewed['Year'])\\\n",
							"        .drop(num_promo_viewed['Month'])\\\n",
							"        .join(num_promo_added,\n",
							"              (segment_users_unique['ContextTraitsPocId2']\n",
							"               == num_promo_added['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == num_promo_added['Year'])\n",
							"              & (segment_users_unique['Month2'] == num_promo_added['Month']),\n",
							"              how='left')\\\n",
							"        .drop(num_promo_added['ContextTraitsPocId'])\\\n",
							"        .drop(num_promo_added['Year'])\\\n",
							"        .drop(num_promo_added['Month'])\\\n",
							"        .join(points_redeemed_binary,\n",
							"              (segment_users_unique['ContextTraitsPocId2'] ==\n",
							"               points_redeemed_binary['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == points_redeemed_binary['Year'])\n",
							"              & (segment_users_unique['Month2'] == points_redeemed_binary['Month']),\n",
							"              how='left')\\\n",
							"        .drop(points_redeemed_binary['ContextTraitsPocId'])\\\n",
							"        .drop(points_redeemed_binary['Year'])\\\n",
							"        .drop(points_redeemed_binary['Month'])\\\n",
							"        .join(points_redeemed_earned,\n",
							"              (segment_users_unique['ContextTraitsPocId2'] ==\n",
							"               points_redeemed_earned['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == points_redeemed_earned['Year'])\n",
							"              & (segment_users_unique['Month2'] == points_redeemed_earned['Month']),\n",
							"              how='left')\\\n",
							"        .drop(points_redeemed_earned['ContextTraitsPocId'])\\\n",
							"        .drop(points_redeemed_earned['Year'])\\\n",
							"        .drop(points_redeemed_earned['Month'])\\\n",
							"        .join(num_activity_list_views,\n",
							"              (segment_users_unique['ContextTraitsPocId2'] ==\n",
							"               num_activity_list_views['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == num_activity_list_views['Year'])\n",
							"              & (segment_users_unique['Month2'] == num_activity_list_views['Month']),\n",
							"              how='left')\\\n",
							"        .drop(num_activity_list_views['ContextTraitsPocId'])\\\n",
							"        .drop(num_activity_list_views['Year'])\\\n",
							"        .drop(num_activity_list_views['Month'])\\\n",
							"        .join(avg_delivery_rating,\n",
							"              (segment_users_unique['ContextTraitsPocId2']\n",
							"               == avg_delivery_rating['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == avg_delivery_rating['Year'])\n",
							"              & (segment_users_unique['Month2'] == avg_delivery_rating['Month']),\n",
							"              how='left')\\\n",
							"        .drop(avg_delivery_rating['ContextTraitsPocId'])\\\n",
							"        .drop(avg_delivery_rating['Year'])\\\n",
							"        .drop(avg_delivery_rating['Month'])\\\n",
							"        .join(num_app_opens,\n",
							"              (segment_users_unique['ContextTraitsPocId2']\n",
							"               == num_app_opens['ContextTraitsPocId'])\n",
							"              & (segment_users_unique['Year2'] == num_app_opens['Year'])\n",
							"              & (segment_users_unique['Month2'] == num_app_opens['Month']),\n",
							"              how='left')\\\n",
							"        .drop(num_app_opens['ContextTraitsPocId'])\\\n",
							"        .drop(num_app_opens['Year'])\\\n",
							"        .drop(num_app_opens['Month'])\\\n",
							"        .withColumnRenamed('ContextTraitsPocId2', 'ContextTraitsPocId')\\\n",
							"        .withColumnRenamed('Year2', 'Year')\\\n",
							"        .withColumnRenamed('Month2', 'Month')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Join Billing and Segment Features\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"def join_billing_segment_features(billing_features, segment_features):\n",
							"    # inner join billing and segment to only get join where there is segment data captured\n",
							"    return billing_features.join(segment_features,\n",
							"                                 (billing_features['PocID'] ==\n",
							"                                  segment_features['ContextTraitsPocId'])\n",
							"                                 & (billing_features['Year'] == segment_features['Year'])\n",
							"                                 & (billing_features['Month'] == segment_features['Month']),\n",
							"                                 how='inner')\\\n",
							"        .drop(segment_features['ContextTraitsPocId'])\\\n",
							"        .drop(segment_features['Year'])\\\n",
							"        .drop(segment_features['Month'])\\\n",
							"        .join(billing.select('PocID', 'Year', 'Month', 'growth'),\n",
							"              (billing_features['PocID']\n",
							"               == billing['PocID'])\n",
							"              & (billing_features['Year'] == billing['Year'])\n",
							"              & (billing_features['Month'] == billing['Month']),\n",
							"              how='inner')\\\n",
							"        .drop(billing['PocID'])\\\n",
							"        .drop(billing['Year'])\\\n",
							"        .drop(billing['Month'])"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Handle Missing Data\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"def handle_missing_data(billing_segment):\n",
							"    # fill in missing values with 0 where appropriate\n",
							"    # dropped average delivery rating because it was missing for 78% of customers\n",
							"    return billing_segment.fillna(0, subset=['forgotten_items', 'quick_order', 'cross_sell_up_sell', 'per_of_rev_from_forgotten', 'per_of_rev_from_quick_sell',\n",
							"                                             'per_of_rev_from_cross_sell', 'num_promo_viewed', 'num_promo_added', 'points_redeemed_binary', 'redeemed_to_earned_points_ratio',\n",
							"                                             'num_activity_list_views', 'num_app_opens']).drop('avg_delivery_rating')"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Feature Engineering of Billing and Segment Data\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"def billing_feature_extraction():\n",
							"    # Extract required features\n",
							"    num_promotions_invoiced = promotions_invoiced()\n",
							"    b2b = b2b_customers()\n",
							"    per_of_rev_from_b2b = b2b_net_revenue()\n",
							"    third_party = third_party_marketplace_purchases()\n",
							"    per_of_rev_from_third_party = third_party_revenue()\n",
							"    brands_data = brands()\n",
							"    packaging_data = packaging()\n",
							"    payment_type_data = payment_type()\n",
							"    per_of_rev_from_credit = credit_card_revenue()\n",
							"\n",
							"    # Join Billing Features\n",
							"    return join_billing_features(num_promotions_invoiced, b2b, per_of_rev_from_b2b, third_party, per_of_rev_from_third_party, brands_data, packaging_data, payment_type_data, per_of_rev_from_credit)"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 29
					},
					{
						"cell_type": "code",
						"source": [
							"def segment_feature_extraction():\n",
							"    # Extract required features\n",
							"    recommendation = recommendation_type_orders()\n",
							"    num_promo_viewed = promotions_viewed()\n",
							"    num_promo_added = promotions_added()\n",
							"    num_activity_list_views = activity_list_views()\n",
							"    avg_delivery_rating = average_delivery_rating()\n",
							"    num_app_opens = app_opens()\n",
							"    points_redeemed_earned = redeemed_points_ratio()\n",
							"    points_redeemed_binary = points_redeemed_func()\n",
							"    per_of_rev_from_rec = recommendation_type_order_revenue()\n",
							"\n",
							"    # Join Segment Features\n",
							"    return join_segment_features(recommendation, per_of_rev_from_rec, num_promo_viewed, num_promo_added, points_redeemed_binary, points_redeemed_earned, num_activity_list_views, avg_delivery_rating, num_app_opens)"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 30
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Feature Engineering\n",
							""
						],
						"attachments": null
					},
					{
						"cell_type": "code",
						"source": [
							"def feature_engineering():\n",
							"    # Extract Features from Billing data\n",
							"    billing_features = billing_feature_extraction()\n",
							"\n",
							"    # Extract Features from Segment data\n",
							"    segment_features = segment_feature_extraction()\n",
							"\n",
							"    # Join the Billing and Segment features\n",
							"    billing_segment = join_billing_segment_features(\n",
							"        billing_features, segment_features)\n",
							"\n",
							"    # Handle Missing Data in Joined features\n",
							"    billing_segment = handle_missing_data(billing_segment)\n",
							"\n",
							"    \n",
							"    # write transformed data to spark table\n",
							"    billing_segment.write.format(\"delta\").mode(\"overwrite\").save(delta_output_path)"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"source": [
							"feature_engineering()"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 32
					},
					{
						"cell_type": "code",
						"source": [
							"features_df = spark.read.format(\"delta\").load(delta_output_path)\n",
							"features_df.show()\n",
							"print(features_df.count())"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 33
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ml_register_dataset')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Growth Factor"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"## Prepare AutoML execution by registering tabular dataset\n",
							"\n",
							"This notebook creates a tabular dataset from the imput required to train AutoML model in Azure Machine Learning UI\n",
							"\n",
							"Steps:\n",
							"\n",
							"1. Initialize spark environment, import libraries, define functions and variables\n",
							"2.\tLoad transformed data from the Azure Data Lake Gen2 storage.\n",
							"3.\tConnect to Azure Machine Learning Workspace\n",
							"4.\tRegister data as a tabular dataset\n",
							"5.\tCreate/Update Azure Machine Learning training cluster to run AutoML"
						]
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 1: Initialize spark environment, import libraries, define functions and variables\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Define spark environment\n",
							"import pyspark\n",
							"spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
							"    .config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1\") \\\n",
							"    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
							"    .getOrCreate()"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "python",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Define variables\n",
							"## Storage\n",
							"root_path = 'abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net'\n",
							"## Transformed data\n",
							"local_transformed_data_path = '/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/transformed_data'\n",
							"transformed_data_path = root_path + local_transformed_data_path\n",
							"transformed_data_mode = 'delta'\n",
							"target_column = 'growth'\n",
							"key_columns = ['PocID', 'Year', 'Month']\n",
							"## Azure Machine Learning Workspace\n",
							"subscription_id = '73f88e6b-3a35-4612-b550-555157e7059f'\n",
							"workspace_name = 'globalbrewdattestamlgbdev'\n",
							"resource_group = 'GLOBAL-BREWDAT-TEST-RG-GB-DEV'\n",
							"datastore_name = 'brewdatadlstestgbpoc'\n",
							"dataset_name = 'transformed_data'\n",
							"local_dataset_path = '/automl/transformed_data.csv'\n",
							"dataset_path = root_path + '/automl/transformed_data.csv'\n",
							"dataset_name = 'transformed_data_automl'\n",
							"dataset_description = 'Transformed Segment and billing data for Customer Insights ML model.'"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"# Define functions\n",
							"## Load data\n",
							"def load_transformed_data(transformed_data_path, transformed_data_mode = 'delta'):\n",
							"    return spark.read.format(transformed_data_mode).load(transformed_data_path)\n",
							"def test_transformed_data(df, target_column):\n",
							"    if target_column not in df.columns:\n",
							"        raise Exception('Column ' + target_column + ' not found in the dataset')\n",
							"    if len(df.columns) < 2:\n",
							"        raise Exception('No features provided')\n",
							"    if df.count() < 100:\n",
							"        raise Exception('Not enough rows to train model')\n",
							"    for col in key_columns:\n",
							"        if col not in df.columns:\n",
							"            raise Exception('Key column ' + col + ' not found')\n",
							"## Azure Machine Learning\n",
							"def connect_to_azure_machine_learning_workspace(\n",
							"    subscription_id,\n",
							"    resource_group,\n",
							"    workspace_name\n",
							"):\n",
							"    from azureml.core import Workspace\n",
							"    ws = Workspace(\n",
							"        subscription_id = subscription_id,\n",
							"        resource_group = resource_group,\n",
							"        workspace_name = workspace_name\n",
							"    )\n",
							"    return ws\n",
							"def get_datastore(\n",
							"    workspace,\n",
							"    datastore_name\n",
							"):\n",
							"    from azureml.core import Datastore\n",
							"    return Datastore.get(ws, datastore_name)\n",
							"def upload_dataset_to_datastore(\n",
							"    dataframe,\n",
							"    dataset_path,\n",
							"    datastore,\n",
							"    sep = ','\n",
							"):\n",
							"    # Upload dataset to datastore\n",
							"    df.repartition(1).write.csv(\n",
							"        path=dataset_path,\n",
							"        header=\"true\",\n",
							"        mode=\"overwrite\",\n",
							"        sep=\",\"\n",
							"    )\n",
							"    # Retrieve exported csv file name\n",
							"    # https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-directory-file-acl-python\n",
							"    import os, uuid, sys\n",
							"    from azure.storage.filedatalake import DataLakeServiceClient\n",
							"    from azure.core._match_conditions import MatchConditions\n",
							"    from azure.storage.filedatalake._models import ContentSettings\n",
							"    from azure.identity import ClientSecretCredential\n",
							"    tenant_id = datastore.tenant_id\n",
							"    client_id = datastore.client_id\n",
							"    client_secret = datastore.client_secret\n",
							"    credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
							"    storage_account_name = datastore.account_name\n",
							"    service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\"https\", storage_account_name), credential=credential)\n",
							"    file_system = datastore.container_name\n",
							"    file_system_client = service_client.get_file_system_client(file_system=file_system)\n",
							"    path_to_read = local_dataset_path\n",
							"    paths = file_system_client.get_paths(path=path_to_read)\n",
							"    csv_file_name = next(p.name for p in paths if 'part' in p.name)\n",
							"    return csv_file_name\n",
							"def register_tabular_dataset(\n",
							"    workspace,\n",
							"    datastore,\n",
							"    csv_file_name,\n",
							"    name,\n",
							"    description = ''\n",
							"):\n",
							"    from azureml.core import Dataset\n",
							"    dataset = Dataset.Tabular.from_delimited_files(path=[(datastore, csv_file_name)])\n",
							"    dataset.register(\n",
							"        workspace = workspace,\n",
							"        name = 'transformed_data_automl',\n",
							"        description = 'Transformed Segment and billing data for Customer Insights ML model.',\n",
							"        create_new_version = True\n",
							"    )\n",
							"    return dataset\n",
							"def create_or_update_compute_target(\n",
							"    workspace,\n",
							"    compute_name,\n",
							"    vm_size,\n",
							"    max_nodes,\n",
							"    timeout_in_minutes = 20\n",
							"):\n",
							"    from azureml.core import ComputeTarget\n",
							"    from azureml.core.compute import AmlCompute\n",
							"    provisioning_config = AmlCompute.provisioning_configuration(\n",
							"        vm_size = vm_size,\n",
							"        min_nodes = 0,\n",
							"        max_nodes = max_nodes\n",
							"    )\n",
							"    compute_target = ComputeTarget.create(workspace, compute_name, provisioning_config)\n",
							"    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=timeout_in_minutes)\n",
							""
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 2: Load transformed data from the Azure Data Lake Gen2 storage."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"df = load_transformed_data(transformed_data_path)\n",
							"test_transformed_data(df, target_column)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 3: Connect to Azure Machine Learning Workspace"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"ws = connect_to_azure_machine_learning_workspace(\n",
							"    subscription_id = subscription_id,\n",
							"    resource_group = resource_group,\n",
							"    workspace_name = workspace_name\n",
							")"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 4: Register data as a tabular dataset"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"datastore = get_datastore(\n",
							"    workspace = ws,\n",
							"    datastore_name = datastore_name\n",
							")\n",
							"dataset_remote_path = upload_dataset_to_datastore(\n",
							"    dataframe = df,\n",
							"    dataset_path = dataset_path,\n",
							"    datastore = datastore\n",
							")\n",
							"dataset = register_tabular_dataset(\n",
							"    workspace = ws,\n",
							"    datastore = datastore,\n",
							"    csv_file_name = dataset_remote_path,\n",
							"    name = dataset_name,\n",
							"    description = dataset_description\n",
							")"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Step 5: Create/Update Azure Machine Learning training cluster to run AutoML"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"create_or_update_compute_target(\n",
							"    workspace = ws,\n",
							"    compute_name = 'aml-compute',\n",
							"    vm_size = 'STANDARD_D12_V2',\n",
							"    max_nodes = 1\n",
							")"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": 16
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/reporting_data_model')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Growth Factor"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 20,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "20",
						"spark.dynamicAllocation.maxExecutors": "20"
					}
				},
				"metadata": {
					"saveOutput": true,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"## Reporting Data Model\n",
							"\n",
							"This notebook prepares the tables used in Power BI reporting, to capture the different features/growth factors and their correlation to customer growth.\n",
							"\n",
							"Four tables are created to enable reporting:\n",
							"\n",
							"1. Growth table\n",
							"    * Identifies whether a customer is classified as growth, no change, or decline, based on a +/-10% change in net revenue month-over-month\n",
							"\t* Saved to **growth_final**\n",
							"2. Customer table\n",
							"    * Supplementary table for additional customer information, such as name and region of sale\n",
							"    * Saved to **customer_final**\n",
							"3. Billing table\n",
							"    * Captures growth factors from invoice data, both ABI and 3rd-party\n",
							"    * E.g. brands purchased, B2B or not, packaging types, payment types, promotions applied, etc.\n",
							"    * Saved to **billing_final**\n",
							"4. Segment table\n",
							"\t* Captures additional growth factors from sement tables, as extracted in previous notebook\n",
							"    * Saved to **segment_final**\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import pyspark\n",
							"from pyspark.sql import functions as F\n",
							"from pyspark.sql.functions import *\n",
							"from pyspark.sql import *\n",
							"from pyspark.sql.types import *\n",
							"from functools import reduce"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"import org.apache.spark.sql.SaveMode"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"\n",
							"val database_name = \"growthfactordev\"\n",
							"val invoice_table_name = database_name + \".\" + \"command_center_core_data.invoice\"\n",
							"val invoice_temporary_table_name = \"abi_invoice_temp\"\n",
							"val third_party_invoice_historical_table_name = database_name + \".\" + \"command_center_raw_data.FacturasBEES_Historico\"\n",
							"val third_party_historical_temporary_table_name = \"third_party_invoice_historical_temp\"\n",
							"val third_party_invoice_current_month_table_name = database_name + \".\" + \"command_center_raw_data.FacturasBEES_MesActual\"\n",
							"val third_party_invoice_current_month_temporary_table_name = \"third_party_invoice_current_temp\"\n",
							"val customer_table_name = database_name + \".\" + \"command_center_raw_data.Cliente\"\n",
							"val customer_temporary_table = \"customer_temp\"\n",
							"val product_table_name = database_name + \".\" + \"command_center_raw_data.PRODUCTO\"\n",
							"val product_temporary_table_name = \"product_temp\"\n",
							"val promotion_table_name = database_name + \".\" + \"command_center_core_data.PROMOTION\"\n",
							"val promotion_temporary_table_name = \"promotion_temp\"\n",
							"val growth_final_table_name = database_name + \".dbo.growth_final\"\n",
							"val customer_final_table_name = database_name + \".dbo.customer_final\"\n",
							"val billing_final_table_name = database_name + \".dbo.billing_final\"\n",
							"val segment_final_table_name = database_name + \".dbo.segment_final\""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"\n",
							"// read billing data\n",
							"\n",
							"// ABI invoice table\n",
							"val abi_invoice = spark.read.sqlanalytics(invoice_table_name).select(\"date\",\"PocID\",\"SKU\",\"origin_system\",\"NetRevenue\",\"payment_type\",\"promotion_id\")\n",
							"abi_invoice.createOrReplaceTempView(invoice_temporary_table_name)\n",
							"\n",
							"// 3rd party invoice table historical (FacturasBEES_Historico) - had to create a new DW table to fix the date schema\n",
							"val third_party_invoice_historical = spark.read.sqlanalytics(third_party_invoice_historical_table_name).select(\"FechaEntrega\",\"ClienteCodigo\",\"SKU\",\"SistemaOrigen\",\"NTOListaAbs\",\"TipoPago\",\"PlanComboCodigo\")\n",
							"third_party_invoice_historical.createOrReplaceTempView(third_party_historical_temporary_table_name)\n",
							"\n",
							"// 3rd party invoice table current month (FacturasBEES_MesActual)\n",
							"val third_party_invoice_current = spark.read.sqlanalytics(third_party_invoice_current_month_table_name).select(\"FechaEntrega\",\"ClienteCodigo\",\"SKU\",\"SistemaOrigen\",\"NTOListaAbs\",\"TipoPago\",\"PlanComboCodigo\")\n",
							"third_party_invoice_current.createOrReplaceTempView(third_party_invoice_current_month_temporary_table_name)\n",
							"\n",
							"// Customer table (Cliente)\n",
							"val customer = spark.read.sqlanalytics(customer_table_name)\n",
							"customer.createOrReplaceTempView(customer_temporary_table)\n",
							"\n",
							"// Product table (Producto)\n",
							"val product = spark.read.sqlanalytics(product_table_name).select(\"Presentacion\",\"Marca\",\"Categoria\",\"SKU\")\n",
							"product.createOrReplaceTempView(product_temporary_table_name)\n",
							"\n",
							"// Promotion table\n",
							"val promotion = spark.read.sqlanalytics(promotion_table_name).select(\"promoType\",\"isCombo\",\"discountPorc\",\"promoCode\")\n",
							"promotion.createOrReplaceTempView(promotion_temporary_table_name)"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate invoice, 3rd party invoice tables joined with product and promotion tables for full billing dataframe \n",
							"billing = spark.sql('( \\\n",
							"                    SELECT \\\n",
							"                        s1.FechaEntrega AS date, \\\n",
							"                        s1.ClienteCodigo AS PocID, \\\n",
							"                        s1.SKU AS SKU, \\\n",
							"                        s1.SistemaOrigen AS system_origin, \\\n",
							"                        s3.promoType, \\\n",
							"                        s3.isCombo, \\\n",
							"                        s3.discountPorc AS discountPer, \\\n",
							"                        s1.NTOListaAbs AS NetRevenue, \\\n",
							"                        s1.TipoPago AS payment_type, \\\n",
							"                        s2.Presentacion AS packaging, \\\n",
							"                        s2.Marca AS brand, \\\n",
							"                        s2.Categoria AS category, \\\n",
							"                        1 AS third_party \\\n",
							"                    FROM third_party_invoice_current_temp AS s1 \\\n",
							"                    LEFT JOIN product_temp AS s2 on s2.SKU = s1.SKU \\\n",
							"                    LEFT JOIN promotion_temp AS s3 on s3.promoCode = s1.PlanComboCodigo \\\n",
							"                    ) \\\n",
							"                    UNION \\\n",
							"                    ( \\\n",
							"                    SELECT \\\n",
							"                        s1.FechaEntrega AS date, \\\n",
							"                        s1.ClienteCodigo AS PocID, \\\n",
							"                        s1.SKU AS SKU, \\\n",
							"                        s1.SistemaOrigen AS system_origin, \\\n",
							"                        s3.promoType, \\\n",
							"                        s3.isCombo, \\\n",
							"                        s3.discountPorc AS discountPer, \\\n",
							"                        s1.NTOListaAbs AS NetRevenue, \\\n",
							"                        s1.TipoPago AS payment_type, \\\n",
							"                        s2.Presentacion AS packaging, \\\n",
							"                        s2.Marca AS brand, \\\n",
							"                        s2.Categoria AS category, \\\n",
							"                        1 AS third_party \\\n",
							"                    FROM third_party_invoice_historical_temp AS s1 \\\n",
							"                    LEFT JOIN product_temp AS s2 on s2.SKU = s1.SKU \\\n",
							"                    LEFT JOIN promotion_temp AS s3 on s3.promoCode = s1.PlanComboCodigo \\\n",
							"                    ) \\\n",
							"                    UNION \\\n",
							"                    ( \\\n",
							"                    SELECT \\\n",
							"                        s1.date, \\\n",
							"                        s1.PocID, \\\n",
							"                        s1.SKU AS SKU, \\\n",
							"                        s1.origin_system, \\\n",
							"                        s3.promoType, \\\n",
							"                        s3.isCombo, \\\n",
							"                        s3.discountPorc AS discountPer, \\\n",
							"                        s1.NetRevenue, \\\n",
							"                        s1.payment_type, \\\n",
							"                        s2.Presentacion AS packaging, \\\n",
							"                        s2.Marca AS brand, \\\n",
							"                        s2.Categoria AS category, \\\n",
							"                        0 AS third_party \\\n",
							"                FROM abi_invoice_temp AS s1 \\\n",
							"                LEFT JOIN product_temp AS s2 on s2.SKU = s1.SKU \\\n",
							"                LEFT JOIN promotion_temp AS s3 on s3.promoCode = s1.promotion_id \\\n",
							"                WHERE Categoria = \"CERVEZAS\" \\\n",
							"                )'\n",
							"               )"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"PocID"
									],
									"values": [
										"discountPer"
									],
									"yLabel": "discountPer",
									"xLabel": "PocID",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"discountPer\":{\"0000258621\":27,\"0000473239\":30.5,\"0000501497\":26,\"0000515397\":26,\"0000533811\":30.5}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"# convert date into month and year, drop SKU and date columns\n",
							"billing = billing.withColumn('month', month(billing['date']))\\\n",
							"                 .withColumn('year', year(billing['date']))\\\n",
							"                 .drop('SKU', 'date')\\\n",
							"                 .select('PocID', 'year', 'month', 'system_origin', 'promoType', 'isCombo', 'discountPer', \n",
							"                        'NetRevenue', 'payment_type', 'packaging', 'brand', 'category', 'third_party') # re-order columns"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Growth Table\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# create & transform table for growth\n",
							"\n",
							"# filter to last 3 years\n",
							"growth = billing.where(\"year >= 2018\")\n",
							"\n",
							"# get monthly revenue\n",
							"growth = growth.withColumn(\"NetRevenue\", billing[\"NetRevenue\"].cast(\"double\"))\\\n",
							"    .groupBy(\"PocID\", \"year\", \"month\") \\\n",
							"    .sum(\"NetRevenue\") \\\n",
							"    .withColumnRenamed(\"sum(NetRevenue)\", \"total_net_revenue\") \\\n",
							"    .orderBy(\"PocID\", \"year\", \"month\")\n",
							"\n",
							"# get deltas for previous month\n",
							"from pyspark.sql.window import Window\n",
							"from pyspark.sql.functions import lag\n",
							"\n",
							"window_specs = Window.partitionBy(\"PocID\").orderBy(\"PocID\", \"month\")\n",
							"\n",
							"growth_lag = growth.withColumn(\"last_month_revenue\", lag(growth.total_net_revenue).over(window_specs))\n",
							"growth_delta = growth_lag.withColumn(\"delta_net_revenue\", (growth_lag.total_net_revenue - growth_lag.last_month_revenue))"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"# identify growth (1) vs. no growth (0) customers\n",
							"# growth defined as +/-10% revenue month-over-month\n",
							"\n",
							"df_growth_a = growth_delta.withColumn(\"percent_delta_revenue\", growth_delta[\"delta_net_revenue\"]/growth_delta[\"last_month_revenue\"])\n",
							"df_growth = df_growth_a.withColumn(\"net_revenue_change_MoM\", \n",
							"        when(df_growth_a[\"percent_delta_revenue\"] >= .1, \"growth\")\n",
							"        .when(df_growth_a[\"percent_delta_revenue\"] <= -.1, \"decline\")\n",
							"        .otherwise(\"no change\"))"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"# add unique identifier, remove unneeded columns and save to temp\n",
							"df_growth_filtered = df_growth.withColumn(\"poc_year_month_id\", concat(df_growth[\"PocID\"], lit(\"-\"), df_growth[\"year\"], lit(\"-\"), df_growth[\"month\"])) \\\n",
							"    .select(\"poc_year_month_id\", \"PocID\", \"year\", \"month\", \"percent_delta_revenue\", \"net_revenue_change_MoM\")\n",
							"\n",
							"df_growth_filtered = df_growth_filtered \\\n",
							"    .filter(df_growth_filtered[\"poc_year_month_id\"].isNotNull()) \\\n",
							"    .filter(df_growth_filtered[\"percent_delta_revenue\"].isNotNull())"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"poc_year_month_id"
									],
									"values": [
										"year"
									],
									"yLabel": "year",
									"xLabel": "poc_year_month_id",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"year\":{\"0000230297-2018-2\":2018,\"0000230297-2019-1\":2019,\"0000230297-2019-2\":2019,\"0000230297-2020-1\":2020,\"0000230297-2020-2\":2020}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"df_growth_filtered.createOrReplaceTempView(\"growth_filtered\")"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"outputCollapsed": true
						},
						"source": [
							"%%spark\n",
							"\n",
							"// save to sql pool\n",
							"\n",
							"val growth_filtered_df = spark.read.table(\"growth_filtered\")\n",
							"growth_filtered_df.write.mode(SaveMode.Overwrite).sqlanalytics(growth_final_table_name, Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Customer Table\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# clean up customer table\n",
							"customer = spark.read.table(\"customer_temp\") \\\n",
							"    .withColumnRenamed(\"ClienteCodigo\", \"PocID\") \\\n",
							"    .withColumnRenamed(\"ClienteNombre\", \"name\") \\\n",
							"    .withColumnRenamed(\"Telefono\", \"phone\") \\\n",
							"    .withColumnRenamed(\"ClienteEstatus\", \"status\") \\\n",
							"    .withColumnRenamed(\"Canal\", \"channel\") \\\n",
							"    .withColumnRenamed(\"SubCanal\", \"subchannel\") \\\n",
							"    .withColumnRenamed(\"Segmento\", \"segment\") \\\n",
							"    .withColumnRenamed(\"SubSegmento\", \"subsegment\") \\\n",
							"    .withColumnRenamed(\"TipoPago\", \"payment_type\") \\\n",
							"    .withColumnRenamed(\"Latitud\", \"latitude\") \\\n",
							"    .withColumnRenamed(\"Longitud\", \"longitude\") \\\n",
							"    .withColumnRenamed(\"Pais\", \"country\") \\\n",
							"    .withColumnRenamed(\"RegionVenta\", \"region_of_sale\") \\\n",
							"    .withColumnRenamed(\"RegionEntrega\", \"region_of_delivery\") \\\n",
							"    .select(\"PocID\", \"name\", \"phone\", \"status\", \"channel\", \"subchannel\", \"segment\", \"subsegment\", \"payment_type\", \"latitude\", \"longitude\", \"country\", \"region_of_sale\", \"region_of_delivery\")"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"PocID"
									],
									"values": [
										"PocID"
									],
									"yLabel": "PocID",
									"xLabel": "PocID",
									"aggregation": "COUNT",
									"aggByBackend": false
								},
								"aggData": "{\"PocID\":{\"DO00063476\":1,\"DO00063886\":1,\"DO00063956\":1,\"DO00106247\":1,\"DO00106966\":1}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"# save temp\n",
							"customer.createOrReplaceTempView(\"customer_filtered\")"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"outputCollapsed": true
						},
						"source": [
							"%%spark\n",
							"\n",
							"// write to sql pool\n",
							"\n",
							"val customer_filtered_df = spark.read.table(\"customer_filtered\")\n",
							"customer_filtered_df.write.mode(SaveMode.Overwrite).sqlanalytics(customer_final_table_name, Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Billing Table\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# add col to identify whether main brand was purchased\n",
							"\n",
							"billing = billing.withColumn(\"isMainBrand\", when((billing[\"brand\"]==\"BOHEMIA\")|\\\n",
							"    (billing[\"brand\"]==\"BRAHMA\")|\\\n",
							"    (billing[\"brand\"]==\"CORONA\")|\\\n",
							"    (billing[\"brand\"]==\"MODELO\")|\\\n",
							"    (billing[\"brand\"]==\"PRESIDENTE\")|\\\n",
							"    (billing[\"brand\"]==\"THE ONE\"), True).otherwise(False))"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"source": [
							"# translate spanish and combine 12 oz and 355 ml into a single value\n",
							"billing = billing.withColumn('packaging', regexp_replace('packaging', 'LITRO', 'LITER')) \\\n",
							"                 .withColumn('packaging', regexp_replace('packaging', '^12 OZ', '12 OZ/355 ML')) \\\n",
							"                 .withColumn('packaging', regexp_replace('packaging', '^355 ML', '12 OZ/355 ML'))"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"payment_type"
									],
									"values": [
										"count(payment_type)"
									],
									"yLabel": "count(payment_type)",
									"xLabel": "payment_type",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"count(payment_type)\":{\"Cash\":10616582,\"Credit\":5110734,\"ND\":315}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"# distribution of payment (credit yes/no) - translate to english\n",
							"\n",
							"billing = billing.withColumn(\"payment_type\",when(billing[\"payment_type\"] == \"Crdito\", \"Credit\").when(billing[\"payment_type\"] == \"Contado\", \"Cash\").otherwise(billing[\"payment_type\"]))"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"PocID"
									],
									"values": [
										"year"
									],
									"yLabel": "year",
									"xLabel": "PocID",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"year\":{\"0000230392\":2020,\"0000248742\":2020,\"0000445846\":2020,\"0000527689\":2020,\"0000538647\":2020}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"# add unique ID and save temp\n",
							"\n",
							"billing = billing.withColumn(\"poc_year_month_id\", concat(billing[\"PocID\"], lit(\"-\"), billing[\"year\"], lit(\"-\"), billing[\"month\"]))\n",
							"billing.createOrReplaceTempView(\"billing_filtered\")"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"outputCollapsed": true
						},
						"source": [
							"%%spark\n",
							"\n",
							"// write to sql pool\n",
							"\n",
							"val billing_filtered_df = spark.read.table(\"billing_filtered\")\n",
							"billing_filtered_df.write.mode(SaveMode.Overwrite).sqlanalytics(billing_final_table_name, Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"source": [
							"billing.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/billing_data\")"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Segment Data\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"billing = spark.read.format(\"delta\").load(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/billing_data\")"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"val order_completed_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.order_completed\")\n",
							"val order_completed_products_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.order_completed_products\")\n",
							"val order_completed_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.order_completed\")\n",
							"val order_completed_products_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.order_completed_products\")\n",
							"val card_viewed_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.card_viewed\")\n",
							"val card_viewed_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.card_viewed\")\n",
							"val product_added_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.product_added\")\n",
							"val product_added_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.product_added\")\n",
							"val points_redeemed_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.points_redeemed\")\n",
							"val points_redeemed_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.points_redeemed\")\n",
							"val points_activity_list_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.points_activity_list_viewed\")\n",
							"val points_activity_list_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.points_activity_list_viewed\")\n",
							"val delivery_rating_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.delivery_rating_submitted\")\n",
							"val delivery_rating_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.delivery_rating_submitted\")\n",
							"val app_opened_android = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_android.application_opened\")\n",
							"val app_opened_ios = spark.read.sqlanalytics(\"growthfactordev.dr_mi_cerveceria_ios.application_opened\")\n",
							"order_completed_ios.createOrReplaceTempView(\"order_completed_ios\")\n",
							"order_completed_products_ios.createOrReplaceTempView(\"order_completed_products_ios\")\n",
							"order_completed_android.createOrReplaceTempView(\"order_completed_android\")\n",
							"order_completed_products_android.createOrReplaceTempView(\"order_completed_products_android\")\n",
							"card_viewed_ios.createOrReplaceTempView(\"card_viewed_ios\")\n",
							"card_viewed_android.createOrReplaceTempView(\"card_viewed_android\")\n",
							"product_added_ios.createOrReplaceTempView(\"product_added_ios\")\n",
							"product_added_android.createOrReplaceTempView(\"product_added_android\")\n",
							"points_redeemed_ios.createOrReplaceTempView(\"points_redeemed_ios\")\n",
							"points_redeemed_android.createOrReplaceTempView(\"points_redeemed_android\")\n",
							"points_activity_list_android.createOrReplaceTempView(\"points_activity_list_android\")\n",
							"points_activity_list_ios.createOrReplaceTempView(\"points_activity_list_ios\")\n",
							"delivery_rating_android.createOrReplaceTempView(\"delivery_rating_android\")\n",
							"delivery_rating_ios.createOrReplaceTempView(\"delivery_rating_ios\")\n",
							"app_opened_android.createOrReplaceTempView(\"app_opened_android\")\n",
							"app_opened_ios.createOrReplaceTempView(\"app_opened_ios\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"source": [
							"order_completed_ios = spark.sql('SELECT * FROM order_completed_ios')\n",
							"order_completed_products_ios = spark.sql('SELECT * FROM order_completed_products_ios')\n",
							"order_completed_android = spark.sql('SELECT * FROM order_completed_android')\n",
							"order_completed_products_android = spark.sql('SELECT * FROM order_completed_products_android')\n",
							"card_viewed_ios = spark.sql('SELECT * FROM card_viewed_ios')\n",
							"card_viewed_android = spark.sql('SELECT * FROM card_viewed_android')\n",
							"product_added_ios = spark.sql('SELECT * FROM product_added_ios')\n",
							"product_added_android = spark.sql('SELECT * FROM product_added_android')\n",
							"points_redeemed_ios = spark.sql('SELECT * FROM points_redeemed_ios')\n",
							"points_redeemed_android = spark.sql('SELECT * FROM points_redeemed_android')\n",
							"points_activity_list_ios = spark.sql('SELECT * FROM points_activity_list_ios')\n",
							"points_activity_list_android = spark.sql('SELECT * FROM points_activity_list_android')\n",
							"delivery_rating_ios = spark.sql('SELECT * FROM delivery_rating_ios')\n",
							"delivery_rating_android = spark.sql('SELECT * FROM delivery_rating_android')\n",
							"app_opened_ios = spark.sql('SELECT * FROM app_opened_ios')\n",
							"app_opened_android = spark.sql('SELECT * FROM app_opened_android')"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"source": [
							"# join order to order completed tables\n",
							"order_completed_products_android_merged = order_completed_products_android.join(order_completed_android, on = 'order_id', how = 'inner')\n",
							"order_completed_products_ios_merged = order_completed_products_ios.join(order_completed_ios, on = 'order_id', how = 'inner')\n",
							"\n",
							"# concatenate order completed android and iOS tables\n",
							"order_completed = order_completed_products_android_merged.select('context_traits_poc_id', 'timestamp', 'brand', 'category', 'packaging', 'original_price', 'price', \n",
							"                                                                 'points_earned', 'sku', 'is_suggested', 'recommendation_type', 'quantity')\\\n",
							"                                                         .union(\n",
							"                  order_completed_products_ios_merged.select('context_traits_poc_id', 'timestamp', 'brand', 'category', 'packaging', 'original_price', 'price', \n",
							"                                                             'points_earned', 'sku', 'is_suggested', 'recommendation_type', 'quantity')                                          \n",
							"                                                            ) \n",
							"\n",
							"# drop rows missing a timestamp\n",
							"order_completed = order_completed.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"order_completed = order_completed.withColumn('month', month(order_completed['timestamp']))\\\n",
							"                                 .withColumn('year', year(order_completed['timestamp']))\n",
							"\n",
							"order_completed = order_completed.withColumn('order_completed', lit(1))\\\n",
							"                                 .drop('timestamp')\n",
							"\n",
							"# combined T and true from is_suggested into a single value\n",
							"order_completed = order_completed.withColumn('is_suggested', regexp_replace('is_suggested', 'true', 'T'))\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"# add a order_completed column, drop timestamp column\n",
							"# merge order completed with billing data for features that are based on % of revenue\n",
							"order_completed = order_completed.join(billing,\n",
							"                                      (billing['PocID'] == order_completed['context_traits_poc_id'])\\\n",
							"                                      & (billing['year'] == order_completed['year'])\\\n",
							"                                      & (billing['month'] == order_completed['month']),\n",
							"                                      how = 'left')\\\n",
							"                                     .drop(order_completed['context_traits_poc_id'])\\\n",
							"                                     .drop(order_completed['year'])\\\n",
							"                                     .drop(order_completed['month'])"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"# calculate percent of revenue that is ordered from recommended orders per customer per month\n",
							"rev_sum_cond = lambda cond: F.sum(F.when(cond, F.col('NetRevenue')).otherwise(0))\n",
							"per_of_rev_from_rec = order_completed.groupBy('PocID', 'year', 'month') \\\n",
							"               .agg(\n",
							"                    rev_sum_cond(F.col('recommendation_type') == 'FORGOTTEN_ITEMS').alias('forgotten_rev'),\n",
							"                    rev_sum_cond(F.col('recommendation_type') == 'QUICK_ORDER').alias('quick_order_rev'),\n",
							"                    rev_sum_cond(F.col('recommendation_type') == 'CROSS_SELL_UP_SELL').alias('cross_sell_rev'),\n",
							"                    rev_sum_cond(F.col('recommendation_type').isNull()).alias('total_revenue')\n",
							"                   ) \\\n",
							"               .withColumn('per_of_rev_from_forgotten', (F.col('forgotten_rev') / (F.col('total_revenue')))) \\\n",
							"               .withColumn('per_of_rev_from_quick_sell', (F.col('quick_order_rev') / (F.col('total_revenue')))) \\\n",
							"               .withColumn('per_of_rev_from_cross_sell', (F.col('cross_sell_rev') / (F.col('total_revenue')))) \\\n",
							"               .drop('forgotten_rev', 'quick_order_rev', 'cross_sell_rev', 'total_revenue', 'forgotten_rev', 'quick_order_rev', 'cross_sell_rev')"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"source": [
							"# count how many times a customer ordered a recommended product by recommendation type in a particular month\n",
							"cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
							"order_completed = order_completed.withColumnRenamed('context_traits_poc_id','PocID')\n",
							"recommendation = order_completed.groupBy('PocID', 'year', 'month')\\\n",
							"                                .agg(\n",
							"                                    cnt_cond(F.col('recommendation_type') == 'FORGOTTEN_ITEMS').alias('forgotten_items'),\n",
							"                                    cnt_cond(F.col('recommendation_type') == 'QUICK_ORDER').alias('quick_order'),\n",
							"                                    cnt_cond(F.col('recommendation_type') == 'CROSS_SELL_UP_SELL').alias('cross_sell_up_sell'),\n",
							"                                    )\n",
							"\n",
							"# change this to binary\n",
							"recommendation = recommendation.withColumn('forgotten_items', when(recommendation['forgotten_items'] >= 1, 1).otherwise(recommendation['forgotten_items'])) \\\n",
							"                               .withColumn('quick_order', when(recommendation['quick_order'] >= 1, 1).otherwise(recommendation['quick_order'])) \\\n",
							"                               .withColumn('cross_sell_up_sell', when(recommendation['cross_sell_up_sell'] >= 1, 1).otherwise(recommendation['cross_sell_up_sell'])) \\"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate card viewed android and iOS tables\n",
							"card_viewed = card_viewed_android.select('context_traits_poc_id', 'timestamp', 'brand', 'card_category', 'packaging', 'price', \n",
							"                                         'sku', 'sku_type', 'is_suggested', 'recommendation_type', 'recommended_quantity', \n",
							"                                         'promotion_type')\\\n",
							"                                 .union(\n",
							"              card_viewed_ios.select('context_traits_poc_id', 'timestamp', 'brand', 'card_category', 'packaging', 'price', \n",
							"                                     'sku', 'sku_type', 'is_suggested', 'recommendation_type', 'recommended_quantity', \n",
							"                                     'promotion_type')\n",
							"                                    )\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"card_viewed = card_viewed.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"card_viewed = card_viewed.withColumn('month', month(card_viewed['timestamp']))\\\n",
							"                         .withColumn('year', year(card_viewed['timestamp']))\n",
							"\n",
							"# add a deal_added column, drop timestamp and event columns and persist to delta table\n",
							"card_viewed = card_viewed.withColumn('card_viewed', lit(1))\\\n",
							"                         .drop('timestamp', 'event')\n",
							"\n",
							"# fix true/false columns\n",
							"card_viewed = card_viewed.withColumn('is_suggested', regexp_replace('is_suggested', 'true', 'T'))"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"# count how many times a customer viewed promotions in a particular month\n",
							"cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
							"num_promo_viewed = card_viewed.groupBy('context_traits_poc_id', 'year', 'month')\\\n",
							"                          .agg(\n",
							"                               cnt_cond(F.col('promotion_type').isNotNull()).alias('num_promo_viewed')\n",
							"                              )"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate product added android and iOS tables\n",
							"product_added = product_added_android.select('context_traits_poc_id', 'timestamp', 'brand', 'category', 'packaging', 'base_price', 'price', \n",
							"                                                              'sku', 'sku_type', 'is_reorder', 'is_redemption', 'is_suggested', 'recommendation_type', 'quantity', \n",
							"                                                              'quantity', 'promotion_type')\\\n",
							"                                     .union(product_added_ios.select('context_traits_poc_id', 'timestamp', 'brand', 'category', 'packaging', 'base_price', 'price', \n",
							"                                                              'sku', 'sku_type', 'is_reorder', 'is_redemption', 'is_suggested', 'recommendation_type', 'quantity', \n",
							"                                                              'quantity', 'promotion_type')\n",
							"                                           )\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"product_added = product_added.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"product_added = product_added.withColumn('month', month(product_added['timestamp']))\\\n",
							"                             .withColumn('year', year(product_added['timestamp']))\n",
							"\n",
							"# add a deal_added column, drop timestamp and event columns and persist to delta table\n",
							"product_added = product_added.withColumn('product_added', lit(1))\\\n",
							"                             .drop('timestamp', 'event')\n",
							"\n",
							"# fix true/false values\n",
							"product_added = product_added.withColumn('is_reorder', regexp_replace('is_reorder', 'false', 'F'))\n",
							"product_added = product_added.withColumn('is_reorder', regexp_replace('is_reorder', '1', 'T'))\n",
							"product_added = product_added.withColumn('is_redemption', regexp_replace('is_redemption', 'false', 'F'))\n",
							"product_added = product_added.withColumn('is_suggested', regexp_replace('is_suggested', '0', 'F'))\n",
							"product_added = product_added.withColumn('is_suggested', regexp_replace('is_suggested', 'true', 'T'))"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"source": [
							"# count how many times a customer added promotions in a particular month\n",
							"cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
							"num_promo_added = product_added.groupBy('context_traits_poc_id', 'year', 'month')\\\n",
							"                          .agg(\n",
							"                               cnt_cond(F.col('promotion_type').isNotNull()).alias('num_promo_added')\n",
							"                              )"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate points redeemed android and iOS tables\n",
							"points_redeemed = points_redeemed_android.select('context_traits_poc_id', 'timestamp', 'points_redeemed')\\\n",
							"                                 .union(\n",
							"                  points_redeemed_ios.select('context_traits_poc_id', 'timestamp', 'points_redeemed')\n",
							"                                       )\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"points_redeemed = points_redeemed.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"points_redeemed = points_redeemed.withColumn('month', month(points_redeemed['timestamp']))\\\n",
							"                                 .withColumn('year', year(points_redeemed['timestamp']))\n",
							"\n",
							"# add a deal_added column, drop timestamp and event columns and persist to delta table\n",
							"points_redeemed = points_redeemed.withColumn('points_redeemed_binary', lit(1))\\\n",
							"                                 .drop('timestamp')"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"source": [
							"# merge order completed with points_redeemed\n",
							"order_completed = order_completed.withColumnRenamed('context_traits_poc_id','PocID')\n",
							"points = order_completed.join(points_redeemed,\n",
							"                             (order_completed['PocID'] == points_redeemed['context_traits_poc_id']) \\\n",
							"                             & (order_completed['year'] == points_redeemed['year']) \\\n",
							"                             & (order_completed['month'] == points_redeemed['month']),\n",
							"                             how = 'left') \\\n",
							"                             .drop(points_redeemed['context_traits_poc_id']) \\\n",
							"                             .drop(points_redeemed['year']) \\\n",
							"                             .drop(points_redeemed['month']) \\\n",
							"                             .dropna(subset = ['PocID', 'year', 'month']) \\\n",
							"                             .fillna(0, subset = ['points_redeemed', 'points_redeemed_binary']) \\\n",
							"                             .select('PocID', 'year', 'month', 'points_redeemed', 'points_earned', 'points_redeemed_binary')\n",
							"\n",
							"# count how many times a customer redeemed points in a particular month\n",
							"cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
							"points_redeemed_binary = points.groupBy('PocID', 'year', 'month')\\\n",
							"                               .agg(\n",
							"                                    cnt_cond(F.col('points_redeemed_binary') == 1).alias('points_redeemed_binary')\n",
							"                                   )\n",
							"\n",
							"# change this to binary\n",
							"points_redeemed_binary = points_redeemed_binary.withColumn('points_redeemed_binary', \n",
							"                                                when(points_redeemed_binary['points_redeemed_binary'] >= 1, 1)\\\n",
							"                                               .otherwise(points_redeemed_binary['points_redeemed_binary']))"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"source": [
							"# redeemed points / earned points ratio\n",
							"points_redeemed_per_month = points.groupBy('PocID', 'month', 'year').agg(sum('points_redeemed').alias('points_redeemed_per_month'))\n",
							"points_earned_per_month = points.groupBy('PocID', 'month', 'year').agg(sum('points_earned').alias('points_earned_per_month'))\n",
							"\n",
							"points_redeemed_earned = points_redeemed_per_month.join(points_earned_per_month,\n",
							"                                                  (points_redeemed_per_month['PocID'] == points_earned_per_month['PocID']) \\\n",
							"                                                  & (points_redeemed_per_month['year'] == points_earned_per_month['year']) \\\n",
							"                                                  & (points_redeemed_per_month['month'] == points_earned_per_month['month']),\n",
							"                                                  how = 'inner') \\\n",
							"                                                  .drop(points_earned_per_month['PocID']) \\\n",
							"                                                  .drop(points_earned_per_month['year']) \\\n",
							"                                                  .drop(points_earned_per_month['month']) \\\n",
							"                                                  .withColumn('redeemed_to_earned_points_ratio', F.col('points_redeemed_per_month') / F.col('points_earned_per_month')) \\\n",
							"                                                  .fillna(0, subset = ['redeemed_to_earned_points_ratio']) \\\n",
							"                                                  .drop('points_redeemed_per_month', 'points_earned_per_month') "
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate order completed android and iOS tables\n",
							"points_activity_list = points_activity_list_android.select('context_traits_poc_id', 'timestamp')\\\n",
							"                                                   .union(\n",
							"                       points_activity_list_ios.select('context_traits_poc_id', 'timestamp')                                          \n",
							"                                                         ) \n",
							"\n",
							"# drop rows missing a timestamp\n",
							"points_activity_list = points_activity_list.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"points_activity_list = points_activity_list.withColumn('month', month(points_activity_list['timestamp']))\\\n",
							"                                           .withColumn('year', year(points_activity_list['timestamp']))\n",
							"\n",
							"# add a deal_added column, drop timestamp column\n",
							"points_activity_list = points_activity_list.withColumn('points_activity_list', lit(1))\\\n",
							"                                           .drop('timestamp')"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"source": [
							"# number of activity list views\n",
							"num_activity_list_views = points_activity_list.groupBy('context_traits_poc_id', 'month', 'year')\\\n",
							"                                              .agg(sum('points_activity_list')\\\n",
							"                                              .alias('num_activity_list_views'))"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate order completed android and iOS tables\n",
							"delivery_rating = delivery_rating_android.select('context_traits_poc_id', 'timestamp', 'rating_given')\\\n",
							"                                         .union(\n",
							"                                                delivery_rating_ios.select('context_traits_poc_id', 'timestamp', 'rating_given')                                          \n",
							"                                               ) \n",
							"\n",
							"# drop rows missing a timestamp\n",
							"delivery_rating = delivery_rating.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"delivery_rating = delivery_rating.withColumn('month', month(delivery_rating['timestamp']))\\\n",
							"                                 .withColumn('year', year(delivery_rating['timestamp']))\n",
							"\n",
							"# add a deal_added column, drop timestamp column\n",
							"delivery_rating = delivery_rating.withColumn('rated', lit(1))\\\n",
							"                                 .drop('timestamp')"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"source": [
							"# avg delivery rating viewed user/mo\n",
							"avg_delivery_rating = delivery_rating.groupBy('context_traits_poc_id', 'month', 'year').agg(avg('rating_given').alias('avg_delivery_rating'))"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"source": [
							"# calculate percent of revenue that is ordered from recommended orders per customer per month\n",
							"rev_sum_cond = lambda cond: F.sum(F.when(cond, F.col('total_net_revenue')).otherwise(0))\n",
							"order_completed = order_completed.withColumn('total_net_revenue', col('price') * col('quantity'))\n",
							"per_of_rev_from_rec = order_completed.groupBy('PocID', 'year', 'month') \\\n",
							"               .agg(\n",
							"                    rev_sum_cond(F.col('recommendation_type') == 'FORGOTTEN_ITEMS').alias('forgotten_rev'),\n",
							"                    rev_sum_cond(F.col('recommendation_type') == 'QUICK_ORDER').alias('quick_order_rev'),\n",
							"                    rev_sum_cond(F.col('recommendation_type') == 'CROSS_SELL_UP_SELL').alias('cross_sell_rev'),\n",
							"                    rev_sum_cond(F.col('recommendation_type').isNull()).alias('total_revenue')\n",
							"                   ) \\\n",
							"               .withColumn('per_of_rev_from_forgotten', (F.col('forgotten_rev') / (F.col('total_revenue')))) \\\n",
							"               .withColumn('per_of_rev_from_quick_sell', (F.col('quick_order_rev') / (F.col('total_revenue')))) \\\n",
							"               .withColumn('per_of_rev_from_cross_sell', (F.col('cross_sell_rev') / (F.col('total_revenue')))) \\\n",
							"               .drop('forgotten_rev', 'quick_order_rev', 'cross_sell_rev', 'total_revenue', 'forgotten_rev', 'quick_order_rev', 'cross_sell_rev')"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"source": [
							"# concatenate app opened android and iOS tables\n",
							"app_opened = app_opened_android.select('context_traits_poc_id', 'timestamp')\\\n",
							"                               .union(\n",
							"             app_opened_ios.select('context_traits_poc_id', 'timestamp')\n",
							"                                     )\n",
							"\n",
							"# drop rows missing a timestamp\n",
							"app_opened = app_opened.dropna(subset = ['timestamp'])\n",
							"\n",
							"# add month and year columns\n",
							"app_opened = app_opened.withColumn('month', month(app_opened['timestamp']))\\\n",
							"                       .withColumn('year', year(app_opened['timestamp']))\n",
							"\n",
							"# add a deal_added column, drop timestamp and event columns and persist to delta table\n",
							"app_opened = app_opened.withColumn('app_opened', lit(1))\\\n",
							"                       .drop('timestamp')"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"source": [
							"# number of app opens per user/mo\n",
							"num_app_opens = app_opened.groupBy('context_traits_poc_id', 'month', 'year').agg(sum('app_opened').alias('num_app_opens'))"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"source": [
							"recommendation.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/recommendation_data\")"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"source": [
							"recommendation = spark.read.format(\"delta\").load(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/recommendation_data\")"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"source": [
							"# create a table with the unique set of composite keys where there is Segment data\n",
							"segment_users_unique = recommendation.select('PocID', 'year', 'month').withColumnRenamed('PocID', 'context_traits_poc_id')\\\n",
							"                                     .union(per_of_rev_from_rec.select('PocID', 'year', 'month').withColumnRenamed('PocID', 'context_traits_poc_id'))\\\n",
							"                                     .union(num_promo_viewed.select('context_traits_poc_id', 'year', 'month'))\\\n",
							"                                     .union(num_promo_added.select('context_traits_poc_id', 'year', 'month'))\\\n",
							"                                     .union(points_redeemed_binary.select('PocID', 'year', 'month').withColumnRenamed('PocID', 'context_traits_poc_id'))\\\n",
							"                                     .union(points_redeemed_earned.select('PocID', 'year', 'month').withColumnRenamed('PocID', 'context_traits_poc_id'))\\\n",
							"                                     .union(num_activity_list_views.select('context_traits_poc_id', 'year', 'month'))\\\n",
							"                                     .union(avg_delivery_rating.select('context_traits_poc_id', 'year', 'month'))\\\n",
							"                                     .union(num_app_opens.select('context_traits_poc_id', 'year', 'month'))\\\n",
							"                                     .dropDuplicates()\\\n",
							"                                     .dropna(subset = ['context_traits_poc_id', 'year', 'month'], how = 'any')\\\n",
							"                                     .withColumnRenamed('context_traits_poc_id', 'context_traits_poc_id2')\\\n",
							"                                     .withColumnRenamed('year', 'year2')\\\n",
							"                                     .withColumnRenamed('month', 'month2')"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"source": [
							"segment_users_unique.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/segment_users_unique\")"
						],
						"outputs": [],
						"execution_count": 29
					},
					{
						"cell_type": "code",
						"source": [
							"segment_users_unique = spark.read.format(\"delta\").load(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/segment_users_unique\")"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"source": [
							"# left join all of the segment features to this table\n",
							"segment_features = segment_users_unique.join(recommendation, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == recommendation['PocID'])\\\n",
							"                                     & (segment_users_unique['year2'] == recommendation['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == recommendation['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(recommendation['PocID'])\\\n",
							"                                     .drop(recommendation['year'])\\\n",
							"                                     .drop(recommendation['month'])\\\n",
							"                                     .join(per_of_rev_from_rec, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == per_of_rev_from_rec['PocID'])\\\n",
							"                                     & (segment_users_unique['year2'] == per_of_rev_from_rec['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == per_of_rev_from_rec['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(per_of_rev_from_rec['PocID'])\\\n",
							"                                     .drop(per_of_rev_from_rec['year'])\\\n",
							"                                     .drop(per_of_rev_from_rec['month'])\\\n",
							"                                     .join(num_promo_viewed, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == num_promo_viewed['context_traits_poc_id'])\\\n",
							"                                     & (segment_users_unique['year2'] == num_promo_viewed['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == num_promo_viewed['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(num_promo_viewed['context_traits_poc_id'])\\\n",
							"                                     .drop(num_promo_viewed['year'])\\\n",
							"                                     .drop(num_promo_viewed['month'])\\\n",
							"                                     .join(num_promo_added, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == num_promo_added['context_traits_poc_id'])\\\n",
							"                                     & (segment_users_unique['year2'] == num_promo_added['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == num_promo_added['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(num_promo_added['context_traits_poc_id'])\\\n",
							"                                     .drop(num_promo_added['year'])\\\n",
							"                                     .drop(num_promo_added['month'])\\\n",
							"                                     .join(points_redeemed_binary, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == points_redeemed_binary['PocID'])\\\n",
							"                                     & (segment_users_unique['year2'] == points_redeemed_binary['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == points_redeemed_binary['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(points_redeemed_binary['PocID'])\\\n",
							"                                     .drop(points_redeemed_binary['year'])\\\n",
							"                                     .drop(points_redeemed_binary['month'])\\\n",
							"                                     .join(points_redeemed_earned, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == points_redeemed_earned['PocID'])\\\n",
							"                                     & (segment_users_unique['year2'] == points_redeemed_earned['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == points_redeemed_earned['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(points_redeemed_earned['PocID'])\\\n",
							"                                     .drop(points_redeemed_earned['year'])\\\n",
							"                                     .drop(points_redeemed_earned['month'])\\\n",
							"                                     .join(num_activity_list_views, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == num_activity_list_views['context_traits_poc_id'])\\\n",
							"                                     & (segment_users_unique['year2'] == num_activity_list_views['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == num_activity_list_views['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(num_activity_list_views['context_traits_poc_id'])\\\n",
							"                                     .drop(num_activity_list_views['year'])\\\n",
							"                                     .drop(num_activity_list_views['month'])\\\n",
							"                                     .join(avg_delivery_rating, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == avg_delivery_rating['context_traits_poc_id'])\\\n",
							"                                     & (segment_users_unique['year2'] == avg_delivery_rating['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == avg_delivery_rating['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(avg_delivery_rating['context_traits_poc_id'])\\\n",
							"                                     .drop(avg_delivery_rating['year'])\\\n",
							"                                     .drop(avg_delivery_rating['month'])\\\n",
							"                                     .join(num_app_opens, \n",
							"                                       (segment_users_unique['context_traits_poc_id2'] == num_app_opens['context_traits_poc_id'])\\\n",
							"                                     & (segment_users_unique['year2'] == num_app_opens['year'])\\\n",
							"                                     & (segment_users_unique['month2'] == num_app_opens['month']),\n",
							"                                        how = 'left')\\\n",
							"                                     .drop(num_app_opens['context_traits_poc_id'])\\\n",
							"                                     .drop(num_app_opens['year'])\\\n",
							"                                     .drop(num_app_opens['month'])\\\n",
							"                                     .withColumnRenamed('context_traits_poc_id2', 'PocID')\\\n",
							"                                     .withColumnRenamed('year2', 'year')\\\n",
							"                                     .withColumnRenamed('month2', 'month')                                                                                                    "
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"outputCollapsed": true
						},
						"source": [
							"segment_features.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/segment_features\")"
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"source": [
							"segment_features = spark.read.format(\"delta\").load(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/segment_features\")"
						],
						"outputs": [],
						"execution_count": 32
					},
					{
						"cell_type": "code",
						"source": [
							"segment_features.write.format('csv').option('header',True).mode('overwrite').save(\"abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/globalbrewdatsynapsegbdev/synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/segment_features_csv\")"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"source": [
							"# Exporting to table in DWH leads to systematic timeout,\n",
							"# that's why I prefered exporting to CSV for PBI consumption\n",
							"# (same reason for creating intermediate outputs)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/test_brandmatch')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "origin",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/73f88e6b-3a35-4612-b550-555157e7059f/resourceGroups/Global-EnterpriseDataHub-RG-GB-DEV/providers/Microsoft.Synapse/workspaces/globalbrewdatsynapsegbdev/bigDataPools/origin",
						"name": "origin",
						"type": "Spark",
						"endpoint": "https://globalbrewdatsynapsegbdev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/origin",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 3,
						"cores": 16,
						"memory": 112
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import os\n",
							"import pandas as pd\n",
							"import numpy as np\n",
							"from pandas import DataFrame\n",
							"from fuzzywuzzy import fuzz\n",
							"from pyspark.sql.functions import *\n",
							"import warnings\n",
							"warnings.filterwarnings(\"ignore\")\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"cellLanguage": "scala",
							"tags": [
								"parameters"
							]
						},
						"source": [
							"%%spark\n",
							"val db_path =\"\"\n",
							"val brandmarket_table_name = db_path + \".dbo.BrandMasterDataConsolidated\"\n",
							"val cip_file_line_error_table_name = db_path + \".jobs.cip_file_line_error_intermediate\"\n",
							"val ds_model_config_table_name = db_path + \".dbo.DataScienceModelConfiguration\"\n",
							"val brand_matching_summary_table_name = db_path + \".dbo.brand_matching_summary\"\n",
							"val brand_matching_performance_table_name = db_path + \".dbo.brand_matching_performance\""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"tags": []
						},
						"source": [
							"root_path = 'abfss://globalbrewdatsynapsegbdev@abigrowthfactoradls.dfs.core.windows.net/'\n",
							"folder_path = 'synapse/workspaces/globalbrewdatsynapsegbdev/warehouse/'\n",
							"output_name = 'matched_brand_data_incremental'\n",
							"output_name1 = 'matched_brand_data_incremental_perfomance'"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"// scala library imports\n",
							"import org.apache.spark.sql.types._\n",
							"import org.apache.spark.sql._\n",
							"import org.apache.spark.sql.SqlAnalyticsConnector._\n",
							"import org.apache.spark._\n",
							"import org.apache.spark.sql.functions._"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"val brandmarket_df = spark.read.sqlanalytics(brandmarket_table_name)\n",
							"brandmarket_df.createOrReplaceTempView(\"brandmarket\")\n",
							"\n",
							"val cip_file_line_error_df = spark.read.sqlanalytics(cip_file_line_error_table_name)\n",
							"cip_file_line_error_df.createOrReplaceTempView(\"cip_file_line_error_intermediate\")\n",
							"\n",
							"val ds_model_config_df = spark.read.sqlanalytics(ds_model_config_table_name)\n",
							"ds_model_config_df.createOrReplaceTempView(\"ds_matchbrand_configuration\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"source": [
							"def read_input_data(table_name):\n",
							"    df = spark.read.table(table_name)\n",
							"    df = df.toPandas()\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"source": [
							"model_config_df = read_input_data(\"ds_matchbrand_configuration\")\n",
							"matching_threshold=model_config_df.iloc[0,3]"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"source": [
							"def write_output_data(df):\n",
							"    sparkdf = spark.createDataFrame(df)\n",
							"    sparkdf = sparkdf\\\n",
							"        .withColumn('date', current_date())     \n",
							"    delta_table_path = root_path + folder_path + output_name\n",
							"    sparkdf.write\\\n",
							"        .format(\"delta\")\\\n",
							"        .mode(\"overwrite\")\\\n",
							"        .option(\"mergeSchema\", \"true\")\\\n",
							"        .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"def write_output_data_perf(dfp):\n",
							"    sparkdfp = spark.createDataFrame(dfp)   \n",
							"    delta_table_path = root_path + folder_path + output_name1\n",
							"    sparkdfp.write\\\n",
							"        .format(\"delta\")\\\n",
							"        .mode(\"overwrite\")\\\n",
							"        .option(\"mergeSchema\", \"true\")\\\n",
							"        .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"source": [
							"def country_master_data(master_data):\n",
							"    #master_data=master_data.loc[master_data['CountryCode'].isin(Master_CC)]\n",
							"    master_data=master_data[['BrandName','CountryCode']]\n",
							"    master_data['sourcedb_name'] = 'CIP'\n",
							"    master_data.rename(columns = {'BrandName':'brand'}, inplace = True)\n",
							"    master_data=master_data.drop_duplicates(subset='brand', keep=\"last\")\n",
							"    return master_data"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"def mbarn_SplCharRemove(mdf):\n",
							"    spec_chars = [\"%\",\"/\",\"'\",\"(\",\")\"]#,\",\",\n",
							"                      #\"/MGD 64\",\"/ Len\"]\n",
							"    for char in spec_chars:\n",
							"        mdf['brand'] = mdf['brand'].str.replace(char,'')\n",
							"    return mdf\n",
							"    \n",
							"def mbarn_replace(mdf):\n",
							"    # This function will help to increase confidance scope\n",
							"    mdf[\"brand\"].replace({\"\": \"o\", \"\": \"o\"}, inplace=True)\n",
							"    mdf['brand'].dropna(axis=0, how='all',inplace = True)\n",
							"    return mdf"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"def cip_errorlog_processing(error_log):\n",
							"    #error_log=error_log.loc[error_log['country_code'] == \"MX\"]\n",
							"    error_log=error_log.fillna(0)\n",
							"    error_log=error_log.astype({'file_id': 'int', 'severity_id': 'int',\\\n",
							"                                        'row_number': 'int','error_id': 'int'})\n",
							"    error_log= error_log[['survey_type','severity_id','error_id',\\\n",
							"                                  'error_field','error_message',\\\n",
							"                                  'error_description','created_date',\\\n",
							"                                  'country_code']]\n",
							"    error_log= error_log[(error_log.error_field==\"DerievedBrandID\")]\n",
							"    error_log=error_log.loc[0:3999,:]\n",
							"    return error_log"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"source": [
							"def brand_extraction(processed_data):\n",
							"    processed_data['H_Brand'] = processed_data.\\\n",
							"    loc[processed_data['error_field'].isin(['DerievedBrandID'])]\\\n",
							"            ['error_description'].str.split('-').str[1]\n",
							"        \n",
							"    processed_data['H_Brand'].fillna('',inplace = True)\n",
							"    processed_data['H_Brand'] = processed_data['H_Brand'].astype('str')\n",
							"    return processed_data\n",
							"\n",
							"def garbage_char_remove(logdf):\n",
							"    spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
							"                          \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
							"                          \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
							"                          \"`\",\"{\",\"|\",\"}\",\"~\",\"\"]\n",
							"    for char in spec_chars:\n",
							"        logdf['H_Brand'] = logdf['H_Brand'].str.replace(char,'')\n",
							"    return logdf\n",
							"\n",
							"def remove_spl_char(char_df):\n",
							"    spec_chars = [\"194\",'195',\"MILLER LITE SSNET\",\"Chandon\",\n",
							"                          \"MGD 64\"]\n",
							"        \n",
							"    for char in spec_chars:\n",
							"        char_df['H_Brand'] = char_df['H_Brand'].str.replace(char,'')\n",
							"    return char_df\n",
							"\n",
							"def date_processing(clean_df):\n",
							"    clean_df['created_date'] = pd.to_datetime(clean_df['created_date'], errors='coerce')\n",
							"    clean_df['BH_Year_Month'] = clean_df['created_date'].dt.strftime('%Y-%m')\n",
							"    clean_df['BH_Year'] = clean_df['created_date'].dt.strftime('%Y')\n",
							"    clean_df = clean_df.drop_duplicates(subset='H_Brand', keep=\"first\")\n",
							"    return clean_df"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"source": [
							"def brand_harmonization(brand_data,BM_master,match_thr):\n",
							"    matched_brands = []\n",
							"    for row in brand_data.index:\n",
							"        brand_name = brand_data.get_value(row,\"H_Brand\")\n",
							"        brand_name=brand_name.strip()\n",
							"        brand_cc = brand_data.get_value(row,\"country_code\")\n",
							"        for row_label in BM_master.index:\n",
							"            BM_master=BM_master.astype(str)\n",
							"            master_brand_name=BM_master.get_value(row_label,\"brand\") \n",
							"            master_brand_name=master_brand_name.strip()\n",
							"            mbrand_source_name=BM_master.get_value(row_label,\"sourcedb_name\")\n",
							"            mbrand_country_name=BM_master.get_value(row_label,\"CountryCode\")\n",
							"            matched_token=fuzz.ratio(brand_name,master_brand_name)\n",
							"            \n",
							"            if matched_token> 90:\n",
							"                matched_category='High'\n",
							"            elif (matched_token> 84 and matched_token<91):\n",
							"                matched_category='Moderate'\n",
							"            elif (matched_token> 80 and matched_token<85):\n",
							"                matched_category='Low'\n",
							"            else:\n",
							"                matched_category='Very Low'\n",
							"            \n",
							"            if matched_token> match_thr:\n",
							"                matched_brands.append([brand_name,brand_cc,master_brand_name,matched_token,\\\n",
							"                                       matched_category,mbrand_source_name,\\\n",
							"                                       mbrand_country_name])\n",
							"    return matched_brands"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"source": [
							"def output_formating(Brand_Matching):\n",
							"    lst=[]\n",
							"    lsti=[]\n",
							"    lstii=[]\n",
							"    lstsi=[]\n",
							"    lstci=[]\n",
							"    brand_unq=[]\n",
							"    bcc=[]\n",
							"    ls=[]\n",
							"    score_seg = []\n",
							"\n",
							"    for i in Brand_Matching.BH.unique():\n",
							"        agg_bcc=Brand_Matching.loc[Brand_Matching.BH==i, 'brand_cc'].unique().tolist()\n",
							"        agg_brand=Brand_Matching.loc[Brand_Matching.BH==i, 'Matched_Brand'].values.tolist()\n",
							"        agg_score=Brand_Matching.loc[Brand_Matching.BH==i, 'Score'].values.tolist()\n",
							"        agg_scorecat=Brand_Matching.loc[Brand_Matching.BH==i, 'Score_categroty'].values.tolist()\n",
							"        agg_si=Brand_Matching.loc[Brand_Matching.BH==i, 'mSource_info'].values.tolist()\n",
							"        agg_ci=Brand_Matching.loc[Brand_Matching.BH==i, 'mCountry_info'].values.tolist()\n",
							"        \n",
							"        cond1 = True in ((i >= 90 and i<=100) for i in agg_score) \n",
							"        cond2 = True in ((i >= 75 and i<90) for i in agg_score) \n",
							"        cond3 = True in ((i >= 0 and i<75) for i in agg_score) \n",
							"\n",
							"        if(cond1):\n",
							"            action = \"No Action\"\n",
							"        elif (cond2):\n",
							"            action = \"Prediction Validation to be suggested to BM\"\n",
							"        elif (cond3):\n",
							"            action = \"Disregard or suggestion to be made by BM\"\n",
							"        else:\n",
							"            action = \"\"\n",
							"\n",
							"        lst.append(agg_brand)\n",
							"        lsti.append(agg_score)\n",
							"        lstii.append(agg_scorecat)\n",
							"        lstsi.append(agg_si)\n",
							"        lstci.append(agg_ci)\n",
							"        brand_unq.append(i)\n",
							"        bcc.append(agg_bcc)\n",
							"        score_seg.append(action)\n",
							"    \n",
							"    data = {'Brand_Harmonized':brand_unq,'Brand_CC':bcc, 'Matched_Brands[Country]':lst,\\\n",
							"            'Score': lsti,'Score_Category':lstii,'mSource_info':lstsi,'mCountry_info':lstci,\\\n",
							"             'Score_Segmentation': score_seg}\n",
							"    newdf = pd.DataFrame(data)\n",
							"    return newdf"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"source": [
							"def process_data(brand_error_log):\n",
							"    brand_error_log_final = cip_errorlog_processing(brand_error_log)\n",
							"    brand_ext= brand_extraction(brand_error_log_final)\n",
							"    clean_brand_ext = garbage_char_remove(brand_ext)\n",
							"    clean_brand_df = remove_spl_char(clean_brand_ext)\n",
							"    brand_error_log = date_processing(clean_brand_df)\n",
							"    return brand_error_log, brand_error_log_final"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"source": [
							"def matching_score(bm_master, brand_error_log, matching_thr):\n",
							"    matched_brands_score = []\n",
							"    matched_brands_score = brand_harmonization(brand_error_log, bm_master, matching_thr)\n",
							"    matching_dataset = pd.DataFrame(matched_brands_score, columns=['BH','brand_cc','Matched_Brand','Score','Score_categroty',\\\n",
							"                                                               'mSource_info','mCountry_info'])\n",
							"    matched_brands = output_formating(matching_dataset)\n",
							"    return matched_brands"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"source": [
							"def brand_matching(matching_threshold):\n",
							"    # Get the Brand Market data\n",
							"    bm_master = read_input_data(\"brandmarket\")\n",
							"    # add this line in masterdata processing function\n",
							"    bm_master[\"CountryCode\"].fillna(\"global\", inplace = True)\n",
							"    master_source=bm_master['SourceSystem'].unique()\n",
							"    Master_Source='_'.join(master_source)\n",
							"    master_cc=bm_master['CountryCode'].unique()\n",
							"    Master_CC='_'.join(master_cc)\n",
							"    # Get the CIP File Line Error Incremental data\n",
							"    brand_error_log = read_input_data(\"cip_file_line_error_intermediate\")\n",
							"    # Perform Data Processing\n",
							"    bm_master= country_master_data(bm_master)\n",
							"    bm_master=mbarn_replace(bm_master)\n",
							"    brand_error_log, brand_error_log_final = process_data(brand_error_log)\n",
							"    # Matching Score using Fuzzy Matching\n",
							"    matched_brands = matching_score(bm_master, brand_error_log, matching_threshold)\n",
							"    #return matched_brands\n",
							"    if(len(matched_brands) > 0):\n",
							"        # Write the Output to Delta Table\n",
							"        write_output_data(matched_brands)\n",
							"    else:\n",
							"        print('No records to write in the output table.')\n",
							"    \n",
							"    #return matched_brands performance\n",
							"    perf_mx_master_local=(matched_brands['Brand_Harmonized'].unique().shape[0]/\n",
							"                          brand_error_log_final['H_Brand'].unique().shape[0])*100\n",
							"    cc=brand_error_log['country_code'].unique()\n",
							"    BH_CC='_'.join(cc)\n",
							"    #Master_CC=\"all\"\n",
							"    BH_Source=\"CIP\" #hardcoding as this information is not available in Source\n",
							"    act_brand_proc=brand_error_log_final.shape[0]\n",
							"    uniq_brand_proc=brand_error_log.shape[0]\n",
							"    matched_brand=matched_brands['Brand_Harmonized'].unique().shape[0]\n",
							"\n",
							"    #output_df['Master_Source']=pd.Series([Master_Data_Source]) #Created Dummy Name for now.\n",
							"    #output_df['Master_CC']=pd.Series([Master_CC]) #Created Dummy Name for now.\n",
							"\n",
							"    #datapf = {'Performance_in_perc':perf_mx_master_local,'BH_CC':cc}\n",
							"    datapf = {'Master_Source': Master_Source,'Master_CC':Master_CC,'BH_Source':BH_Source,\\\n",
							"        'BH_CC':BH_CC,'Actual_Brand_Processed':act_brand_proc,\\\n",
							"        'Unique_Brand_Processed':uniq_brand_proc,'Matched_Brand':matched_brand,\\\n",
							"        'Performance_in_perc':perf_mx_master_local}\n",
							"    output_df = pd.DataFrame(datapf, index=[0])\n",
							"\n",
							"    write_output_data_perf(output_df)\n",
							""
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"_1"
									],
									"values": [
										"_4"
									],
									"yLabel": "_4",
									"xLabel": "_1",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"_4\":{\"Gilbeys\":93,\"Gordons\":1386,\"Hennessy\":793,\"Jack Daniels\":1631,\"Jameson\":400,\"Smirnoff\":4653,\"Strongbow\":1547,\"Tafel Lager\":611,\"VAT 69\":300,\"William Grants\":365,\"Windhoek Light\":1559}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"brand_matching(matching_threshold)"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Brand_Harmonized"
									],
									"values": [
										"Brand_Harmonized"
									],
									"yLabel": "Brand_Harmonized",
									"xLabel": "Brand_Harmonized",
									"aggregation": "COUNT",
									"aggByBackend": false
								},
								"aggData": "{\"Brand_Harmonized\":{\"Amstel lager\":1,\"Michelob Ultra\":1,\"Strongbow\":1,\"Tafel Lager\":1,\"Windhoek Light\":1}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"delta_table_path = root_path + folder_path + output_name\n",
							"output_df = spark.read.format(\"delta\").load(delta_table_path)\n",
							"output_df.createOrReplaceTempView(\"matched_brands_temp\")\n",
							"display(output_df)"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Brand_Harmonized"
									],
									"values": [
										"Brand_Harmonized"
									],
									"yLabel": "Brand_Harmonized",
									"xLabel": "Brand_Harmonized",
									"aggregation": "COUNT",
									"aggByBackend": false
								},
								"aggData": "{\"Brand_Harmonized\":{\"Amstel lager\":1,\"Michelob Ultra\":1,\"Strongbow\":1,\"Tafel Lager\":1,\"Windhoek Light\":1}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"%%spark\n",
							"val mbdf = spark.sqlContext.sql (\"select * from matched_brands_temp\").\n",
							"                    withColumn(\"Brand_CC\", concat_ws(\",\", $\"Brand_CC\")).\n",
							"                    withColumn(\"Matched_Brands[Country]\", concat_ws(\",\", $\"Matched_Brands[Country]\")).\n",
							"                    withColumn(\"Score\", concat_ws(\",\", $\"Score\")).\n",
							"                    withColumn(\"Score_Category\", concat_ws(\",\", $\"Score_Category\")).\n",
							"                    withColumn(\"mSource_info\", concat_ws(\",\", $\"mSource_info\")).\n",
							"                    withColumn(\"mCountry_info\", concat_ws(\",\", $\"mCountry_info\")).\n",
							"                    drop(\"Matched_Brands_Country\").\n",
							"                    withColumnRenamed(\"Matched_Brands[Country]\",\"Matched_Brands_Country\")\n",
							"              \n",
							"display(mbdf)"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"mbdf.write.synapsesql(brand_matching_summary_table_name, com.microsoft.spark.sqlanalytics.utils.Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"BH_CC"
									],
									"values": [
										"Performance_in_perc"
									],
									"yLabel": "Performance_in_perc",
									"xLabel": "BH_CC",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"Performance_in_perc\":{\"AR_KR_GH_ZA\":50}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"delta_table_path = root_path + folder_path + output_name1\n",
							"output_df1 = spark.read.format(\"delta\").load(delta_table_path)\n",
							"output_df1.createOrReplaceTempView(\"matched_brands_perf_temp\")"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"diagram": {
								"activateDiagramType": 1,
								"chartConfig": {
									"category": "bar",
									"keys": [
										"Master_Source"
									],
									"values": [
										"Actual_Brand_Processed"
									],
									"yLabel": "Actual_Brand_Processed",
									"xLabel": "Master_Source",
									"aggregation": "SUM",
									"aggByBackend": false
								},
								"aggData": "{\"Actual_Brand_Processed\":{\"CIP_Rosetta\":9}}",
								"isSummary": false,
								"previewData": {
									"filter": null
								},
								"isSql": false
							}
						},
						"source": [
							"%%spark\n",
							"val mbpdf = spark.sqlContext.sql (\"select * from matched_brands_perf_temp\").\n",
							"                    withColumn(\"Master_Source\", concat_ws(\"_\", $\"Master_Source\")).\n",
							"                    withColumn(\"Master_CC\", concat_ws(\"_\", $\"Master_CC\")).\n",
							"                    withColumn(\"BH_CC\", concat_ws(\"_\", $\"BH_CC\"))              \n",
							"display(mbpdf)"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"source": [
							"%%spark\n",
							"mbpdf.write.synapsesql(brand_matching_performance_table_name, com.microsoft.spark.sqlanalytics.utils.Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 25
					}
				]
			},
			"dependsOn": []
		}
	]
}
